{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30657e10",
   "metadata": {},
   "source": [
    "# LLM/NLP Analysis of Cognitive States using ZuCo Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0334ab",
   "metadata": {},
   "source": [
    "## 1. **Project Setup and Initial Configuration**  \n",
    "This section consolidates all imports, configurations, and initial data loading functions for streamlined analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b900f",
   "metadata": {},
   "source": [
    "### 1.1. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0818b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Eda AYDIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Core Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk # For tokenization\n",
    "\n",
    "# --- Scikit-learn for Modeling & Preprocessing ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    accuracy_score\n",
    ")\n",
    "\n",
    "# --- NLP & Feature Extraction Libraries ---\n",
    "# Ensure these are installed:\n",
    "# pip install sentence-transformers textstat spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "# pip install ollama (if using actual Ollama integration)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import textstat\n",
    "import spacy\n",
    "# import ollama # Uncomment if you plan to use direct Ollama integration\n",
    "\n",
    "# --- Utility ---\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Suppress warnings for cleaner output (optional)\n",
    "\n",
    "# --- Plotting Style ---\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# --- Reproducibility ---\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# --- Download NLTK resources (if not already present) ---\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except (LookupError, OSError):\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    \n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c79300",
   "metadata": {},
   "source": [
    "### 1.2. Configuration Constants and File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d3bbc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration Constants ---\n",
    "DATA_DIRECTORY = \"task_materials\"  # Directory containing the CSV files\n",
    "NR_FILE_PATTERN = \"nr_*.csv\"\n",
    "TSR_FILE_PATTERN = \"tsr_*.csv\"\n",
    "SENTENCE_COLUMN_INDEX = 2  # Sentences are in the 3rd column (0-indexed)\n",
    "\n",
    "# --- Output Filenames for Processed Data & Features ---\n",
    "# This helps in saving intermediate results and avoiding re-computation\n",
    "PROCESSED_DATA_FILENAME = \"zuco_processed_sentences.csv\"\n",
    "EMBEDDINGS_FILENAME_NP = \"sentence_embeddings.npy\"\n",
    "BASE_DISCRETE_FEATURES_FILENAME_CSV = \"base_discrete_features.csv\"\n",
    "ENHANCED_DISCRETE_FEATURES_FILENAME_CSV = \"enhanced_discrete_features.csv\"\n",
    "\n",
    "# --- For Storing Model Results ---\n",
    "all_model_results_list = [] # Initialize a list to store results from all models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4e3c6f",
   "metadata": {},
   "source": [
    "### 1.3. Utility Functions\n",
    "\n",
    "#### 1.3.1. Data Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3254caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentences_from_files(directory, file_pattern, condition_label):\n",
    "    \"\"\"\n",
    "    Loads sentences from CSV files matching a pattern within a specified directory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The directory where CSV files are located.\n",
    "        file_pattern (str): Glob pattern for the CSV files (e.g., \"nr_*.csv\").\n",
    "        condition_label (str): Label to assign (e.g., \"NR\" or \"TSR\").\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with 'sentence' and 'condition' columns,\n",
    "                          or an empty DataFrame if no files are found or errors occur.\n",
    "    \"\"\"\n",
    "    full_pattern = os.path.join(directory, file_pattern)\n",
    "    filenames = sorted(glob.glob(full_pattern)) # Sort for consistent order\n",
    "\n",
    "    if not filenames:\n",
    "        print(f\"No files found for pattern: {full_pattern}\")\n",
    "        print(\"Please ensure DATA_DIRECTORY and file patterns are correct.\")\n",
    "        return pd.DataFrame(columns=['sentence', 'condition']) # Return empty DataFrame\n",
    "\n",
    "    all_sentences_dfs = []\n",
    "    for filename in filenames:\n",
    "        try:\n",
    "            # Assuming sentences are in the column specified by SENTENCE_COLUMN_INDEX\n",
    "            df = pd.read_csv(filename, delimiter=';', header=None, on_bad_lines='warn')\n",
    "            if SENTENCE_COLUMN_INDEX < df.shape[1]:\n",
    "                sentences_df = df.iloc[:, [SENTENCE_COLUMN_INDEX]].copy() # Use .copy()\n",
    "                sentences_df.columns = ['sentence']\n",
    "                sentences_df['condition'] = condition_label\n",
    "                all_sentences_dfs.append(sentences_df)\n",
    "            else:\n",
    "                print(f\"Warning: {filename} does not have column index {SENTENCE_COLUMN_INDEX}.\")\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Warning: {filename} is empty.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "    if not all_sentences_dfs:\n",
    "        print(f\"No sentences extracted for condition: {condition_label}\")\n",
    "        return pd.DataFrame(columns=['sentence', 'condition'])\n",
    "\n",
    "    return pd.concat(all_sentences_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6b56e8",
   "metadata": {},
   "source": [
    "#### 1.3.2. Text Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008a4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans a text string by converting to lowercase and removing extra whitespace.\n",
    "    Handles potential non-string inputs by converting to string first.\n",
    "\n",
    "    Args:\n",
    "        text (any): The input text to clean.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text.\n",
    "    \"\"\"\n",
    "    text = str(text).lower() # Ensure text is string, then lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n",
    "    # Consider other cleaning steps here if needed (e.g., removing specific punctuation, numbers)\n",
    "    # For this project, keeping numbers like \"[1]\" as they might be relevant.\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155e1839",
   "metadata": {},
   "source": [
    "## 2. Data Loading, Initial EDA, and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d63114",
   "metadata": {},
   "source": [
    "### 2.1. Load Raw Sentence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e8c930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.1. Loading Raw Sentence Data ---\n",
      "Successfully loaded and combined NR and TSR sentences.\n",
      "Shape of combined_df: (781, 2)\n",
      "\n",
      "Initial combined_df head:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "condition",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9b3fc019-f061-45e9-b057-14e1580d87cb",
       "rows": [
        [
         "0",
         "Henry Ford (July 30, 1863 - April 7, 1947) was the founder of the Henry Ford Motor Company which later became Cadillac and Ford Motor Company.",
         "NR"
        ],
        [
         "1",
         "Henry Ford, with eleven other investors and $28,000 in capital, incorporated the Ford Motor Company in 1903.",
         "NR"
        ],
        [
         "2",
         "On January 1, 1919, after unsuccessfully seeking a seat in the United States Senate, [1] Henry Ford turned the presidency of Ford Motor Company over to his son Edsel, although still maintaining a firm hand in its management, few company decisions under Edsel's presidency were made without approval by Henry, and those few that were, Henry often reversed.",
         "NR"
        ],
        [
         "3",
         "Henry Ford, with his son Edsel, founded the Ford Foundation in 1936 as a local philanthropic organization with a broad charter to promote human welfare.",
         "NR"
        ],
        [
         "4",
         "After this initial success, Ford left Edison Illuminating and, with other investors, formed the Detroit Automobile Company.",
         "NR"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Henry Ford (July 30, 1863 - April 7, 1947) was...</td>\n",
       "      <td>NR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Henry Ford, with eleven other investors and $2...</td>\n",
       "      <td>NR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On January 1, 1919, after unsuccessfully seeki...</td>\n",
       "      <td>NR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Henry Ford, with his son Edsel, founded the Fo...</td>\n",
       "      <td>NR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After this initial success, Ford left Edison I...</td>\n",
       "      <td>NR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence condition\n",
       "0  Henry Ford (July 30, 1863 - April 7, 1947) was...        NR\n",
       "1  Henry Ford, with eleven other investors and $2...        NR\n",
       "2  On January 1, 1919, after unsuccessfully seeki...        NR\n",
       "3  Henry Ford, with his son Edsel, founded the Fo...        NR\n",
       "4  After this initial success, Ford left Edison I...        NR"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Condition distribution:\n",
      "condition\n",
      "TSR    411\n",
      "NR     370\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of missing sentences: 0\n",
      "Number of duplicate sentences (raw): 85\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 2.1. Loading Raw Sentence Data ---\")\n",
    "nr_sentences_df = load_sentences_from_files(DATA_DIRECTORY, NR_FILE_PATTERN, \"NR\")\n",
    "tsr_sentences_df = load_sentences_from_files(DATA_DIRECTORY, TSR_FILE_PATTERN, \"TSR\")\n",
    "\n",
    "combined_df = pd.DataFrame(columns=['sentence', 'condition']) # Initialize\n",
    "if not nr_sentences_df.empty and not tsr_sentences_df.empty:\n",
    "    combined_df = pd.concat([nr_sentences_df, tsr_sentences_df], ignore_index=True)\n",
    "    print(f\"Successfully loaded and combined NR and TSR sentences.\")\n",
    "    print(f\"Shape of combined_df: {combined_df.shape}\")\n",
    "elif not nr_sentences_df.empty:\n",
    "    combined_df = nr_sentences_df\n",
    "    print(\"Warning: Only NR data was loaded.\")\n",
    "elif not tsr_sentences_df.empty:\n",
    "    combined_df = tsr_sentences_df\n",
    "    print(\"Warning: Only TSR data was loaded.\")\n",
    "else:\n",
    "    print(\"Error: No data was loaded. Please check DATA_DIRECTORY and file patterns.\")\n",
    "\n",
    "if not combined_df.empty:\n",
    "    combined_df['sentence'] = combined_df['sentence'].astype(str) # Ensure sentence column is string\n",
    "    print(\"\\nInitial combined_df head:\")\n",
    "    display(combined_df.head())\n",
    "    print(\"\\nCondition distribution:\")\n",
    "    print(combined_df['condition'].value_counts())\n",
    "    print(f\"\\nNumber of missing sentences: {combined_df['sentence'].isnull().sum()}\")\n",
    "    print(f\"Number of duplicate sentences (raw): {combined_df.duplicated(subset=['sentence']).sum()}\")\n",
    "else:\n",
    "    print(\"Cannot proceed as combined_df is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1cad17",
   "metadata": {},
   "source": [
    "### 2.2. Basic Exploratory Data Analysis (EDA) - Sentence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "def6f06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2.2. Basic Exploratory Data Analysis (Sentence Lengths) ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Statistics for Sentence Lengths (Overall):\n",
      "       char_length  word_length\n",
      "count   781.000000   781.000000\n",
      "mean    122.581306    20.501921\n",
      "std      57.796572     9.388567\n",
      "min      25.000000     5.000000\n",
      "25%      80.000000    13.000000\n",
      "50%     111.000000    19.000000\n",
      "75%     154.000000    25.000000\n",
      "max     355.000000    58.000000\n",
      "\n",
      "Descriptive Statistics for Sentence Lengths (Grouped by Condition):\n",
      "          char_length                                                     \\\n",
      "                count        mean        std   min    25%    50%     75%   \n",
      "condition                                                                  \n",
      "NR              370.0  115.994595  55.278011  25.0  77.25  106.0  142.75   \n",
      "TSR             411.0  128.510949  59.418005  25.0  82.00  118.0  160.00   \n",
      "\n",
      "                 word_length                                                    \n",
      "             max       count       mean       std  min   25%   50%   75%   max  \n",
      "condition                                                                       \n",
      "NR         355.0       370.0  19.467568  8.968495  5.0  13.0  18.0  24.0  58.0  \n",
      "TSR        325.0       411.0  21.433090  9.667763  5.0  14.0  20.0  26.0  53.0  \n"
     ]
    }
   ],
   "source": [
    "if not combined_df.empty:\n",
    "    print(\"\\n--- 2.2. Basic Exploratory Data Analysis (Sentence Lengths) ---\")\n",
    "    combined_df['char_length'] = combined_df['sentence'].apply(len)\n",
    "    combined_df['word_length'] = combined_df['sentence'].apply(lambda x: len(x.split())) # Simple word count\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(data=combined_df, x='char_length', hue='condition', kde=True, bins=30)\n",
    "    plt.title('Character Length Distribution by Condition')\n",
    "    plt.xlabel('Character Length')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(data=combined_df, x='word_length', hue='condition', kde=True, bins=30)\n",
    "    plt.title('Word Length Distribution by Condition')\n",
    "    plt.xlabel('Word Length')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"sentence_length_distributions.png\") # Save the plot\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.boxplot(data=combined_df, x='condition', y='char_length')\n",
    "    plt.title('Character Length by Condition (Boxplot)')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(data=combined_df, x='condition', y='word_length')\n",
    "    plt.title('Word Length by Condition (Boxplot)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"sentence_length_boxplots.png\") # Save the plot\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nDescriptive Statistics for Sentence Lengths (Overall):\")\n",
    "    print(combined_df[['char_length', 'word_length']].describe())\n",
    "    print(\"\\nDescriptive Statistics for Sentence Lengths (Grouped by Condition):\")\n",
    "    print(combined_df.groupby('condition')[['char_length', 'word_length']].describe())\n",
    "else:\n",
    "    print(\"Skipping EDA as combined_df is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43841a1e",
   "metadata": {},
   "source": [
    "### 2.3. Data Preprocessing: Unique Sentences, Cleaning, and Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3839e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2.3. Data Preprocessing ---\n",
      "Number of unique NR sentences: 365\n",
      "Number of unique TSR sentences: 392\n",
      "Number of sentences common to both unique NR and TSR lists: 61\n",
      "\n",
      "Shape of the final processed dataset (df_processed): (635, 4)\n",
      "Distribution of conditions in the final processed dataset:\n",
      "label\n",
      "1    0.52126\n",
      "0    0.47874\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Processed dataset saved to: zuco_processed_sentences.csv\n",
      "\n",
      "Head of df_processed:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "condition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cleaned_sentence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f4540f52-a409-4b35-a396-cc2e65ed9b11",
       "rows": [
        [
         "0",
         "Through his son Timothy Bush, Jr., who was also a blacksmith, descended two American Presidents -George H. W. Bush and George W. Bush.",
         "NR",
         "through his son timothy bush, jr., who was also a blacksmith, descended two american presidents -george h. w. bush and george w. bush.",
         "0"
        ],
        [
         "1",
         "Kerouac's spontaneous, confessional language style inspired other writers, including Tom Robbins, Richard Brautigan, Hunter S. Thompson, Ken Kesey, and Bob Dylan.",
         "NR",
         "kerouac's spontaneous, confessional language style inspired other writers, including tom robbins, richard brautigan, hunter s. thompson, ken kesey, and bob dylan.",
         "0"
        ],
        [
         "2",
         "Lawford later admitted the most terrifying experience of his career was the first musical number he performed.",
         "NR",
         "lawford later admitted the most terrifying experience of his career was the first musical number he performed.",
         "0"
        ],
        [
         "3",
         "They had four children: Frederick Dent Grant, Ulysses S. (Buck) Grant, Jr., Ellen (Nellie) Grant, and Jesse Root Grant.",
         "NR",
         "they had four children: frederick dent grant, ulysses s. (buck) grant, jr., ellen (nellie) grant, and jesse root grant.",
         "0"
        ],
        [
         "4",
         "He received his bachelor's degree in 1965 and master's degree in political science in 1966 both from the University of Wyoming.",
         "NR",
         "he received his bachelor's degree in 1965 and master's degree in political science in 1966 both from the university of wyoming.",
         "0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>condition</th>\n",
       "      <th>cleaned_sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Through his son Timothy Bush, Jr., who was als...</td>\n",
       "      <td>NR</td>\n",
       "      <td>through his son timothy bush, jr., who was als...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kerouac's spontaneous, confessional language s...</td>\n",
       "      <td>NR</td>\n",
       "      <td>kerouac's spontaneous, confessional language s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lawford later admitted the most terrifying exp...</td>\n",
       "      <td>NR</td>\n",
       "      <td>lawford later admitted the most terrifying exp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They had four children: Frederick Dent Grant, ...</td>\n",
       "      <td>NR</td>\n",
       "      <td>they had four children: frederick dent grant, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He received his bachelor's degree in 1965 and ...</td>\n",
       "      <td>NR</td>\n",
       "      <td>he received his bachelor's degree in 1965 and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence condition  \\\n",
       "0  Through his son Timothy Bush, Jr., who was als...        NR   \n",
       "1  Kerouac's spontaneous, confessional language s...        NR   \n",
       "2  Lawford later admitted the most terrifying exp...        NR   \n",
       "3  They had four children: Frederick Dent Grant, ...        NR   \n",
       "4  He received his bachelor's degree in 1965 and ...        NR   \n",
       "\n",
       "                                    cleaned_sentence  label  \n",
       "0  through his son timothy bush, jr., who was als...      0  \n",
       "1  kerouac's spontaneous, confessional language s...      0  \n",
       "2  lawford later admitted the most terrifying exp...      0  \n",
       "3  they had four children: frederick dent grant, ...      0  \n",
       "4  he received his bachelor's degree in 1965 and ...      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_processed = pd.DataFrame() # Initialize\n",
    "\n",
    "if not nr_sentences_df.empty and not tsr_sentences_df.empty:\n",
    "    print(\"\\n--- 2.3. Data Preprocessing ---\")\n",
    "    # Get unique sentences for each condition\n",
    "    nr_unique_sentences_list = nr_sentences_df['sentence'].drop_duplicates().tolist()\n",
    "    tsr_unique_sentences_list = tsr_sentences_df['sentence'].drop_duplicates().tolist()\n",
    "\n",
    "    print(f\"Number of unique NR sentences: {len(nr_unique_sentences_list)}\")\n",
    "    print(f\"Number of unique TSR sentences: {len(tsr_unique_sentences_list)}\")\n",
    "\n",
    "    # Find sentences common to both unique lists\n",
    "    common_sentences_set = set(nr_unique_sentences_list).intersection(set(tsr_unique_sentences_list))\n",
    "    print(f\"Number of sentences common to both unique NR and TSR lists: {len(common_sentences_set)}\")\n",
    "\n",
    "    # Create DataFrames with only unique sentences for each condition, excluding common ones\n",
    "    df_nr_only = pd.DataFrame({\n",
    "        'sentence': list(set(nr_unique_sentences_list) - common_sentences_set),\n",
    "        'condition': 'NR'\n",
    "    })\n",
    "    df_tsr_only = pd.DataFrame({\n",
    "        'sentence': list(set(tsr_unique_sentences_list) - common_sentences_set),\n",
    "        'condition': 'TSR'\n",
    "    })\n",
    "\n",
    "    df_processed = pd.concat([df_nr_only, df_tsr_only], ignore_index=True)\n",
    "\n",
    "    # Apply text cleaning\n",
    "    df_processed['cleaned_sentence'] = df_processed['sentence'].apply(clean_text)\n",
    "\n",
    "    # Remove duplicates that might have arisen *after* cleaning\n",
    "    df_processed.drop_duplicates(subset=['cleaned_sentence'], keep='first', inplace=True)\n",
    "    df_processed.reset_index(drop=True, inplace=True) # Reset index after dropping duplicates\n",
    "\n",
    "    # Encode labels\n",
    "    df_processed['label'] = df_processed['condition'].apply(lambda x: 0 if x == 'NR' else 1) # NR:0, TSR:1\n",
    "\n",
    "    print(f\"\\nShape of the final processed dataset (df_processed): {df_processed.shape}\")\n",
    "    print(\"Distribution of conditions in the final processed dataset:\")\n",
    "    print(df_processed['label'].value_counts(normalize=True)) # Show normalized counts for balance\n",
    "\n",
    "    # Save the processed DataFrame\n",
    "    try:\n",
    "        df_processed.to_csv(PROCESSED_DATA_FILENAME, index=False)\n",
    "        print(f\"\\nProcessed dataset saved to: {PROCESSED_DATA_FILENAME}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving processed dataset: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping preprocessing as NR or TSR data is missing or empty.\")\n",
    "\n",
    "# Display head of the final processed data\n",
    "if not df_processed.empty:\n",
    "    print(\"\\nHead of df_processed:\")\n",
    "    display(df_processed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e54854",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95439d7e",
   "metadata": {},
   "source": [
    "### 3.1. Feature Engineering Strategy\n",
    "\n",
    "**Strategy Overview:**\n",
    "Two primary feature engineering strategies will be implemented, and their performance will be compared using the F1-score for the TSR class (label 1) as the main metric, alongside accuracy and macro F1-score.\n",
    "\n",
    "\n",
    "**Option A: Sentence Embeddings (LLM-based)**\n",
    "- **Approach**: Use a pre-trained sentence transformer (e.g., `all-MiniLM-L6-v2`) to generate dense vector representations.\n",
    "- **Rationale**: Captures rich semantic and syntactic information, making it suitable for subtle distinctions in text.\n",
    "\n",
    "**Option B: Discrete Linguistic Features & (Optionally) Locally-Generated LLM Metrics**\n",
    "- **Extracted Features**:\n",
    "    - **Basic Text Statistics**: Character length, word count, average word length.\n",
    "    - **Lexical Features**: Type-Token Ratio (TTR), Lexical Density (proxy).\n",
    "    - **Readability Scores**: Flesch Reading Ease, Flesch-Kincaid Grade, Gunning Fog Index (via `textstat`).\n",
    "    - **Syntactic Complexity Features**: \n",
    "        - Number of subordinate/conjunctive clauses (simplified).\n",
    "        - Average/max dependency distance.\n",
    "        - POS tag counts (verbs, nouns, adjectives, adverbs, prepositions, conjunctions) using `spaCy`.\n",
    "    - **(Experimental/Optional) Locally-Generated LLM Metrics**: \n",
    "        - Proxy for perplexity or prompt-based complexity rating (using `Ollama` with models like `llama3`).\n",
    "        - Note: Computationally intensive with variable results.\n",
    "- **Rationale**: Offers interpretability and highlights specific structural/lexical differences. Local LLM metrics explore model-perceived complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06570f5",
   "metadata": {},
   "source": [
    "### 3.2. Option A: Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fe96ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3.2.1. Loading saved sentence embeddings from sentence_embeddings.npy ---\n",
      "Loaded sentence embeddings. Shape: (635, 384)\n"
     ]
    }
   ],
   "source": [
    "# --- Option A: Sentence Embeddings ---\n",
    "sentence_embeddings_array = np.array([]) # Initialize\n",
    "\n",
    "# Try to load saved embeddings first\n",
    "if os.path.exists(EMBEDDINGS_FILENAME_NP):\n",
    "    print(f\"--- 3.2.1. Loading saved sentence embeddings from {EMBEDDINGS_FILENAME_NP} ---\")\n",
    "    sentence_embeddings_array = np.load(EMBEDDINGS_FILENAME_NP)\n",
    "    print(f\"Loaded sentence embeddings. Shape: {sentence_embeddings_array.shape}\")\n",
    "    # Ensure the loaded embeddings match the current df_processed length\n",
    "    if not df_processed.empty and sentence_embeddings_array.shape[0] != len(df_processed):\n",
    "        print(f\"Warning: Loaded embeddings shape {sentence_embeddings_array.shape} \"\n",
    "              f\"does not match df_processed length {len(df_processed)}. Will regenerate.\")\n",
    "        sentence_embeddings_array = np.array([]) # Force regeneration\n",
    "elif not df_processed.empty and 'cleaned_sentence' in df_processed.columns:\n",
    "    print(\"\\n--- 3.2.1. Generating Sentence Embeddings (Option A) ---\")\n",
    "    try:\n",
    "        # Use a robust, freely available sentence transformer model\n",
    "        embedding_model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu') # Specify CPU if GPU issues\n",
    "        sentences_to_embed = df_processed['cleaned_sentence'].tolist()\n",
    "\n",
    "        if not any(s.strip() for s in sentences_to_embed): # Check if all sentences are empty/whitespace\n",
    "            print(\"Warning: No valid sentences to embed for Option A.\")\n",
    "        else:\n",
    "            print(f\"Embedding {len(sentences_to_embed)} sentences...\")\n",
    "            sentence_embeddings_array = embedding_model.encode(sentences_to_embed, show_progress_bar=True)\n",
    "            print(f\"Shape of generated sentence embeddings: {sentence_embeddings_array.shape}\")\n",
    "            # Save the generated embeddings\n",
    "            try:\n",
    "                np.save(EMBEDDINGS_FILENAME_NP, sentence_embeddings_array)\n",
    "                print(f\"Sentence embeddings saved to: {EMBEDDINGS_FILENAME_NP}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving sentence embeddings: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating sentence embeddings: {e}\")\n",
    "else:\n",
    "    print(\"Skipping Option A (Sentence Embeddings) as processed data is unavailable.\")\n",
    "\n",
    "if sentence_embeddings_array.size == 0 and not df_processed.empty:\n",
    "     print(\"Warning: Sentence embeddings array is empty. Subsequent steps using embeddings might fail.\")\n",
    "elif not df_processed.empty and sentence_embeddings_array.shape[0] != len(df_processed):\n",
    "    print(f\"Critical Error: Embeddings shape {sentence_embeddings_array.shape} does not match df_processed length {len(df_processed)} even after attempting regeneration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d077f421",
   "metadata": {},
   "source": [
    "### 3.3. Option B: Discrete Linguistic Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e89656",
   "metadata": {},
   "source": [
    "#### 3.3.1. Base Discrete Features (Text Stats, Lexical, Readability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3e05d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3.3.1. Loading saved base discrete features from base_discrete_features.csv ---\n",
      "Loaded base discrete features. Shape: (635, 8)\n",
      "\n",
      "Head of df_base_discrete_features:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "char_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "word_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "avg_word_length",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ttr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lex_density_proxy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4161389b-8ec8-4107-bfda-ccd20e606075",
       "rows": [
        [
         "0",
         "168",
         "27",
         "6.222222222222222",
         "0.8333333333333334",
         "0.2666666666666666",
         "32.163333333333355",
         "15.480740740740742",
         "18.20740740740741"
        ],
        [
         "1",
         "126",
         "22",
         "5.727272727272728",
         "0.8928571428571429",
         "0.25",
         "34.532272727272726",
         "13.90818181818182",
         "17.89090909090909"
        ],
        [
         "2",
         "157",
         "25",
         "6.28",
         "0.925925925925926",
         "0.2592592592592592",
         "46.10000000000002",
         "13.040000000000004",
         "19.6"
        ],
        [
         "3",
         "195",
         "31",
         "6.290322580645161",
         "0.8571428571428571",
         "0.2857142857142857",
         "36.18935483870968",
         "15.912903225806453",
         "16.270967741935486"
        ],
        [
         "4",
         "90",
         "16",
         "5.625",
         "0.8947368421052632",
         "0.2105263157894736",
         "68.9825",
         "7.612500000000001",
         "6.4"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>ttr</th>\n",
       "      <th>lex_density_proxy</th>\n",
       "      <th>flesch_ease</th>\n",
       "      <th>flesch_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>168</td>\n",
       "      <td>27</td>\n",
       "      <td>6.222222</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>32.163333</td>\n",
       "      <td>15.480741</td>\n",
       "      <td>18.207407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>22</td>\n",
       "      <td>5.727273</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>34.532273</td>\n",
       "      <td>13.908182</td>\n",
       "      <td>17.890909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157</td>\n",
       "      <td>25</td>\n",
       "      <td>6.280000</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>46.100000</td>\n",
       "      <td>13.040000</td>\n",
       "      <td>19.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "      <td>31</td>\n",
       "      <td>6.290323</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>36.189355</td>\n",
       "      <td>15.912903</td>\n",
       "      <td>16.270968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>16</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>68.982500</td>\n",
       "      <td>7.612500</td>\n",
       "      <td>6.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count  word_count  avg_word_length       ttr  lex_density_proxy  \\\n",
       "0         168          27         6.222222  0.833333           0.266667   \n",
       "1         126          22         5.727273  0.892857           0.250000   \n",
       "2         157          25         6.280000  0.925926           0.259259   \n",
       "3         195          31         6.290323  0.857143           0.285714   \n",
       "4          90          16         5.625000  0.894737           0.210526   \n",
       "\n",
       "   flesch_ease  flesch_grade  gunning_fog  \n",
       "0    32.163333     15.480741    18.207407  \n",
       "1    34.532273     13.908182    17.890909  \n",
       "2    46.100000     13.040000    19.600000  \n",
       "3    36.189355     15.912903    16.270968  \n",
       "4    68.982500      7.612500     6.400000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Description of df_base_discrete_features:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "char_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "word_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_word_length",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ttr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lex_density_proxy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7eef3564-b31d-41d6-9903-a10db886e3b0",
       "rows": [
        [
         "count",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0"
        ],
        [
         "mean",
         "126.54803149606299",
         "21.064566929133857",
         "6.001505578902042",
         "0.899012328431195",
         "0.22986365681413848",
         "48.454157757615995",
         "11.55499598087992",
         "13.729520948645886"
        ],
        [
         "std",
         "59.50788306392519",
         "9.671118076602415",
         "0.5979520919042367",
         "0.08311206737048588",
         "0.08546088409217244",
         "24.074463067153996",
         "4.46851981602659",
         "5.10165876734378"
        ],
        [
         "min",
         "27.0",
         "5.0",
         "4.285714285714286",
         "0.6140350877192983",
         "0.0",
         "-27.89999999999995",
         "-1.0599999999999987",
         "2.2"
        ],
        [
         "25%",
         "82.5",
         "14.0",
         "5.6",
         "0.8481554677206851",
         "0.17316341829085455",
         "33.465",
         "8.544545454545453",
         "10.0"
        ],
        [
         "50%",
         "116.0",
         "20.0",
         "5.973684210526316",
         "0.9090909090909092",
         "0.2307692307692307",
         "47.45500000000003",
         "11.16941176470588",
         "13.866666666666667"
        ],
        [
         "75%",
         "159.0",
         "26.0",
         "6.388888888888889",
         "0.9565217391304348",
         "0.2857142857142857",
         "61.99869565217393",
         "14.371803069053712",
         "16.914285714285715"
        ],
        [
         "max",
         "355.0",
         "58.0",
         "8.88888888888889",
         "1.0",
         "0.5555555555555556",
         "200.0",
         "27.37482758620689",
         "30.596078431372547"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>ttr</th>\n",
       "      <th>lex_density_proxy</th>\n",
       "      <th>flesch_ease</th>\n",
       "      <th>flesch_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>126.548031</td>\n",
       "      <td>21.064567</td>\n",
       "      <td>6.001506</td>\n",
       "      <td>0.899012</td>\n",
       "      <td>0.229864</td>\n",
       "      <td>48.454158</td>\n",
       "      <td>11.554996</td>\n",
       "      <td>13.729521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>59.507883</td>\n",
       "      <td>9.671118</td>\n",
       "      <td>0.597952</td>\n",
       "      <td>0.083112</td>\n",
       "      <td>0.085461</td>\n",
       "      <td>24.074463</td>\n",
       "      <td>4.468520</td>\n",
       "      <td>5.101659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-27.900000</td>\n",
       "      <td>-1.060000</td>\n",
       "      <td>2.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>82.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.848155</td>\n",
       "      <td>0.173163</td>\n",
       "      <td>33.465000</td>\n",
       "      <td>8.544545</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.973684</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>47.455000</td>\n",
       "      <td>11.169412</td>\n",
       "      <td>13.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>159.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>6.388889</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>61.998696</td>\n",
       "      <td>14.371803</td>\n",
       "      <td>16.914286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>355.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>8.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>27.374828</td>\n",
       "      <td>30.596078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       char_count  word_count  avg_word_length         ttr  lex_density_proxy  \\\n",
       "count  635.000000  635.000000       635.000000  635.000000         635.000000   \n",
       "mean   126.548031   21.064567         6.001506    0.899012           0.229864   \n",
       "std     59.507883    9.671118         0.597952    0.083112           0.085461   \n",
       "min     27.000000    5.000000         4.285714    0.614035           0.000000   \n",
       "25%     82.500000   14.000000         5.600000    0.848155           0.173163   \n",
       "50%    116.000000   20.000000         5.973684    0.909091           0.230769   \n",
       "75%    159.000000   26.000000         6.388889    0.956522           0.285714   \n",
       "max    355.000000   58.000000         8.888889    1.000000           0.555556   \n",
       "\n",
       "       flesch_ease  flesch_grade  gunning_fog  \n",
       "count   635.000000    635.000000   635.000000  \n",
       "mean     48.454158     11.554996    13.729521  \n",
       "std      24.074463      4.468520     5.101659  \n",
       "min     -27.900000     -1.060000     2.200000  \n",
       "25%      33.465000      8.544545    10.000000  \n",
       "50%      47.455000     11.169412    13.866667  \n",
       "75%      61.998696     14.371803    16.914286  \n",
       "max     200.000000     27.374828    30.596078  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_base_discrete_features = pd.DataFrame() # Initialize\n",
    "\n",
    "# Try to load saved base discrete features first\n",
    "if os.path.exists(BASE_DISCRETE_FEATURES_FILENAME_CSV):\n",
    "    print(f\"\\n--- 3.3.1. Loading saved base discrete features from {BASE_DISCRETE_FEATURES_FILENAME_CSV} ---\")\n",
    "    df_base_discrete_features = pd.read_csv(BASE_DISCRETE_FEATURES_FILENAME_CSV)\n",
    "    print(f\"Loaded base discrete features. Shape: {df_base_discrete_features.shape}\")\n",
    "    if not df_processed.empty and len(df_base_discrete_features) != len(df_processed):\n",
    "        print(f\"Warning: Loaded base discrete features length {len(df_base_discrete_features)} \"\n",
    "              f\"does not match df_processed length {len(df_processed)}. Will regenerate.\")\n",
    "        df_base_discrete_features = pd.DataFrame() # Force regeneration\n",
    "elif not df_processed.empty and 'cleaned_sentence' in df_processed.columns:\n",
    "    print(\"\\n--- 3.3.1. Generating Base Discrete Linguistic Features (Option B) ---\")\n",
    "    df_base_discrete_features = pd.DataFrame(index=df_processed.index) # Align with df_processed\n",
    "\n",
    "    # 1. Basic Text Statistics\n",
    "    df_base_discrete_features['char_count'] = df_processed['cleaned_sentence'].apply(len)\n",
    "    df_base_discrete_features['word_count'] = df_processed['cleaned_sentence'].apply(lambda x: len(x.split()))\n",
    "    # Avoid division by zero for avg_word_length\n",
    "    df_base_discrete_features['avg_word_length'] = df_base_discrete_features['char_count'] / \\\n",
    "                                              df_base_discrete_features['word_count'].replace(0, np.nan) # Use NaN for 0 words\n",
    "\n",
    "    # 2. Lexical Features\n",
    "    def type_token_ratio(text):\n",
    "        tokens = word_tokenize(text) # Using nltk.word_tokenize for better tokenization\n",
    "        return len(set(tokens)) / len(tokens) if tokens else 0\n",
    "    df_base_discrete_features['ttr'] = df_processed['cleaned_sentence'].apply(type_token_ratio)\n",
    "\n",
    "    def lexical_density_proxy(text):\n",
    "        tokens = word_tokenize(text)\n",
    "        # Basic proxy: ratio of words longer than 6 chars (often content words)\n",
    "        return sum(1 for word in tokens if len(word) > 6) / len(tokens) if tokens else 0\n",
    "    df_base_discrete_features['lex_density_proxy'] = df_processed['cleaned_sentence'].apply(lexical_density_proxy)\n",
    "\n",
    "    # 3. Readability Scores (using textstat)\n",
    "    def get_safe_readability_score(text, func, default_val=0.0):\n",
    "        \"\"\"Safely computes readability score, handling empty or very short texts.\"\"\"\n",
    "        if text and len(text.split()) > 5: # textstat might need a minimum number of words\n",
    "            try:\n",
    "                return float(func(text))\n",
    "            except: # Catch any error from textstat\n",
    "                return float(default_val)\n",
    "        return float(default_val)\n",
    "\n",
    "    df_base_discrete_features['flesch_ease'] = df_processed['cleaned_sentence'].apply(\n",
    "        lambda x: get_safe_readability_score(x, textstat.flesch_reading_ease, default_val=200.0)) # Higher is easier\n",
    "    df_base_discrete_features['flesch_grade'] = df_processed['cleaned_sentence'].apply(\n",
    "        lambda x: get_safe_readability_score(x, textstat.flesch_kincaid_grade, default_val=20.0)) # Higher is harder\n",
    "    df_base_discrete_features['gunning_fog'] = df_processed['cleaned_sentence'].apply(\n",
    "        lambda x: get_safe_readability_score(x, textstat.gunning_fog, default_val=20.0)) # Higher is harder\n",
    "\n",
    "    # Handle potential NaN/inf values robustly (e.g., from avg_word_length if word_count was 0)\n",
    "    df_base_discrete_features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    # Impute NaNs - using median is often more robust to outliers than mean for these types of features\n",
    "    for col in df_base_discrete_features.columns:\n",
    "        if df_base_discrete_features[col].isnull().any():\n",
    "            df_base_discrete_features[col].fillna(df_base_discrete_features[col].median(), inplace=True)\n",
    "    df_base_discrete_features.fillna(0, inplace=True) # Catch-all for any remaining NaNs (e.g., if all values were NaN)\n",
    "\n",
    "    print(f\"Base discrete linguistic features generated. Shape: {df_base_discrete_features.shape}\")\n",
    "    try:\n",
    "        df_base_discrete_features.to_csv(BASE_DISCRETE_FEATURES_FILENAME_CSV, index=False)\n",
    "        print(f\"Base discrete features saved to: {BASE_DISCRETE_FEATURES_FILENAME_CSV}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving base discrete features: {e}\")\n",
    "else:\n",
    "    print(\"Skipping Base Discrete Feature extraction as processed data is unavailable.\")\n",
    "\n",
    "if not df_base_discrete_features.empty:\n",
    "    print(\"\\nHead of df_base_discrete_features:\")\n",
    "    display(df_base_discrete_features.head())\n",
    "    print(\"\\nDescription of df_base_discrete_features:\")\n",
    "    display(df_base_discrete_features.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5f1d3d",
   "metadata": {},
   "source": [
    "#### 3.3.2. Enhanced Discrete Features (Syntactic with spaCy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9f55f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3.3.2. Loading saved ENHANCED discrete features from enhanced_discrete_features.csv ---\n",
      "Loaded ENHANCED discrete features. Shape: (635, 18)\n",
      "\n",
      "Head of df_enhanced_discrete_features:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "char_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "word_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "avg_word_length",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ttr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lex_density_proxy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_subord_clauses",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_conj_clauses",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "avg_dep_dist",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "max_dep_dist",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_verbs",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_nouns",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_adjectives",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_adverbs",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_prepositions",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_conjunctions",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0a7c44ba-8fe8-4cd1-9d5e-c33fc2f46c38",
       "rows": [
        [
         "0",
         "168",
         "27",
         "6.222222222222222",
         "0.8333333333333334",
         "0.2666666666666666",
         "32.163333333333355",
         "15.480740740740742",
         "18.20740740740741",
         "1",
         "0",
         "2.933333333333333",
         "22",
         "3",
         "9",
         "2",
         "1",
         "3",
         "4"
        ],
        [
         "1",
         "126",
         "22",
         "5.727272727272728",
         "0.8928571428571429",
         "0.25",
         "34.532272727272726",
         "13.90818181818182",
         "17.89090909090909",
         "0",
         "0",
         "2.607142857142857",
         "13",
         "3",
         "8",
         "1",
         "2",
         "4",
         "0"
        ],
        [
         "2",
         "157",
         "25",
         "6.28",
         "0.925925925925926",
         "0.2592592592592592",
         "46.10000000000002",
         "13.040000000000004",
         "19.6",
         "0",
         "0",
         "3.129032258064516",
         "28",
         "4",
         "8",
         "1",
         "0",
         "5",
         "0"
        ],
        [
         "3",
         "195",
         "31",
         "6.290322580645161",
         "0.8571428571428571",
         "0.2857142857142857",
         "36.18935483870968",
         "15.912903225806453",
         "16.270967741935486",
         "0",
         "0",
         "2.742857142857143",
         "31",
         "4",
         "13",
         "0",
         "0",
         "6",
         "1"
        ],
        [
         "4",
         "90",
         "16",
         "5.625",
         "0.8947368421052632",
         "0.2105263157894736",
         "68.9825",
         "7.612500000000001",
         "6.4",
         "0",
         "0",
         "2.736842105263158",
         "15",
         "2",
         "8",
         "0",
         "0",
         "1",
         "1"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>ttr</th>\n",
       "      <th>lex_density_proxy</th>\n",
       "      <th>flesch_ease</th>\n",
       "      <th>flesch_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>num_subord_clauses</th>\n",
       "      <th>num_conj_clauses</th>\n",
       "      <th>avg_dep_dist</th>\n",
       "      <th>max_dep_dist</th>\n",
       "      <th>num_verbs</th>\n",
       "      <th>num_nouns</th>\n",
       "      <th>num_adjectives</th>\n",
       "      <th>num_adverbs</th>\n",
       "      <th>num_prepositions</th>\n",
       "      <th>num_conjunctions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>168</td>\n",
       "      <td>27</td>\n",
       "      <td>6.222222</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>32.163333</td>\n",
       "      <td>15.480741</td>\n",
       "      <td>18.207407</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>22</td>\n",
       "      <td>5.727273</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>34.532273</td>\n",
       "      <td>13.908182</td>\n",
       "      <td>17.890909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.607143</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157</td>\n",
       "      <td>25</td>\n",
       "      <td>6.280000</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>46.100000</td>\n",
       "      <td>13.040000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.129032</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "      <td>31</td>\n",
       "      <td>6.290323</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>36.189355</td>\n",
       "      <td>15.912903</td>\n",
       "      <td>16.270968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.742857</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>16</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>68.982500</td>\n",
       "      <td>7.612500</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.736842</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count  word_count  avg_word_length       ttr  lex_density_proxy  \\\n",
       "0         168          27         6.222222  0.833333           0.266667   \n",
       "1         126          22         5.727273  0.892857           0.250000   \n",
       "2         157          25         6.280000  0.925926           0.259259   \n",
       "3         195          31         6.290323  0.857143           0.285714   \n",
       "4          90          16         5.625000  0.894737           0.210526   \n",
       "\n",
       "   flesch_ease  flesch_grade  gunning_fog  num_subord_clauses  \\\n",
       "0    32.163333     15.480741    18.207407                   1   \n",
       "1    34.532273     13.908182    17.890909                   0   \n",
       "2    46.100000     13.040000    19.600000                   0   \n",
       "3    36.189355     15.912903    16.270968                   0   \n",
       "4    68.982500      7.612500     6.400000                   0   \n",
       "\n",
       "   num_conj_clauses  avg_dep_dist  max_dep_dist  num_verbs  num_nouns  \\\n",
       "0                 0      2.933333            22          3          9   \n",
       "1                 0      2.607143            13          3          8   \n",
       "2                 0      3.129032            28          4          8   \n",
       "3                 0      2.742857            31          4         13   \n",
       "4                 0      2.736842            15          2          8   \n",
       "\n",
       "   num_adjectives  num_adverbs  num_prepositions  num_conjunctions  \n",
       "0               2            1                 3                 4  \n",
       "1               1            2                 4                 0  \n",
       "2               1            0                 5                 0  \n",
       "3               0            0                 6                 1  \n",
       "4               0            0                 1                 1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Description of df_enhanced_discrete_features:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "char_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "word_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_word_length",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ttr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lex_density_proxy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_subord_clauses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_conj_clauses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_dep_dist",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "max_dep_dist",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_verbs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_nouns",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_adjectives",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_adverbs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_prepositions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_conjunctions",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d3a01e0e-b34c-43e2-a9f5-a99aafdc28d0",
       "rows": [
        [
         "count",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0"
        ],
        [
         "mean",
         "126.54803149606299",
         "21.064566929133857",
         "6.001505578902042",
         "0.899012328431195",
         "0.22986365681413848",
         "48.454157757615995",
         "11.55499598087992",
         "13.729520948645886",
         "0.12440944881889764",
         "0.2614173228346457",
         "3.037494198560913",
         "17.938582677165353",
         "1.9291338582677164",
         "7.870866141732283",
         "1.552755905511811",
         "0.573228346456693",
         "2.8913385826771654",
         "0.9795275590551181"
        ],
        [
         "std",
         "59.50788306392519",
         "9.671118076602415",
         "0.5979520919042367",
         "0.08311206737048588",
         "0.08546088409217244",
         "24.074463067153996",
         "4.46851981602659",
         "5.10165876734378",
         "0.3792148071240425",
         "0.5064329459282128",
         "0.7329207109711102",
         "9.85851044894406",
         "1.3995329457647046",
         "4.428081280052084",
         "1.4203249046065725",
         "0.8695196849272407",
         "2.117041550044101",
         "0.9487945683415242"
        ],
        [
         "min",
         "27.0",
         "5.0",
         "4.285714285714286",
         "0.6140350877192983",
         "0.0",
         "-27.89999999999995",
         "-1.0599999999999987",
         "2.2",
         "0.0",
         "0.0",
         "1.3333333333333333",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "25%",
         "82.5",
         "14.0",
         "5.6",
         "0.8481554677206851",
         "0.17316341829085455",
         "33.465",
         "8.544545454545453",
         "10.0",
         "0.0",
         "0.0",
         "2.5250626566416043",
         "11.0",
         "1.0",
         "5.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0"
        ],
        [
         "50%",
         "116.0",
         "20.0",
         "5.973684210526316",
         "0.9090909090909092",
         "0.2307692307692307",
         "47.45500000000003",
         "11.16941176470588",
         "13.866666666666667",
         "0.0",
         "0.0",
         "2.942857142857143",
         "15.0",
         "2.0",
         "7.0",
         "1.0",
         "0.0",
         "3.0",
         "1.0"
        ],
        [
         "75%",
         "159.0",
         "26.0",
         "6.388888888888889",
         "0.9565217391304348",
         "0.2857142857142857",
         "61.99869565217393",
         "14.371803069053712",
         "16.914285714285715",
         "0.0",
         "0.0",
         "3.450956937799043",
         "22.0",
         "3.0",
         "10.5",
         "2.0",
         "1.0",
         "4.0",
         "2.0"
        ],
        [
         "max",
         "355.0",
         "58.0",
         "8.88888888888889",
         "1.0",
         "0.5555555555555556",
         "200.0",
         "27.37482758620689",
         "30.596078431372547",
         "3.0",
         "3.0",
         "6.711864406779661",
         "61.0",
         "9.0",
         "25.0",
         "8.0",
         "7.0",
         "13.0",
         "4.0"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>ttr</th>\n",
       "      <th>lex_density_proxy</th>\n",
       "      <th>flesch_ease</th>\n",
       "      <th>flesch_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>num_subord_clauses</th>\n",
       "      <th>num_conj_clauses</th>\n",
       "      <th>avg_dep_dist</th>\n",
       "      <th>max_dep_dist</th>\n",
       "      <th>num_verbs</th>\n",
       "      <th>num_nouns</th>\n",
       "      <th>num_adjectives</th>\n",
       "      <th>num_adverbs</th>\n",
       "      <th>num_prepositions</th>\n",
       "      <th>num_conjunctions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>126.548031</td>\n",
       "      <td>21.064567</td>\n",
       "      <td>6.001506</td>\n",
       "      <td>0.899012</td>\n",
       "      <td>0.229864</td>\n",
       "      <td>48.454158</td>\n",
       "      <td>11.554996</td>\n",
       "      <td>13.729521</td>\n",
       "      <td>0.124409</td>\n",
       "      <td>0.261417</td>\n",
       "      <td>3.037494</td>\n",
       "      <td>17.938583</td>\n",
       "      <td>1.929134</td>\n",
       "      <td>7.870866</td>\n",
       "      <td>1.552756</td>\n",
       "      <td>0.573228</td>\n",
       "      <td>2.891339</td>\n",
       "      <td>0.979528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>59.507883</td>\n",
       "      <td>9.671118</td>\n",
       "      <td>0.597952</td>\n",
       "      <td>0.083112</td>\n",
       "      <td>0.085461</td>\n",
       "      <td>24.074463</td>\n",
       "      <td>4.468520</td>\n",
       "      <td>5.101659</td>\n",
       "      <td>0.379215</td>\n",
       "      <td>0.506433</td>\n",
       "      <td>0.732921</td>\n",
       "      <td>9.858510</td>\n",
       "      <td>1.399533</td>\n",
       "      <td>4.428081</td>\n",
       "      <td>1.420325</td>\n",
       "      <td>0.869520</td>\n",
       "      <td>2.117042</td>\n",
       "      <td>0.948795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-27.900000</td>\n",
       "      <td>-1.060000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>82.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.848155</td>\n",
       "      <td>0.173163</td>\n",
       "      <td>33.465000</td>\n",
       "      <td>8.544545</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.525063</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.973684</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>47.455000</td>\n",
       "      <td>11.169412</td>\n",
       "      <td>13.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.942857</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>159.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>6.388889</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>61.998696</td>\n",
       "      <td>14.371803</td>\n",
       "      <td>16.914286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.450957</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>355.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>8.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>27.374828</td>\n",
       "      <td>30.596078</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.711864</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       char_count  word_count  avg_word_length         ttr  lex_density_proxy  \\\n",
       "count  635.000000  635.000000       635.000000  635.000000         635.000000   \n",
       "mean   126.548031   21.064567         6.001506    0.899012           0.229864   \n",
       "std     59.507883    9.671118         0.597952    0.083112           0.085461   \n",
       "min     27.000000    5.000000         4.285714    0.614035           0.000000   \n",
       "25%     82.500000   14.000000         5.600000    0.848155           0.173163   \n",
       "50%    116.000000   20.000000         5.973684    0.909091           0.230769   \n",
       "75%    159.000000   26.000000         6.388889    0.956522           0.285714   \n",
       "max    355.000000   58.000000         8.888889    1.000000           0.555556   \n",
       "\n",
       "       flesch_ease  flesch_grade  gunning_fog  num_subord_clauses  \\\n",
       "count   635.000000    635.000000   635.000000          635.000000   \n",
       "mean     48.454158     11.554996    13.729521            0.124409   \n",
       "std      24.074463      4.468520     5.101659            0.379215   \n",
       "min     -27.900000     -1.060000     2.200000            0.000000   \n",
       "25%      33.465000      8.544545    10.000000            0.000000   \n",
       "50%      47.455000     11.169412    13.866667            0.000000   \n",
       "75%      61.998696     14.371803    16.914286            0.000000   \n",
       "max     200.000000     27.374828    30.596078            3.000000   \n",
       "\n",
       "       num_conj_clauses  avg_dep_dist  max_dep_dist   num_verbs   num_nouns  \\\n",
       "count        635.000000    635.000000    635.000000  635.000000  635.000000   \n",
       "mean           0.261417      3.037494     17.938583    1.929134    7.870866   \n",
       "std            0.506433      0.732921      9.858510    1.399533    4.428081   \n",
       "min            0.000000      1.333333      3.000000    0.000000    0.000000   \n",
       "25%            0.000000      2.525063     11.000000    1.000000    5.000000   \n",
       "50%            0.000000      2.942857     15.000000    2.000000    7.000000   \n",
       "75%            0.000000      3.450957     22.000000    3.000000   10.500000   \n",
       "max            3.000000      6.711864     61.000000    9.000000   25.000000   \n",
       "\n",
       "       num_adjectives  num_adverbs  num_prepositions  num_conjunctions  \n",
       "count      635.000000   635.000000        635.000000        635.000000  \n",
       "mean         1.552756     0.573228          2.891339          0.979528  \n",
       "std          1.420325     0.869520          2.117042          0.948795  \n",
       "min          0.000000     0.000000          0.000000          0.000000  \n",
       "25%          1.000000     0.000000          1.000000          0.000000  \n",
       "50%          1.000000     0.000000          3.000000          1.000000  \n",
       "75%          2.000000     1.000000          4.000000          2.000000  \n",
       "max          8.000000     7.000000         13.000000          4.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_enhanced_discrete_features = pd.DataFrame() # Initialize\n",
    "\n",
    "# Try to load saved enhanced discrete features first\n",
    "if os.path.exists(ENHANCED_DISCRETE_FEATURES_FILENAME_CSV):\n",
    "    print(f\"\\n--- 3.3.2. Loading saved ENHANCED discrete features from {ENHANCED_DISCRETE_FEATURES_FILENAME_CSV} ---\")\n",
    "    df_enhanced_discrete_features = pd.read_csv(ENHANCED_DISCRETE_FEATURES_FILENAME_CSV)\n",
    "    print(f\"Loaded ENHANCED discrete features. Shape: {df_enhanced_discrete_features.shape}\")\n",
    "    if not df_processed.empty and len(df_enhanced_discrete_features) != len(df_processed):\n",
    "        print(f\"Warning: Loaded ENHANCED discrete features length {len(df_enhanced_discrete_features)} \"\n",
    "              f\"does not match df_processed length {len(df_processed)}. Will regenerate if base exists.\")\n",
    "        df_enhanced_discrete_features = pd.DataFrame() # Force regeneration path if base exists\n",
    "elif not df_base_discrete_features.empty and not df_processed.empty: # Regenerate if base exists but enhanced doesn't\n",
    "    print(\"\\n--- 3.3.2. Generating ENHANCED Discrete Features (adding spaCy Syntactic) ---\")\n",
    "    df_enhanced_discrete_features = df_base_discrete_features.copy() # Start with base features\n",
    "\n",
    "    try:\n",
    "        # Load spaCy model (small English model)\n",
    "        # Disable unnecessary components for speed if only using parser/tagger\n",
    "        nlp = spacy.load('en_core_web_sm', disable=['ner', 'textcat'])\n",
    "        print(\"spaCy model 'en_core_web_sm' loaded successfully.\")\n",
    "\n",
    "        syntactic_features_list = []\n",
    "        # Process texts in batches using nlp.pipe for efficiency\n",
    "        print(f\"Extracting syntactic features for {len(df_processed)} sentences using spaCy...\")\n",
    "        for doc in nlp.pipe(df_processed['cleaned_sentence'].fillna('').tolist(), batch_size=50):\n",
    "            if not doc or len(doc) == 0: # Handle empty docs after fillna('')\n",
    "                features = {\n",
    "                    'num_subord_clauses': 0, 'num_conj_clauses': 0, 'avg_dep_dist': 0.0,\n",
    "                    'max_dep_dist': 0, 'num_verbs': 0, 'num_nouns': 0, 'num_adjectives': 0,\n",
    "                    'num_adverbs': 0, 'num_prepositions': 0, 'num_conjunctions': 0\n",
    "                }\n",
    "            else:\n",
    "                # Simplified clause counting\n",
    "                num_sconj = sum(1 for token in doc if token.dep_ == 'mark') # Subordinating conjunctions often mark subordinate clauses\n",
    "                num_cconj = sum(1 for token in doc if token.dep_ == 'cc' and token.head.pos_ == 'VERB') # Conjunctions joining verb phrases\n",
    "\n",
    "                dep_distances = [abs(token.i - token.head.i) for token in doc if token.head is not token]\n",
    "\n",
    "                pos_counts = doc.count_by(spacy.attrs.POS)\n",
    "                num_verbs = pos_counts.get(spacy.parts_of_speech.VERB, 0)\n",
    "                num_nouns = pos_counts.get(spacy.parts_of_speech.NOUN, 0) + pos_counts.get(spacy.parts_of_speech.PROPN, 0)\n",
    "                num_adjectives = pos_counts.get(spacy.parts_of_speech.ADJ, 0)\n",
    "                num_adverbs = pos_counts.get(spacy.parts_of_speech.ADV, 0)\n",
    "                num_prepositions = pos_counts.get(spacy.parts_of_speech.ADP, 0) # Adpositions\n",
    "                num_conjunctions = pos_counts.get(spacy.parts_of_speech.CCONJ, 0) + pos_counts.get(spacy.parts_of_speech.SCONJ, 0)\n",
    "\n",
    "                features = {\n",
    "                    'num_subord_clauses': num_sconj,\n",
    "                    'num_conj_clauses': num_cconj,\n",
    "                    'avg_dep_dist': np.mean(dep_distances) if dep_distances else 0.0,\n",
    "                    'max_dep_dist': np.max(dep_distances) if dep_distances else 0,\n",
    "                    'num_verbs': num_verbs,\n",
    "                    'num_nouns': num_nouns,\n",
    "                    'num_adjectives': num_adjectives,\n",
    "                    'num_adverbs': num_adverbs,\n",
    "                    'num_prepositions': num_prepositions,\n",
    "                    'num_conjunctions': num_conjunctions\n",
    "                }\n",
    "            syntactic_features_list.append(features)\n",
    "\n",
    "        df_spacy_features = pd.DataFrame(syntactic_features_list, index=df_processed.index)\n",
    "        df_enhanced_discrete_features = pd.concat([df_enhanced_discrete_features, df_spacy_features], axis=1)\n",
    "\n",
    "        # Clean up NaNs/Infs again after adding new features\n",
    "        df_enhanced_discrete_features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        for col in df_spacy_features.columns: # Only impute newly added columns if needed\n",
    "            if df_enhanced_discrete_features[col].isnull().any():\n",
    "                 df_enhanced_discrete_features[col].fillna(df_enhanced_discrete_features[col].median(), inplace=True)\n",
    "        df_enhanced_discrete_features.fillna(0, inplace=True)\n",
    "\n",
    "        print(f\"spaCy syntactic features added. Shape of df_enhanced_discrete_features: {df_enhanced_discrete_features.shape}\")\n",
    "        try:\n",
    "            df_enhanced_discrete_features.to_csv(ENHANCED_DISCRETE_FEATURES_FILENAME_CSV, index=False)\n",
    "            print(f\"Enhanced discrete features saved to: {ENHANCED_DISCRETE_FEATURES_FILENAME_CSV}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving ENHANCED discrete features: {e}\")\n",
    "\n",
    "    except OSError:\n",
    "        print(\"spaCy model 'en_core_web_sm' not found. Please download it: python -m spacy download en_core_web_sm\")\n",
    "        print(\"Skipping spaCy feature enhancement.\")\n",
    "        df_enhanced_discrete_features = df_base_discrete_features.copy() # Fallback to base features\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during spaCy feature extraction: {e}\")\n",
    "        df_enhanced_discrete_features = df_base_discrete_features.copy() # Fallback\n",
    "else:\n",
    "     print(\"Skipping ENHANCED Discrete Feature generation (spaCy) as base discrete features or processed data is unavailable.\")\n",
    "\n",
    "\n",
    "if not df_enhanced_discrete_features.empty:\n",
    "    print(\"\\nHead of df_enhanced_discrete_features:\")\n",
    "    display(df_enhanced_discrete_features.head())\n",
    "    print(\"\\nDescription of df_enhanced_discrete_features:\")\n",
    "    display(df_enhanced_discrete_features.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4363ac",
   "metadata": {},
   "source": [
    "#### 3.3.3. (Experimental) Locally-Generated LLM Metrics via Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b8c3a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3.3.3. Generating LLM-based Complexity Rating via Ollama (Experimental, Model: llama3.2) ---\n",
      "Attempting to generate LLM complexity ratings for 635 sentences.\n",
      "This can be extremely time-consuming. Consider running on a small subset first.\n",
      "Processing sentence 50/635 for LLM rating...\n",
      "Processing sentence 100/635 for LLM rating...\n",
      "Processing sentence 150/635 for LLM rating...\n",
      "Processing sentence 200/635 for LLM rating...\n",
      "Processing sentence 250/635 for LLM rating...\n",
      "Processing sentence 300/635 for LLM rating...\n",
      "Processing sentence 350/635 for LLM rating...\n",
      "Processing sentence 400/635 for LLM rating...\n",
      "Processing sentence 450/635 for LLM rating...\n",
      "Processing sentence 500/635 for LLM rating...\n",
      "Processing sentence 550/635 for LLM rating...\n",
      "Processing sentence 600/635 for LLM rating...\n",
      "USING SIMULATED OLLAMA RATINGS FOR SPEED. Comment out this block for actual Ollama calls.\n",
      "'ollama_llm_rating' feature processed and NaNs imputed.\n",
      "Enhanced discrete features (with Ollama ratings) saved to: enhanced_discrete_features.csv\n",
      "\n",
      "Head of df_enhanced_discrete_features (potentially with Ollama rating):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "char_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "word_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "avg_word_length",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ttr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lex_density_proxy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_subord_clauses",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_conj_clauses",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "avg_dep_dist",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "max_dep_dist",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_verbs",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_nouns",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_adjectives",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_adverbs",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_prepositions",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_conjunctions",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ollama_llm_rating",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d5bffc96-27a4-4561-930c-524f22ca2128",
       "rows": [
        [
         "0",
         "168",
         "27",
         "6.222222222222222",
         "0.8333333333333334",
         "0.2666666666666666",
         "32.163333333333355",
         "15.480740740740742",
         "18.20740740740741",
         "1",
         "0",
         "2.933333333333333",
         "22",
         "3",
         "9",
         "2",
         "1",
         "3",
         "4",
         "4.0"
        ],
        [
         "1",
         "126",
         "22",
         "5.727272727272728",
         "0.8928571428571429",
         "0.25",
         "34.532272727272726",
         "13.90818181818182",
         "17.89090909090909",
         "0",
         "0",
         "2.607142857142857",
         "13",
         "3",
         "8",
         "1",
         "2",
         "4",
         "0",
         "5.0"
        ],
        [
         "2",
         "157",
         "25",
         "6.28",
         "0.925925925925926",
         "0.2592592592592592",
         "46.10000000000002",
         "13.040000000000004",
         "19.6",
         "0",
         "0",
         "3.129032258064516",
         "28",
         "4",
         "8",
         "1",
         "0",
         "5",
         "0",
         "3.0"
        ],
        [
         "3",
         "195",
         "31",
         "6.290322580645161",
         "0.8571428571428571",
         "0.2857142857142857",
         "36.18935483870968",
         "15.912903225806453",
         "16.270967741935486",
         "0",
         "0",
         "2.742857142857143",
         "31",
         "4",
         "13",
         "0",
         "0",
         "6",
         "1",
         "5.0"
        ],
        [
         "4",
         "90",
         "16",
         "5.625",
         "0.8947368421052632",
         "0.2105263157894736",
         "68.9825",
         "7.612500000000001",
         "6.4",
         "0",
         "0",
         "2.736842105263158",
         "15",
         "2",
         "8",
         "0",
         "0",
         "1",
         "1",
         "5.0"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>ttr</th>\n",
       "      <th>lex_density_proxy</th>\n",
       "      <th>flesch_ease</th>\n",
       "      <th>flesch_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>num_subord_clauses</th>\n",
       "      <th>num_conj_clauses</th>\n",
       "      <th>avg_dep_dist</th>\n",
       "      <th>max_dep_dist</th>\n",
       "      <th>num_verbs</th>\n",
       "      <th>num_nouns</th>\n",
       "      <th>num_adjectives</th>\n",
       "      <th>num_adverbs</th>\n",
       "      <th>num_prepositions</th>\n",
       "      <th>num_conjunctions</th>\n",
       "      <th>ollama_llm_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>168</td>\n",
       "      <td>27</td>\n",
       "      <td>6.222222</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>32.163333</td>\n",
       "      <td>15.480741</td>\n",
       "      <td>18.207407</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>22</td>\n",
       "      <td>5.727273</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>34.532273</td>\n",
       "      <td>13.908182</td>\n",
       "      <td>17.890909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.607143</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157</td>\n",
       "      <td>25</td>\n",
       "      <td>6.280000</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>46.100000</td>\n",
       "      <td>13.040000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.129032</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "      <td>31</td>\n",
       "      <td>6.290323</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>36.189355</td>\n",
       "      <td>15.912903</td>\n",
       "      <td>16.270968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.742857</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>16</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>68.982500</td>\n",
       "      <td>7.612500</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.736842</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count  word_count  avg_word_length       ttr  lex_density_proxy  \\\n",
       "0         168          27         6.222222  0.833333           0.266667   \n",
       "1         126          22         5.727273  0.892857           0.250000   \n",
       "2         157          25         6.280000  0.925926           0.259259   \n",
       "3         195          31         6.290323  0.857143           0.285714   \n",
       "4          90          16         5.625000  0.894737           0.210526   \n",
       "\n",
       "   flesch_ease  flesch_grade  gunning_fog  num_subord_clauses  \\\n",
       "0    32.163333     15.480741    18.207407                   1   \n",
       "1    34.532273     13.908182    17.890909                   0   \n",
       "2    46.100000     13.040000    19.600000                   0   \n",
       "3    36.189355     15.912903    16.270968                   0   \n",
       "4    68.982500      7.612500     6.400000                   0   \n",
       "\n",
       "   num_conj_clauses  avg_dep_dist  max_dep_dist  num_verbs  num_nouns  \\\n",
       "0                 0      2.933333            22          3          9   \n",
       "1                 0      2.607143            13          3          8   \n",
       "2                 0      3.129032            28          4          8   \n",
       "3                 0      2.742857            31          4         13   \n",
       "4                 0      2.736842            15          2          8   \n",
       "\n",
       "   num_adjectives  num_adverbs  num_prepositions  num_conjunctions  \\\n",
       "0               2            1                 3                 4   \n",
       "1               1            2                 4                 0   \n",
       "2               1            0                 5                 0   \n",
       "3               0            0                 6                 1   \n",
       "4               0            0                 1                 1   \n",
       "\n",
       "   ollama_llm_rating  \n",
       "0                4.0  \n",
       "1                5.0  \n",
       "2                3.0  \n",
       "3                5.0  \n",
       "4                5.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Description of df_enhanced_discrete_features (potentially with Ollama rating):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "char_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "word_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_word_length",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ttr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lex_density_proxy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_subord_clauses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_conj_clauses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_dep_dist",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "max_dep_dist",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_verbs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_nouns",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_adjectives",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_adverbs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_prepositions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_conjunctions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ollama_llm_rating",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f0415c4b-0d32-4364-8742-cd041829a96c",
       "rows": [
        [
         "count",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0",
         "635.0"
        ],
        [
         "mean",
         "126.54803149606299",
         "21.064566929133857",
         "6.001505578902042",
         "0.899012328431195",
         "0.22986365681413848",
         "48.454157757615995",
         "11.55499598087992",
         "13.729520948645886",
         "0.12440944881889764",
         "0.2614173228346457",
         "3.037494198560913",
         "17.938582677165353",
         "1.9291338582677164",
         "7.870866141732283",
         "1.552755905511811",
         "0.573228346456693",
         "2.8913385826771654",
         "0.9795275590551181",
         "3.017322834645669"
        ],
        [
         "std",
         "59.50788306392519",
         "9.671118076602415",
         "0.5979520919042367",
         "0.08311206737048588",
         "0.08546088409217244",
         "24.074463067153996",
         "4.46851981602659",
         "5.10165876734378",
         "0.3792148071240425",
         "0.5064329459282128",
         "0.7329207109711102",
         "9.85851044894406",
         "1.3995329457647046",
         "4.428081280052084",
         "1.4203249046065725",
         "0.8695196849272407",
         "2.117041550044101",
         "0.9487945683415242",
         "1.391053800674331"
        ],
        [
         "min",
         "27.0",
         "5.0",
         "4.285714285714286",
         "0.6140350877192983",
         "0.0",
         "-27.89999999999995",
         "-1.0599999999999987",
         "2.2",
         "0.0",
         "0.0",
         "1.3333333333333333",
         "3.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "25%",
         "82.5",
         "14.0",
         "5.6",
         "0.8481554677206851",
         "0.17316341829085455",
         "33.465",
         "8.544545454545453",
         "10.0",
         "0.0",
         "0.0",
         "2.5250626566416043",
         "11.0",
         "1.0",
         "5.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "2.0"
        ],
        [
         "50%",
         "116.0",
         "20.0",
         "5.973684210526316",
         "0.9090909090909092",
         "0.2307692307692307",
         "47.45500000000003",
         "11.16941176470588",
         "13.866666666666667",
         "0.0",
         "0.0",
         "2.942857142857143",
         "15.0",
         "2.0",
         "7.0",
         "1.0",
         "0.0",
         "3.0",
         "1.0",
         "3.0"
        ],
        [
         "75%",
         "159.0",
         "26.0",
         "6.388888888888889",
         "0.9565217391304348",
         "0.2857142857142857",
         "61.99869565217393",
         "14.371803069053712",
         "16.914285714285715",
         "0.0",
         "0.0",
         "3.450956937799043",
         "22.0",
         "3.0",
         "10.5",
         "2.0",
         "1.0",
         "4.0",
         "2.0",
         "4.0"
        ],
        [
         "max",
         "355.0",
         "58.0",
         "8.88888888888889",
         "1.0",
         "0.5555555555555556",
         "200.0",
         "27.37482758620689",
         "30.596078431372547",
         "3.0",
         "3.0",
         "6.711864406779661",
         "61.0",
         "9.0",
         "25.0",
         "8.0",
         "7.0",
         "13.0",
         "4.0",
         "5.0"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>ttr</th>\n",
       "      <th>lex_density_proxy</th>\n",
       "      <th>flesch_ease</th>\n",
       "      <th>flesch_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>num_subord_clauses</th>\n",
       "      <th>num_conj_clauses</th>\n",
       "      <th>avg_dep_dist</th>\n",
       "      <th>max_dep_dist</th>\n",
       "      <th>num_verbs</th>\n",
       "      <th>num_nouns</th>\n",
       "      <th>num_adjectives</th>\n",
       "      <th>num_adverbs</th>\n",
       "      <th>num_prepositions</th>\n",
       "      <th>num_conjunctions</th>\n",
       "      <th>ollama_llm_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>635.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>126.548031</td>\n",
       "      <td>21.064567</td>\n",
       "      <td>6.001506</td>\n",
       "      <td>0.899012</td>\n",
       "      <td>0.229864</td>\n",
       "      <td>48.454158</td>\n",
       "      <td>11.554996</td>\n",
       "      <td>13.729521</td>\n",
       "      <td>0.124409</td>\n",
       "      <td>0.261417</td>\n",
       "      <td>3.037494</td>\n",
       "      <td>17.938583</td>\n",
       "      <td>1.929134</td>\n",
       "      <td>7.870866</td>\n",
       "      <td>1.552756</td>\n",
       "      <td>0.573228</td>\n",
       "      <td>2.891339</td>\n",
       "      <td>0.979528</td>\n",
       "      <td>3.017323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>59.507883</td>\n",
       "      <td>9.671118</td>\n",
       "      <td>0.597952</td>\n",
       "      <td>0.083112</td>\n",
       "      <td>0.085461</td>\n",
       "      <td>24.074463</td>\n",
       "      <td>4.468520</td>\n",
       "      <td>5.101659</td>\n",
       "      <td>0.379215</td>\n",
       "      <td>0.506433</td>\n",
       "      <td>0.732921</td>\n",
       "      <td>9.858510</td>\n",
       "      <td>1.399533</td>\n",
       "      <td>4.428081</td>\n",
       "      <td>1.420325</td>\n",
       "      <td>0.869520</td>\n",
       "      <td>2.117042</td>\n",
       "      <td>0.948795</td>\n",
       "      <td>1.391054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-27.900000</td>\n",
       "      <td>-1.060000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>82.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.848155</td>\n",
       "      <td>0.173163</td>\n",
       "      <td>33.465000</td>\n",
       "      <td>8.544545</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.525063</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.973684</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>47.455000</td>\n",
       "      <td>11.169412</td>\n",
       "      <td>13.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.942857</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>159.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>6.388889</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>61.998696</td>\n",
       "      <td>14.371803</td>\n",
       "      <td>16.914286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.450957</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>355.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>8.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>27.374828</td>\n",
       "      <td>30.596078</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.711864</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       char_count  word_count  avg_word_length         ttr  lex_density_proxy  \\\n",
       "count  635.000000  635.000000       635.000000  635.000000         635.000000   \n",
       "mean   126.548031   21.064567         6.001506    0.899012           0.229864   \n",
       "std     59.507883    9.671118         0.597952    0.083112           0.085461   \n",
       "min     27.000000    5.000000         4.285714    0.614035           0.000000   \n",
       "25%     82.500000   14.000000         5.600000    0.848155           0.173163   \n",
       "50%    116.000000   20.000000         5.973684    0.909091           0.230769   \n",
       "75%    159.000000   26.000000         6.388889    0.956522           0.285714   \n",
       "max    355.000000   58.000000         8.888889    1.000000           0.555556   \n",
       "\n",
       "       flesch_ease  flesch_grade  gunning_fog  num_subord_clauses  \\\n",
       "count   635.000000    635.000000   635.000000          635.000000   \n",
       "mean     48.454158     11.554996    13.729521            0.124409   \n",
       "std      24.074463      4.468520     5.101659            0.379215   \n",
       "min     -27.900000     -1.060000     2.200000            0.000000   \n",
       "25%      33.465000      8.544545    10.000000            0.000000   \n",
       "50%      47.455000     11.169412    13.866667            0.000000   \n",
       "75%      61.998696     14.371803    16.914286            0.000000   \n",
       "max     200.000000     27.374828    30.596078            3.000000   \n",
       "\n",
       "       num_conj_clauses  avg_dep_dist  max_dep_dist   num_verbs   num_nouns  \\\n",
       "count        635.000000    635.000000    635.000000  635.000000  635.000000   \n",
       "mean           0.261417      3.037494     17.938583    1.929134    7.870866   \n",
       "std            0.506433      0.732921      9.858510    1.399533    4.428081   \n",
       "min            0.000000      1.333333      3.000000    0.000000    0.000000   \n",
       "25%            0.000000      2.525063     11.000000    1.000000    5.000000   \n",
       "50%            0.000000      2.942857     15.000000    2.000000    7.000000   \n",
       "75%            0.000000      3.450957     22.000000    3.000000   10.500000   \n",
       "max            3.000000      6.711864     61.000000    9.000000   25.000000   \n",
       "\n",
       "       num_adjectives  num_adverbs  num_prepositions  num_conjunctions  \\\n",
       "count      635.000000   635.000000        635.000000        635.000000   \n",
       "mean         1.552756     0.573228          2.891339          0.979528   \n",
       "std          1.420325     0.869520          2.117042          0.948795   \n",
       "min          0.000000     0.000000          0.000000          0.000000   \n",
       "25%          1.000000     0.000000          1.000000          0.000000   \n",
       "50%          1.000000     0.000000          3.000000          1.000000   \n",
       "75%          2.000000     1.000000          4.000000          2.000000   \n",
       "max          8.000000     7.000000         13.000000          4.000000   \n",
       "\n",
       "       ollama_llm_rating  \n",
       "count         635.000000  \n",
       "mean            3.017323  \n",
       "std             1.391054  \n",
       "min             1.000000  \n",
       "25%             2.000000  \n",
       "50%             3.000000  \n",
       "75%             4.000000  \n",
       "max             5.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- (Experimental) Locally-Generated LLM Metrics (Ollama) ---\n",
    "# This section is experimental and can be VERY time-consuming.\n",
    "# Ensure Ollama server is running and the model (e.g., 'llama3') is pulled.\n",
    "\n",
    "OLLAMA_ENABLED = True # Set to True to run actual Ollama calls (VERY SLOW)\n",
    "OLLAMA_MODEL_NAME = 'llama3.2' # Or your specific Ollama model, e.g., 'llama3:8b'\n",
    "\n",
    "if 'df_enhanced_discrete_features' not in globals(): # Ensure previous df exists\n",
    "    df_enhanced_discrete_features = df_base_discrete_features.copy() if 'df_base_discrete_features' in globals() and not df_base_discrete_features.empty else pd.DataFrame()\n",
    "\n",
    "if OLLAMA_ENABLED and not df_processed.empty and not df_enhanced_discrete_features.empty and \\\n",
    "   df_processed.shape[0] == df_enhanced_discrete_features.shape[0]:\n",
    "    print(f\"\\n--- 3.3.3. Generating LLM-based Complexity Rating via Ollama (Experimental, Model: {OLLAMA_MODEL_NAME}) ---\")\n",
    "\n",
    "    def get_ollama_complexity_rating_prompt(sentence_text, model_name=OLLAMA_MODEL_NAME):\n",
    "        if not sentence_text or not sentence_text.strip():\n",
    "            return np.nan\n",
    "        # Refined prompt for a more constrained, numerical output\n",
    "        prompt_template = (\n",
    "            f\"Rate the complexity of the following English sentence on a scale of 1 (very simple) \"\n",
    "            f\"to 5 (very complex). Respond with ONLY the integer number (1, 2, 3, 4, or 5) and nothing else.\\n\"\n",
    "            f\"Sentence: \\\"{sentence_text}\\\"\\n\"\n",
    "            f\"Rating:\"\n",
    "        )\n",
    "        try:\n",
    "            response = ollama.generate(\n",
    "                model=model_name,\n",
    "                prompt=prompt_template,\n",
    "                stream=False,\n",
    "                options={\"temperature\": 0.1, \"num_predict\": 3} # Low temp for consistency, limit output\n",
    "            )\n",
    "            rating_text = response['response'].strip()\n",
    "            # Try to extract the first integer found in the response\n",
    "            match = re.search(r'\\b([1-5])\\b', rating_text) # Look for a single digit 1-5\n",
    "            if match:\n",
    "                return int(match.group(0))\n",
    "            else:\n",
    "                # print(f\"Warning: Could not parse valid rating (1-5) from Ollama response: '{rating_text}' for sentence: '{sentence_text[:30]}...'\")\n",
    "                return np.nan # Return NaN if parsing fails\n",
    "        except Exception as e:\n",
    "            # print(f\"Error with Ollama for sentence '{sentence_text[:30]}...': {e}\")\n",
    "            return np.nan\n",
    "\n",
    "    llm_complexity_ratings = []\n",
    "    sentences_for_llm_rating = df_processed['cleaned_sentence'].fillna('').tolist()\n",
    "\n",
    "    print(f\"Attempting to generate LLM complexity ratings for {len(sentences_for_llm_rating)} sentences.\")\n",
    "    print(\"This can be extremely time-consuming. Consider running on a small subset first.\")\n",
    "    for i, sentence in enumerate(sentences_for_llm_rating): # UNCOMMENT FOR ACTUAL RUN\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"Processing sentence {i + 1}/{len(sentences_for_llm_rating)} for LLM rating...\")\n",
    "        rating = get_ollama_complexity_rating_prompt(sentence)\n",
    "        llm_complexity_ratings.append(rating)\n",
    "        time.sleep(0.2) # Be nice to the local server\n",
    "\n",
    "    # --- SIMULATION BLOCK (Remove or comment out for actual Ollama calls) ---\n",
    "    print(\"USING SIMULATED OLLAMA RATINGS FOR SPEED. Comment out this block for actual Ollama calls.\")\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "    llm_complexity_ratings = np.random.randint(1, 6, size=len(sentences_for_llm_rating)).astype(float)\n",
    "    nan_indices_sim = np.random.choice(len(llm_complexity_ratings), size=int(0.05 * len(llm_complexity_ratings)), replace=False)\n",
    "    llm_complexity_ratings[nan_indices_sim] = np.nan\n",
    "    # --- END SIMULATION BLOCK ---\n",
    "\n",
    "    df_enhanced_discrete_features['ollama_llm_rating'] = llm_complexity_ratings\n",
    "    # Impute NaNs from errors or simulation\n",
    "    median_llm_rating = df_enhanced_discrete_features['ollama_llm_rating'].median()\n",
    "    if pd.isna(median_llm_rating): median_llm_rating = 3.0 # Default if all are NaN\n",
    "    df_enhanced_discrete_features['ollama_llm_rating'].fillna(median_llm_rating, inplace=True)\n",
    "    print(\"'ollama_llm_rating' feature processed and NaNs imputed.\")\n",
    "\n",
    "    # Save the dataframe again if Ollama features were actually generated and added\n",
    "    if OLLAMA_ENABLED: # Only save if actual calls were made\n",
    "        try:\n",
    "            df_enhanced_discrete_features.to_csv(ENHANCED_DISCRETE_FEATURES_FILENAME_CSV, index=False)\n",
    "            print(f\"Enhanced discrete features (with Ollama ratings) saved to: {ENHANCED_DISCRETE_FEATURES_FILENAME_CSV}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving enhanced discrete features with Ollama ratings: {e}\")\n",
    "\n",
    "elif not OLLAMA_ENABLED:\n",
    "    print(\"Ollama LLM rating generation was SKIPPED (OLLAMA_ENABLED=False).\")\n",
    "    # If df_enhanced_discrete_features exists and ollama_llm_rating is not already there from a previous run,\n",
    "    # we might add a simulated column just so the subsequent code doesn't break if it expects it.\n",
    "    if 'df_enhanced_discrete_features' in globals() and not df_enhanced_discrete_features.empty and \\\n",
    "       'ollama_llm_rating' not in df_enhanced_discrete_features.columns:\n",
    "        print(\"Adding SIMULATED 'ollama_llm_rating' column as Ollama was disabled.\")\n",
    "        np.random.seed(RANDOM_STATE)\n",
    "        sim_ratings = np.random.randint(1, 6, size=len(df_enhanced_discrete_features)).astype(float)\n",
    "        df_enhanced_discrete_features['ollama_llm_rating'] = sim_ratings\n",
    "\n",
    "else:\n",
    "    print(\"Skipping Ollama LLM rating generation as base data is unavailable or misaligned.\")\n",
    "\n",
    "if not df_enhanced_discrete_features.empty:\n",
    "    print(\"\\nHead of df_enhanced_discrete_features (potentially with Ollama rating):\")\n",
    "    display(df_enhanced_discrete_features.head())\n",
    "    print(\"\\nDescription of df_enhanced_discrete_features (potentially with Ollama rating):\")\n",
    "    display(df_enhanced_discrete_features.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac788733",
   "metadata": {},
   "source": [
    "## 4. Model Training, Evaluation, and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5734e703",
   "metadata": {},
   "source": [
    "#### 4.1 Helper Functions for Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "461f1287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(X_train, y_train, X_test, y_test,\n",
    "                             model_instance, model_class_name, feature_set_name):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a given scikit-learn model instance.\n",
    "\n",
    "    Args:\n",
    "        X_train, y_train, X_test, y_test: Training and testing data.\n",
    "        model_instance: An instance of a scikit-learn classifier.\n",
    "        model_class_name (str): Name of the model class (e.g., \"LogisticRegression\").\n",
    "        feature_set_name (str): Name of the feature set used (e.g., \"Embeddings\").\n",
    "\n",
    "    Returns:\n",
    "        tuple: (trained_model, results_dict)\n",
    "    \"\"\"\n",
    "    global all_model_results_list # Use the global list to store results\n",
    "\n",
    "    model_full_name = f\"{model_class_name} on {feature_set_name}\"\n",
    "\n",
    "    if X_train is None or X_test is None or y_train is None or y_test is None or \\\n",
    "       (isinstance(X_train, np.ndarray) and X_train.size == 0) or \\\n",
    "       (isinstance(X_train, pd.DataFrame) and X_train.empty):\n",
    "        print(f\"Skipping training for {model_full_name} as data is unavailable or empty.\")\n",
    "        return None, {}\n",
    "\n",
    "    print(f\"\\n--- Training and Evaluating: {model_full_name} ---\")\n",
    "    model = model_instance # Use the passed instance\n",
    "\n",
    "    start_time_train = time.time()\n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during training {model_full_name}: {e}\")\n",
    "        return None, {}\n",
    "    training_time = time.time() - start_time_train\n",
    "\n",
    "    start_time_pred = time.time()\n",
    "    try:\n",
    "        y_pred = model.predict(X_test)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during prediction with {model_full_name}: {e}\")\n",
    "        return model, {} # Return the trained model but empty results for prediction part\n",
    "    prediction_time = time.time() - start_time_pred\n",
    "\n",
    "    print(f\"Training time: {training_time:.3f}s | Prediction time: {prediction_time:.3f}s\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    try:\n",
    "        report_str = classification_report(y_test, y_pred, target_names=['NR (0)', 'TSR (1)'], zero_division=0)\n",
    "        report_dict = classification_report(y_test, y_pred, target_names=['NR (0)', 'TSR (1)'], output_dict=True, zero_division=0)\n",
    "        print(report_str)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating classification report for {model_full_name}: {e}\")\n",
    "        report_dict = {}\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_tsr = f1_score(y_test, y_pred, pos_label=1, zero_division=0) # TSR is class 1\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1-score (TSR class): {f1_tsr:.4f}\")\n",
    "    print(f\"F1-score (Macro): {f1_macro:.4f}\")\n",
    "    print(f\"F1-score (Weighted): {f1_weighted:.4f}\")\n",
    "\n",
    "    results = {\n",
    "        \"model_name\": model_full_name,\n",
    "        \"model_class\": model_class_name,\n",
    "        \"feature_set\": feature_set_name,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score_TSR\": f1_tsr,\n",
    "        \"f1_score_macro\": f1_macro,\n",
    "        \"f1_score_weighted\": f1_weighted,\n",
    "        \"classification_report_dict\": report_dict,\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "        \"training_time_seconds\": training_time,\n",
    "        \"prediction_time_seconds\": prediction_time\n",
    "    }\n",
    "    all_model_results_list.append(results)\n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aaf69a",
   "metadata": {},
   "source": [
    "#### 4.2 Prepare Data Splits for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1a1fbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4.2. Preparing Data Splits (Total samples: 635) ---\n",
      "Data split for Option A (Embeddings): Train (508, 384), Test (127, 384)\n",
      "Data split for Option B (Base Discrete): Train Scaled (508, 8), Test Scaled (127, 8)\n",
      "Data split for Option B (Enhanced Discrete): Train Scaled (508, 19), Test Scaled (127, 19)\n",
      "Data split for Combined Features: Train (508, 403), Test (127, 403)\n"
     ]
    }
   ],
   "source": [
    "# Ensure df_processed is loaded and has the 'label' column\n",
    "labels_array = np.array([])\n",
    "if not df_processed.empty and 'label' in df_processed.columns:\n",
    "    labels_array = df_processed['label'].values\n",
    "    print(f\"--- 4.2. Preparing Data Splits (Total samples: {len(labels_array)}) ---\")\n",
    "else:\n",
    "    print(\"Error: Labels ('label' column in df_processed) not found. Cannot proceed with data splitting.\")\n",
    "\n",
    "# Option A: Sentence Embeddings\n",
    "X_emb_train, X_emb_test, y_emb_train, y_emb_test = [None]*4 # Initialize\n",
    "if sentence_embeddings_array.size > 0 and labels_array.size > 0:\n",
    "    if sentence_embeddings_array.shape[0] == len(labels_array):\n",
    "        X_emb_train, X_emb_test, y_emb_train, y_emb_test = train_test_split(\n",
    "            sentence_embeddings_array, labels_array, test_size=0.2, random_state=RANDOM_STATE, stratify=labels_array\n",
    "        )\n",
    "        print(f\"Data split for Option A (Embeddings): Train {X_emb_train.shape}, Test {X_emb_test.shape}\")\n",
    "    else:\n",
    "        print(\"Error: Mismatch between number of embeddings and labels for Option A.\")\n",
    "else:\n",
    "    print(\"Skipping data split for Option A: Embeddings or labels are unavailable/empty.\")\n",
    "\n",
    "\n",
    "# Option B: Base Discrete Features (df_base_discrete_features)\n",
    "X_base_disc_train_scaled, X_base_disc_test_scaled = [None]*2\n",
    "X_base_disc_train_unscaled_df, X_base_disc_test_unscaled_df = [None]*2\n",
    "y_base_disc_train, y_base_disc_test = [None]*2\n",
    "\n",
    "if not df_base_discrete_features.empty and labels_array.size > 0:\n",
    "    if len(df_base_discrete_features) == len(labels_array):\n",
    "        X_base_disc_train_unscaled_df, X_base_disc_test_unscaled_df, \\\n",
    "        y_base_disc_train, y_base_disc_test = train_test_split(\n",
    "            df_base_discrete_features, labels_array, test_size=0.2, random_state=RANDOM_STATE, stratify=labels_array\n",
    "        )\n",
    "        scaler_base_disc = StandardScaler()\n",
    "        X_base_disc_train_scaled = scaler_base_disc.fit_transform(X_base_disc_train_unscaled_df)\n",
    "        X_base_disc_test_scaled = scaler_base_disc.transform(X_base_disc_test_unscaled_df)\n",
    "        print(f\"Data split for Option B (Base Discrete): Train Scaled {X_base_disc_train_scaled.shape}, Test Scaled {X_base_disc_test_scaled.shape}\")\n",
    "    else:\n",
    "        print(\"Error: Mismatch between number of base discrete features and labels for Option B.\")\n",
    "else:\n",
    "    print(\"Skipping data split for Option B (Base Discrete): Features or labels are unavailable/empty.\")\n",
    "\n",
    "\n",
    "# Option B Enhanced: Enhanced Discrete Features (df_enhanced_discrete_features)\n",
    "X_enh_disc_train_scaled, X_enh_disc_test_scaled = [None]*2\n",
    "X_enh_disc_train_unscaled_df, X_enh_disc_test_unscaled_df = [None]*2\n",
    "y_enh_disc_train, y_enh_disc_test = [None]*2\n",
    "\n",
    "if not df_enhanced_discrete_features.empty and labels_array.size > 0:\n",
    "    if len(df_enhanced_discrete_features) == len(labels_array):\n",
    "        X_enh_disc_train_unscaled_df, X_enh_disc_test_unscaled_df, \\\n",
    "        y_enh_disc_train, y_enh_disc_test = train_test_split(\n",
    "            df_enhanced_discrete_features, labels_array, test_size=0.2, random_state=RANDOM_STATE, stratify=labels_array\n",
    "        )\n",
    "        scaler_enh_disc = StandardScaler()\n",
    "        X_enh_disc_train_scaled = scaler_enh_disc.fit_transform(X_enh_disc_train_unscaled_df)\n",
    "        X_enh_disc_test_scaled = scaler_enh_disc.transform(X_enh_disc_test_unscaled_df)\n",
    "        print(f\"Data split for Option B (Enhanced Discrete): Train Scaled {X_enh_disc_train_scaled.shape}, Test Scaled {X_enh_disc_test_scaled.shape}\")\n",
    "    else:\n",
    "         print(\"Error: Mismatch between number of enhanced discrete features and labels for Option B (Enhanced).\")\n",
    "else:\n",
    "    print(\"Skipping data split for Option B (Enhanced Discrete): Features or labels are unavailable/empty.\")\n",
    "\n",
    "\n",
    "# Combined Features (Embeddings + Scaled Enhanced Discrete)\n",
    "X_combined_train, X_combined_test = [None]*2\n",
    "y_combined_train, y_combined_test = (y_emb_train, y_emb_test) if y_emb_train is not None else (y_enh_disc_train, y_enh_disc_test) # Use available y_train/test\n",
    "\n",
    "if X_emb_train is not None and X_enh_disc_train_scaled is not None:\n",
    "    if X_emb_train.shape[0] == X_enh_disc_train_scaled.shape[0]: # Ensure row counts match\n",
    "        X_combined_train = np.concatenate((X_emb_train, X_enh_disc_train_scaled), axis=1)\n",
    "        X_combined_test = np.concatenate((X_emb_test, X_enh_disc_test_scaled), axis=1)\n",
    "        print(f\"Data split for Combined Features: Train {X_combined_train.shape}, Test {X_combined_test.shape}\")\n",
    "    else:\n",
    "        print(\"Error: Mismatch in sample numbers between embedding and scaled enhanced discrete feature sets for training. Cannot combine.\")\n",
    "else:\n",
    "    print(\"Skipping data split for Combined Features: Embeddings or scaled enhanced discrete features are unavailable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab9d265",
   "metadata": {},
   "source": [
    "#### 4.3. Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "748c548c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4.3. Training and Evaluating Models ---\n",
      "\n",
      "--- Training and Evaluating: LogisticRegression on Embeddings (Option A) ---\n",
      "Training time: 0.017s | Prediction time: 0.001s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.68      0.66      0.67        61\n",
      "     TSR (1)       0.69      0.71      0.70        66\n",
      "\n",
      "    accuracy                           0.69       127\n",
      "   macro avg       0.68      0.68      0.68       127\n",
      "weighted avg       0.68      0.69      0.68       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[40 21]\n",
      " [19 47]]\n",
      "\n",
      "Accuracy: 0.6850\n",
      "F1-score (TSR class): 0.7015\n",
      "F1-score (Macro): 0.6841\n",
      "F1-score (Weighted): 0.6848\n",
      "\n",
      "--- Training and Evaluating: LogisticRegression on Base Discrete Scaled (Option B) ---\n",
      "Training time: 0.002s | Prediction time: 0.000s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.56      0.57      0.56        61\n",
      "     TSR (1)       0.59      0.58      0.58        66\n",
      "\n",
      "    accuracy                           0.57       127\n",
      "   macro avg       0.57      0.57      0.57       127\n",
      "weighted avg       0.58      0.57      0.57       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[35 26]\n",
      " [28 38]]\n",
      "\n",
      "Accuracy: 0.5748\n",
      "F1-score (TSR class): 0.5846\n",
      "F1-score (Macro): 0.5746\n",
      "F1-score (Weighted): 0.5750\n",
      "\n",
      "--- Training and Evaluating: LogisticRegression on Enhanced Discrete Scaled (Option B) ---\n",
      "Training time: 0.004s | Prediction time: 0.000s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.65      0.69      0.67        61\n",
      "     TSR (1)       0.69      0.65      0.67        66\n",
      "\n",
      "    accuracy                           0.67       127\n",
      "   macro avg       0.67      0.67      0.67       127\n",
      "weighted avg       0.67      0.67      0.67       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[42 19]\n",
      " [23 43]]\n",
      "\n",
      "Accuracy: 0.6693\n",
      "F1-score (TSR class): 0.6719\n",
      "F1-score (Macro): 0.6693\n",
      "F1-score (Weighted): 0.6694\n",
      "\n",
      "--- Training and Evaluating: DecisionTree on Embeddings (Option A) ---\n",
      "Training time: 0.234s | Prediction time: 0.001s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.47      0.44      0.45        61\n",
      "     TSR (1)       0.51      0.53      0.52        66\n",
      "\n",
      "    accuracy                           0.49       127\n",
      "   macro avg       0.49      0.49      0.49       127\n",
      "weighted avg       0.49      0.49      0.49       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[27 34]\n",
      " [31 35]]\n",
      "\n",
      "Accuracy: 0.4882\n",
      "F1-score (TSR class): 0.5185\n",
      "F1-score (Macro): 0.4862\n",
      "F1-score (Weighted): 0.4874\n",
      "\n",
      "--- Training and Evaluating: DecisionTree on Base Discrete Unscaled (Option B) ---\n",
      "Training time: 0.008s | Prediction time: 0.002s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.49      0.54      0.52        61\n",
      "     TSR (1)       0.53      0.48      0.51        66\n",
      "\n",
      "    accuracy                           0.51       127\n",
      "   macro avg       0.51      0.51      0.51       127\n",
      "weighted avg       0.51      0.51      0.51       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[33 28]\n",
      " [34 32]]\n",
      "\n",
      "Accuracy: 0.5118\n",
      "F1-score (TSR class): 0.5079\n",
      "F1-score (Macro): 0.5118\n",
      "F1-score (Weighted): 0.5116\n",
      "\n",
      "--- Training and Evaluating: DecisionTree on Enhanced Discrete Unscaled (Option B) ---\n",
      "Training time: 0.010s | Prediction time: 0.001s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.59      0.54      0.56        61\n",
      "     TSR (1)       0.61      0.65      0.63        66\n",
      "\n",
      "    accuracy                           0.60       127\n",
      "   macro avg       0.60      0.60      0.60       127\n",
      "weighted avg       0.60      0.60      0.60       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[33 28]\n",
      " [23 43]]\n",
      "\n",
      "Accuracy: 0.5984\n",
      "F1-score (TSR class): 0.6277\n",
      "F1-score (Macro): 0.5959\n",
      "F1-score (Weighted): 0.5972\n",
      "\n",
      "--- Training and Evaluating: RandomForest on Embeddings (Option A) ---\n",
      "Training time: 0.261s | Prediction time: 0.047s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.70      0.66      0.68        61\n",
      "     TSR (1)       0.70      0.74      0.72        66\n",
      "\n",
      "    accuracy                           0.70       127\n",
      "   macro avg       0.70      0.70      0.70       127\n",
      "weighted avg       0.70      0.70      0.70       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[40 21]\n",
      " [17 49]]\n",
      "\n",
      "Accuracy: 0.7008\n",
      "F1-score (TSR class): 0.7206\n",
      "F1-score (Macro): 0.6993\n",
      "F1-score (Weighted): 0.7001\n",
      "\n",
      "--- Training and Evaluating: RandomForest on Base Discrete Unscaled (Option B) ---\n",
      "Training time: 0.250s | Prediction time: 0.042s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.66      0.61      0.63        61\n",
      "     TSR (1)       0.66      0.71      0.69        66\n",
      "\n",
      "    accuracy                           0.66       127\n",
      "   macro avg       0.66      0.66      0.66       127\n",
      "weighted avg       0.66      0.66      0.66       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[37 24]\n",
      " [19 47]]\n",
      "\n",
      "Accuracy: 0.6614\n",
      "F1-score (TSR class): 0.6861\n",
      "F1-score (Macro): 0.6593\n",
      "F1-score (Weighted): 0.6604\n",
      "\n",
      "--- Training and Evaluating: RandomForest on Enhanced Discrete Unscaled (Option B) ---\n",
      "Training time: 0.253s | Prediction time: 0.048s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.73      0.67      0.70        61\n",
      "     TSR (1)       0.72      0.77      0.74        66\n",
      "\n",
      "    accuracy                           0.72       127\n",
      "   macro avg       0.73      0.72      0.72       127\n",
      "weighted avg       0.72      0.72      0.72       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[41 20]\n",
      " [15 51]]\n",
      "\n",
      "Accuracy: 0.7244\n",
      "F1-score (TSR class): 0.7445\n",
      "F1-score (Macro): 0.7227\n",
      "F1-score (Weighted): 0.7235\n",
      "\n",
      "--- Training and Evaluating: RandomForest on Combined (A + Scaled Enh. B) ---\n",
      "Training time: 0.269s | Prediction time: 0.039s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.63      0.64      0.63        61\n",
      "     TSR (1)       0.66      0.65      0.66        66\n",
      "\n",
      "    accuracy                           0.65       127\n",
      "   macro avg       0.65      0.65      0.65       127\n",
      "weighted avg       0.65      0.65      0.65       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[39 22]\n",
      " [23 43]]\n",
      "\n",
      "Accuracy: 0.6457\n",
      "F1-score (TSR class): 0.6565\n",
      "F1-score (Macro): 0.6453\n",
      "F1-score (Weighted): 0.6458\n",
      "\n",
      "--- Training and Evaluating: LightGBM on Embeddings (Option A) ---\n",
      "Training time: 0.580s | Prediction time: 0.002s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.69      0.66      0.67        61\n",
      "     TSR (1)       0.70      0.73      0.71        66\n",
      "\n",
      "    accuracy                           0.69       127\n",
      "   macro avg       0.69      0.69      0.69       127\n",
      "weighted avg       0.69      0.69      0.69       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[40 21]\n",
      " [18 48]]\n",
      "\n",
      "Accuracy: 0.6929\n",
      "F1-score (TSR class): 0.7111\n",
      "F1-score (Macro): 0.6917\n",
      "F1-score (Weighted): 0.6925\n",
      "\n",
      "--- Training and Evaluating: LightGBM on Base Discrete Unscaled (Option B) ---\n",
      "Training time: 0.042s | Prediction time: 0.003s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.55      0.52      0.54        61\n",
      "     TSR (1)       0.58      0.61      0.59        66\n",
      "\n",
      "    accuracy                           0.57       127\n",
      "   macro avg       0.57      0.57      0.57       127\n",
      "weighted avg       0.57      0.57      0.57       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[32 29]\n",
      " [26 40]]\n",
      "\n",
      "Accuracy: 0.5669\n",
      "F1-score (TSR class): 0.5926\n",
      "F1-score (Macro): 0.5652\n",
      "F1-score (Weighted): 0.5663\n",
      "\n",
      "--- Training and Evaluating: LightGBM on Enhanced Discrete Unscaled (Option B) ---\n",
      "Training time: 0.056s | Prediction time: 0.003s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.65      0.54      0.59        61\n",
      "     TSR (1)       0.63      0.73      0.68        66\n",
      "\n",
      "    accuracy                           0.64       127\n",
      "   macro avg       0.64      0.63      0.63       127\n",
      "weighted avg       0.64      0.64      0.63       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[33 28]\n",
      " [18 48]]\n",
      "\n",
      "Accuracy: 0.6378\n",
      "F1-score (TSR class): 0.6761\n",
      "F1-score (Macro): 0.6327\n",
      "F1-score (Weighted): 0.6344\n",
      "\n",
      "--- Training and Evaluating: LightGBM on Combined (A + Scaled Enh. B) ---\n",
      "Training time: 0.430s | Prediction time: 0.003s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.64      0.69      0.66        61\n",
      "     TSR (1)       0.69      0.64      0.66        66\n",
      "\n",
      "    accuracy                           0.66       127\n",
      "   macro avg       0.66      0.66      0.66       127\n",
      "weighted avg       0.66      0.66      0.66       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[42 19]\n",
      " [24 42]]\n",
      "\n",
      "Accuracy: 0.6614\n",
      "F1-score (TSR class): 0.6614\n",
      "F1-score (Macro): 0.6614\n",
      "F1-score (Weighted): 0.6614\n",
      "\n",
      "--- Training and Evaluating: SVM on Embeddings (Option A) ---\n",
      "Training time: 0.257s | Prediction time: 0.020s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.70      0.72      0.71        61\n",
      "     TSR (1)       0.73      0.71      0.72        66\n",
      "\n",
      "    accuracy                           0.72       127\n",
      "   macro avg       0.72      0.72      0.72       127\n",
      "weighted avg       0.72      0.72      0.72       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[44 17]\n",
      " [19 47]]\n",
      "\n",
      "Accuracy: 0.7165\n",
      "F1-score (TSR class): 0.7231\n",
      "F1-score (Macro): 0.7164\n",
      "F1-score (Weighted): 0.7166\n",
      "\n",
      "--- Training and Evaluating: SVM on Base Discrete Scaled (Option B) ---\n",
      "Training time: 0.067s | Prediction time: 0.007s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.56      0.64      0.60        61\n",
      "     TSR (1)       0.61      0.53      0.57        66\n",
      "\n",
      "    accuracy                           0.58       127\n",
      "   macro avg       0.59      0.58      0.58       127\n",
      "weighted avg       0.59      0.58      0.58       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[39 22]\n",
      " [31 35]]\n",
      "\n",
      "Accuracy: 0.5827\n",
      "F1-score (TSR class): 0.5691\n",
      "F1-score (Macro): 0.5823\n",
      "F1-score (Weighted): 0.5817\n",
      "\n",
      "--- Training and Evaluating: SVM on Enhanced Discrete Scaled (Option B) ---\n",
      "Training time: 0.074s | Prediction time: 0.007s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.67      0.61      0.64        61\n",
      "     TSR (1)       0.67      0.73      0.70        66\n",
      "\n",
      "    accuracy                           0.67       127\n",
      "   macro avg       0.67      0.67      0.67       127\n",
      "weighted avg       0.67      0.67      0.67       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[37 24]\n",
      " [18 48]]\n",
      "\n",
      "Accuracy: 0.6693\n",
      "F1-score (TSR class): 0.6957\n",
      "F1-score (Macro): 0.6668\n",
      "F1-score (Weighted): 0.6679\n",
      "\n",
      "--- Training and Evaluating: SVM on Combined (A + Scaled Enh. B) ---\n",
      "Training time: 0.228s | Prediction time: 0.020s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.70      0.66      0.68        61\n",
      "     TSR (1)       0.70      0.74      0.72        66\n",
      "\n",
      "    accuracy                           0.70       127\n",
      "   macro avg       0.70      0.70      0.70       127\n",
      "weighted avg       0.70      0.70      0.70       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[40 21]\n",
      " [17 49]]\n",
      "\n",
      "Accuracy: 0.7008\n",
      "F1-score (TSR class): 0.7206\n",
      "F1-score (Macro): 0.6993\n",
      "F1-score (Weighted): 0.7001\n",
      "\n",
      "--- Training and Evaluating: MLP on Embeddings (Option A) ---\n",
      "Training time: 0.406s | Prediction time: 0.004s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.67      0.67      0.67        61\n",
      "     TSR (1)       0.70      0.70      0.70        66\n",
      "\n",
      "    accuracy                           0.69       127\n",
      "   macro avg       0.68      0.68      0.68       127\n",
      "weighted avg       0.69      0.69      0.69       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[41 20]\n",
      " [20 46]]\n",
      "\n",
      "Accuracy: 0.6850\n",
      "F1-score (TSR class): 0.6970\n",
      "F1-score (Macro): 0.6846\n",
      "F1-score (Weighted): 0.6850\n",
      "\n",
      "--- Training and Evaluating: MLP on Base Discrete Scaled (Option B) ---\n",
      "Training time: 0.199s | Prediction time: 0.000s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.52      0.36      0.43        61\n",
      "     TSR (1)       0.54      0.70      0.61        66\n",
      "\n",
      "    accuracy                           0.54       127\n",
      "   macro avg       0.53      0.53      0.52       127\n",
      "weighted avg       0.53      0.54      0.52       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[22 39]\n",
      " [20 46]]\n",
      "\n",
      "Accuracy: 0.5354\n",
      "F1-score (TSR class): 0.6093\n",
      "F1-score (Macro): 0.5182\n",
      "F1-score (Weighted): 0.5218\n",
      "\n",
      "--- Training and Evaluating: MLP on Enhanced Discrete Scaled (Option B) ---\n",
      "Training time: 0.134s | Prediction time: 0.001s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.62      0.57      0.60        61\n",
      "     TSR (1)       0.63      0.68      0.66        66\n",
      "\n",
      "    accuracy                           0.63       127\n",
      "   macro avg       0.63      0.63      0.63       127\n",
      "weighted avg       0.63      0.63      0.63       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[35 26]\n",
      " [21 45]]\n",
      "\n",
      "Accuracy: 0.6299\n",
      "F1-score (TSR class): 0.6569\n",
      "F1-score (Macro): 0.6276\n",
      "F1-score (Weighted): 0.6288\n",
      "\n",
      "--- Training and Evaluating: MLP on Combined (A + Scaled Enh. B) ---\n",
      "Training time: 0.573s | Prediction time: 0.002s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.69      0.67      0.68        61\n",
      "     TSR (1)       0.71      0.73      0.72        66\n",
      "\n",
      "    accuracy                           0.70       127\n",
      "   macro avg       0.70      0.70      0.70       127\n",
      "weighted avg       0.70      0.70      0.70       127\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[41 20]\n",
      " [18 48]]\n",
      "\n",
      "Accuracy: 0.7008\n",
      "F1-score (TSR class): 0.7164\n",
      "F1-score (Macro): 0.6999\n",
      "F1-score (Weighted): 0.7005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(MLPClassifier(early_stopping=True, hidden_layer_sizes=(100, 50), max_iter=1000,\n",
       "               random_state=42),\n",
       " {'model_name': 'MLP on Combined (A + Scaled Enh. B)',\n",
       "  'model_class': 'MLP',\n",
       "  'feature_set': 'Combined (A + Scaled Enh. B)',\n",
       "  'accuracy': 0.7007874015748031,\n",
       "  'f1_score_TSR': 0.7164179104477612,\n",
       "  'f1_score_macro': 0.6998756218905473,\n",
       "  'f1_score_weighted': 0.7005268930935871,\n",
       "  'classification_report_dict': {'NR (0)': {'precision': 0.6949152542372882,\n",
       "    'recall': 0.6721311475409836,\n",
       "    'f1-score': 0.6833333333333333,\n",
       "    'support': 61.0},\n",
       "   'TSR (1)': {'precision': 0.7058823529411765,\n",
       "    'recall': 0.7272727272727273,\n",
       "    'f1-score': 0.7164179104477612,\n",
       "    'support': 66.0},\n",
       "   'accuracy': 0.7007874015748031,\n",
       "   'macro avg': {'precision': 0.7003988035892323,\n",
       "    'recall': 0.6997019374068554,\n",
       "    'f1-score': 0.6998756218905473,\n",
       "    'support': 127.0},\n",
       "   'weighted avg': {'precision': 0.7006146913589939,\n",
       "    'recall': 0.7007874015748031,\n",
       "    'f1-score': 0.7005268930935871,\n",
       "    'support': 127.0}},\n",
       "  'confusion_matrix': [[41, 20], [18, 48]],\n",
       "  'training_time_seconds': 0.5725297927856445,\n",
       "  'prediction_time_seconds': 0.001998424530029297})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Train and Evaluate Models ---\n",
    "print(\"\\n--- 4.3. Training and Evaluating Models ---\")\n",
    "all_model_results_list = [] # Reset the list for a clean run\n",
    "\n",
    "# --- Logistic Regression ---\n",
    "lr_params = {'random_state': RANDOM_STATE, 'max_iter': 1000, 'solver': 'liblinear', 'class_weight': 'balanced'}\n",
    "train_and_evaluate_model(X_emb_train, y_emb_train, X_emb_test, y_emb_test,\n",
    "                         LogisticRegression(**lr_params), \"LogisticRegression\", \"Embeddings (Option A)\")\n",
    "train_and_evaluate_model(X_base_disc_train_scaled, y_base_disc_train, X_base_disc_test_scaled, y_base_disc_test,\n",
    "                         LogisticRegression(**lr_params), \"LogisticRegression\", \"Base Discrete Scaled (Option B)\")\n",
    "train_and_evaluate_model(X_enh_disc_train_scaled, y_enh_disc_train, X_enh_disc_test_scaled, y_enh_disc_test,\n",
    "                         LogisticRegression(**lr_params), \"LogisticRegression\", \"Enhanced Discrete Scaled (Option B)\")\n",
    "\n",
    "# --- Decision Tree (uses unscaled discrete features) ---\n",
    "dt_params = {'random_state': RANDOM_STATE, 'class_weight': 'balanced'}\n",
    "train_and_evaluate_model(X_emb_train, y_emb_train, X_emb_test, y_emb_test,\n",
    "                         DecisionTreeClassifier(**dt_params), \"DecisionTree\", \"Embeddings (Option A)\")\n",
    "train_and_evaluate_model(X_base_disc_train_unscaled_df, y_base_disc_train, X_base_disc_test_unscaled_df, y_base_disc_test,\n",
    "                         DecisionTreeClassifier(**dt_params), \"DecisionTree\", \"Base Discrete Unscaled (Option B)\")\n",
    "train_and_evaluate_model(X_enh_disc_train_unscaled_df, y_enh_disc_train, X_enh_disc_test_unscaled_df, y_enh_disc_test,\n",
    "                         DecisionTreeClassifier(**dt_params), \"DecisionTree\", \"Enhanced Discrete Unscaled (Option B)\")\n",
    "\n",
    "\n",
    "# --- Random Forest (uses unscaled discrete features) ---\n",
    "rf_params = {'random_state': RANDOM_STATE, 'class_weight': 'balanced', 'n_jobs': -1}\n",
    "train_and_evaluate_model(X_emb_train, y_emb_train, X_emb_test, y_emb_test,\n",
    "                         RandomForestClassifier(**rf_params), \"RandomForest\", \"Embeddings (Option A)\")\n",
    "train_and_evaluate_model(X_base_disc_train_unscaled_df, y_base_disc_train, X_base_disc_test_unscaled_df, y_base_disc_test,\n",
    "                         RandomForestClassifier(**rf_params), \"RandomForest\", \"Base Discrete Unscaled (Option B)\")\n",
    "train_and_evaluate_model(X_enh_disc_train_unscaled_df, y_enh_disc_train, X_enh_disc_test_unscaled_df, y_enh_disc_test,\n",
    "                         RandomForestClassifier(**rf_params), \"RandomForest\", \"Enhanced Discrete Unscaled (Option B)\")\n",
    "train_and_evaluate_model(X_combined_train, y_combined_train, X_combined_test, y_combined_test,\n",
    "                         RandomForestClassifier(**rf_params), \"RandomForest\", \"Combined (A + Scaled Enh. B)\")\n",
    "\n",
    "\n",
    "# --- LightGBM (can handle unscaled discrete features well) ---\n",
    "lgbm_params = {'random_state': RANDOM_STATE, 'class_weight': 'balanced', 'verbose': -1}\n",
    "train_and_evaluate_model(X_emb_train, y_emb_train, X_emb_test, y_emb_test,\n",
    "                         lgb.LGBMClassifier(**lgbm_params), \"LightGBM\", \"Embeddings (Option A)\")\n",
    "train_and_evaluate_model(X_base_disc_train_unscaled_df, y_base_disc_train, X_base_disc_test_unscaled_df, y_base_disc_test, # Using unscaled for LGBM\n",
    "                         lgb.LGBMClassifier(**lgbm_params), \"LightGBM\", \"Base Discrete Unscaled (Option B)\")\n",
    "train_and_evaluate_model(X_enh_disc_train_unscaled_df, y_enh_disc_train, X_enh_disc_test_unscaled_df, y_enh_disc_test, # Using unscaled for LGBM\n",
    "                         lgb.LGBMClassifier(**lgbm_params), \"LightGBM\", \"Enhanced Discrete Unscaled (Option B)\")\n",
    "train_and_evaluate_model(X_combined_train, y_combined_train, X_combined_test, y_combined_test, # Combined includes scaled discrete\n",
    "                         lgb.LGBMClassifier(**lgbm_params), \"LightGBM\", \"Combined (A + Scaled Enh. B)\")\n",
    "\n",
    "\n",
    "# --- SVM (uses scaled features) ---\n",
    "svm_params = {'random_state': RANDOM_STATE, 'class_weight': 'balanced', 'probability': True} # probability=True for some metrics if needed, but slows training\n",
    "train_and_evaluate_model(X_emb_train, y_emb_train, X_emb_test, y_emb_test,\n",
    "                         SVC(**svm_params), \"SVM\", \"Embeddings (Option A)\")\n",
    "train_and_evaluate_model(X_base_disc_train_scaled, y_base_disc_train, X_base_disc_test_scaled, y_base_disc_test,\n",
    "                         SVC(**svm_params), \"SVM\", \"Base Discrete Scaled (Option B)\")\n",
    "train_and_evaluate_model(X_enh_disc_train_scaled, y_enh_disc_train, X_enh_disc_test_scaled, y_enh_disc_test,\n",
    "                         SVC(**svm_params), \"SVM\", \"Enhanced Discrete Scaled (Option B)\")\n",
    "train_and_evaluate_model(X_combined_train, y_combined_train, X_combined_test, y_combined_test,\n",
    "                         SVC(**svm_params), \"SVM\", \"Combined (A + Scaled Enh. B)\")\n",
    "\n",
    "\n",
    "# --- MLP (uses scaled features) ---\n",
    "mlp_params = {'random_state': RANDOM_STATE, 'max_iter': 1000, 'early_stopping': True, 'hidden_layer_sizes': (100, 50)} # Example architecture\n",
    "train_and_evaluate_model(X_emb_train, y_emb_train, X_emb_test, y_emb_test,\n",
    "                         MLPClassifier(**mlp_params), \"MLP\", \"Embeddings (Option A)\")\n",
    "train_and_evaluate_model(X_base_disc_train_scaled, y_base_disc_train, X_base_disc_test_scaled, y_base_disc_test,\n",
    "                         MLPClassifier(**mlp_params), \"MLP\", \"Base Discrete Scaled (Option B)\")\n",
    "train_and_evaluate_model(X_enh_disc_train_scaled, y_enh_disc_train, X_enh_disc_test_scaled, y_enh_disc_test,\n",
    "                         MLPClassifier(**mlp_params), \"MLP\", \"Enhanced Discrete Scaled (Option B)\")\n",
    "train_and_evaluate_model(X_combined_train, y_combined_train, X_combined_test, y_combined_test,\n",
    "                         MLPClassifier(**mlp_params), \"MLP\", \"Combined (A + Scaled Enh. B)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45edf932",
   "metadata": {},
   "source": [
    "#### 4.4. Compile and Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08daa240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4.4. Final Model Performance Summary ---\n",
      "Model Performance Summary (Sorted by F1-score for TSR class):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "feature_set",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_class",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "f1_score_TSR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f1_score_macro",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "training_time_seconds",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prediction_time_seconds",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0b29ed5a-6b9b-4cb0-b8ce-bfe12f4f0e8d",
       "rows": [
        [
         "8",
         "RandomForest on Enhanced Discrete Unscaled (Option B)",
         "Enhanced Discrete Unscaled (Option B)",
         "RandomForest",
         "0.7445255474452555",
         "0.7226901241499781",
         "0.7244094488188977",
         "0.25255537033081055",
         "0.04806661605834961"
        ],
        [
         "14",
         "SVM on Embeddings (Option A)",
         "Embeddings (Option A)",
         "SVM",
         "0.7230769230769231",
         "0.7163771712158808",
         "0.7165354330708661",
         "0.2565762996673584",
         "0.019513607025146484"
        ],
        [
         "6",
         "RandomForest on Embeddings (Option A)",
         "Embeddings (Option A)",
         "RandomForest",
         "0.7205882352941176",
         "0.6992771684945165",
         "0.7007874015748031",
         "0.26078367233276367",
         "0.04703974723815918"
        ],
        [
         "17",
         "SVM on Combined (A + Scaled Enh. B)",
         "Combined (A + Scaled Enh. B)",
         "SVM",
         "0.7205882352941176",
         "0.6992771684945165",
         "0.7007874015748031",
         "0.22800707817077637",
         "0.019999980926513672"
        ],
        [
         "21",
         "MLP on Combined (A + Scaled Enh. B)",
         "Combined (A + Scaled Enh. B)",
         "MLP",
         "0.7164179104477612",
         "0.6998756218905473",
         "0.7007874015748031",
         "0.5725297927856445",
         "0.001998424530029297"
        ],
        [
         "10",
         "LightGBM on Embeddings (Option A)",
         "Embeddings (Option A)",
         "LightGBM",
         "0.7111111111111111",
         "0.6916900093370681",
         "0.6929133858267716",
         "0.5799911022186279",
         "0.0020046234130859375"
        ],
        [
         "0",
         "LogisticRegression on Embeddings (Option A)",
         "Embeddings (Option A)",
         "LogisticRegression",
         "0.7014925373134329",
         "0.6840796019900497",
         "0.6850393700787402",
         "0.017002582550048828",
         "0.0009963512420654297"
        ],
        [
         "18",
         "MLP on Embeddings (Option A)",
         "Embeddings (Option A)",
         "MLP",
         "0.696969696969697",
         "0.6845504222553402",
         "0.6850393700787402",
         "0.4063129425048828",
         "0.0039975643157958984"
        ],
        [
         "16",
         "SVM on Enhanced Discrete Scaled (Option B)",
         "Enhanced Discrete Scaled (Option B)",
         "SVM",
         "0.6956521739130435",
         "0.6667916041979011",
         "0.6692913385826772",
         "0.07436084747314453",
         "0.006511688232421875"
        ],
        [
         "7",
         "RandomForest on Base Discrete Unscaled (Option B)",
         "Base Discrete Unscaled (Option B)",
         "RandomForest",
         "0.6861313868613139",
         "0.6593050096699732",
         "0.6614173228346457",
         "0.25018310546875",
         "0.04230189323425293"
        ],
        [
         "12",
         "LightGBM on Enhanced Discrete Unscaled (Option B)",
         "Enhanced Discrete Unscaled (Option B)",
         "LightGBM",
         "0.676056338028169",
         "0.6326710261569417",
         "0.6377952755905512",
         "0.055519819259643555",
         "0.002999544143676758"
        ],
        [
         "2",
         "LogisticRegression on Enhanced Discrete Scaled (Option B)",
         "Enhanced Discrete Scaled (Option B)",
         "LogisticRegression",
         "0.671875",
         "0.6692708333333333",
         "0.6692913385826772",
         "0.003971576690673828",
         "0.0"
        ],
        [
         "13",
         "LightGBM on Combined (A + Scaled Enh. B)",
         "Combined (A + Scaled Enh. B)",
         "LightGBM",
         "0.6614173228346457",
         "0.6614173228346457",
         "0.6614173228346457",
         "0.43012547492980957",
         "0.0030002593994140625"
        ],
        [
         "20",
         "MLP on Enhanced Discrete Scaled (Option B)",
         "Enhanced Discrete Scaled (Option B)",
         "MLP",
         "0.656934306569343",
         "0.6276124524299707",
         "0.6299212598425197",
         "0.13390398025512695",
         "0.001001596450805664"
        ],
        [
         "9",
         "RandomForest on Combined (A + Scaled Enh. B)",
         "Combined (A + Scaled Enh. B)",
         "RandomForest",
         "0.6564885496183206",
         "0.6453174455408677",
         "0.6456692913385826",
         "0.2693593502044678",
         "0.03941750526428223"
        ],
        [
         "5",
         "DecisionTree on Enhanced Discrete Unscaled (Option B)",
         "Enhanced Discrete Unscaled (Option B)",
         "DecisionTree",
         "0.6277372262773723",
         "0.5959198951899682",
         "0.5984251968503937",
         "0.009999275207519531",
         "0.0010025501251220703"
        ],
        [
         "19",
         "MLP on Base Discrete Scaled (Option B)",
         "Base Discrete Scaled (Option B)",
         "MLP",
         "0.609271523178808",
         "0.5182279945991127",
         "0.5354330708661418",
         "0.19896245002746582",
         "0.0"
        ],
        [
         "11",
         "LightGBM on Base Discrete Unscaled (Option B)",
         "Base Discrete Unscaled (Option B)",
         "LightGBM",
         "0.5925925925925926",
         "0.5652038593215063",
         "0.5669291338582677",
         "0.04152274131774902",
         "0.0030014514923095703"
        ],
        [
         "1",
         "LogisticRegression on Base Discrete Scaled (Option B)",
         "Base Discrete Scaled (Option B)",
         "LogisticRegression",
         "0.5846153846153846",
         "0.5745657568238214",
         "0.5748031496062992",
         "0.0020008087158203125",
         "0.0"
        ],
        [
         "15",
         "SVM on Base Discrete Scaled (Option B)",
         "Base Discrete Scaled (Option B)",
         "SVM",
         "0.5691056910569106",
         "0.5822627691925775",
         "0.5826771653543307",
         "0.06700801849365234",
         "0.00650477409362793"
        ],
        [
         "3",
         "DecisionTree on Embeddings (Option A)",
         "Embeddings (Option A)",
         "DecisionTree",
         "0.5185185185185185",
         "0.4861500155617803",
         "0.4881889763779528",
         "0.23421835899353027",
         "0.0009996891021728516"
        ],
        [
         "4",
         "DecisionTree on Base Discrete Unscaled (Option B)",
         "Base Discrete Unscaled (Option B)",
         "DecisionTree",
         "0.5079365079365079",
         "0.511780753968254",
         "0.5118110236220472",
         "0.0075130462646484375",
         "0.0020003318786621094"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 22
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>model_class</th>\n",
       "      <th>f1_score_TSR</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>training_time_seconds</th>\n",
       "      <th>prediction_time_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForest on Enhanced Discrete Unscaled (Op...</td>\n",
       "      <td>Enhanced Discrete Unscaled (Option B)</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.722690</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.252555</td>\n",
       "      <td>0.048067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVM on Embeddings (Option A)</td>\n",
       "      <td>Embeddings (Option A)</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.716377</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>0.256576</td>\n",
       "      <td>0.019514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest on Embeddings (Option A)</td>\n",
       "      <td>Embeddings (Option A)</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.699277</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>0.260784</td>\n",
       "      <td>0.047040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM on Combined (A + Scaled Enh. B)</td>\n",
       "      <td>Combined (A + Scaled Enh. B)</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.699277</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>0.228007</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MLP on Combined (A + Scaled Enh. B)</td>\n",
       "      <td>Combined (A + Scaled Enh. B)</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.699876</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>0.572530</td>\n",
       "      <td>0.001998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBM on Embeddings (Option A)</td>\n",
       "      <td>Embeddings (Option A)</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.691690</td>\n",
       "      <td>0.692913</td>\n",
       "      <td>0.579991</td>\n",
       "      <td>0.002005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression on Embeddings (Option A)</td>\n",
       "      <td>Embeddings (Option A)</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.684080</td>\n",
       "      <td>0.685039</td>\n",
       "      <td>0.017003</td>\n",
       "      <td>0.000996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MLP on Embeddings (Option A)</td>\n",
       "      <td>Embeddings (Option A)</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.684550</td>\n",
       "      <td>0.685039</td>\n",
       "      <td>0.406313</td>\n",
       "      <td>0.003998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVM on Enhanced Discrete Scaled (Option B)</td>\n",
       "      <td>Enhanced Discrete Scaled (Option B)</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.666792</td>\n",
       "      <td>0.669291</td>\n",
       "      <td>0.074361</td>\n",
       "      <td>0.006512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForest on Base Discrete Unscaled (Option B)</td>\n",
       "      <td>Base Discrete Unscaled (Option B)</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.686131</td>\n",
       "      <td>0.659305</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.250183</td>\n",
       "      <td>0.042302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBM on Enhanced Discrete Unscaled (Option B)</td>\n",
       "      <td>Enhanced Discrete Unscaled (Option B)</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.632671</td>\n",
       "      <td>0.637795</td>\n",
       "      <td>0.055520</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression on Enhanced Discrete Scaled...</td>\n",
       "      <td>Enhanced Discrete Scaled (Option B)</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.669271</td>\n",
       "      <td>0.669291</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBM on Combined (A + Scaled Enh. B)</td>\n",
       "      <td>Combined (A + Scaled Enh. B)</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.430125</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MLP on Enhanced Discrete Scaled (Option B)</td>\n",
       "      <td>Enhanced Discrete Scaled (Option B)</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.656934</td>\n",
       "      <td>0.627612</td>\n",
       "      <td>0.629921</td>\n",
       "      <td>0.133904</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForest on Combined (A + Scaled Enh. B)</td>\n",
       "      <td>Combined (A + Scaled Enh. B)</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.656489</td>\n",
       "      <td>0.645317</td>\n",
       "      <td>0.645669</td>\n",
       "      <td>0.269359</td>\n",
       "      <td>0.039418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTree on Enhanced Discrete Unscaled (Op...</td>\n",
       "      <td>Enhanced Discrete Unscaled (Option B)</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.627737</td>\n",
       "      <td>0.595920</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>0.001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MLP on Base Discrete Scaled (Option B)</td>\n",
       "      <td>Base Discrete Scaled (Option B)</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.518228</td>\n",
       "      <td>0.535433</td>\n",
       "      <td>0.198962</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBM on Base Discrete Unscaled (Option B)</td>\n",
       "      <td>Base Discrete Unscaled (Option B)</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.565204</td>\n",
       "      <td>0.566929</td>\n",
       "      <td>0.041523</td>\n",
       "      <td>0.003001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression on Base Discrete Scaled (Op...</td>\n",
       "      <td>Base Discrete Scaled (Option B)</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.574566</td>\n",
       "      <td>0.574803</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVM on Base Discrete Scaled (Option B)</td>\n",
       "      <td>Base Discrete Scaled (Option B)</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.569106</td>\n",
       "      <td>0.582263</td>\n",
       "      <td>0.582677</td>\n",
       "      <td>0.067008</td>\n",
       "      <td>0.006505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTree on Embeddings (Option A)</td>\n",
       "      <td>Embeddings (Option A)</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.486150</td>\n",
       "      <td>0.488189</td>\n",
       "      <td>0.234218</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree on Base Discrete Unscaled (Option B)</td>\n",
       "      <td>Base Discrete Unscaled (Option B)</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.511781</td>\n",
       "      <td>0.511811</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model_name  \\\n",
       "8   RandomForest on Enhanced Discrete Unscaled (Op...   \n",
       "14                       SVM on Embeddings (Option A)   \n",
       "6               RandomForest on Embeddings (Option A)   \n",
       "17                SVM on Combined (A + Scaled Enh. B)   \n",
       "21                MLP on Combined (A + Scaled Enh. B)   \n",
       "10                  LightGBM on Embeddings (Option A)   \n",
       "0         LogisticRegression on Embeddings (Option A)   \n",
       "18                       MLP on Embeddings (Option A)   \n",
       "16         SVM on Enhanced Discrete Scaled (Option B)   \n",
       "7   RandomForest on Base Discrete Unscaled (Option B)   \n",
       "12  LightGBM on Enhanced Discrete Unscaled (Option B)   \n",
       "2   LogisticRegression on Enhanced Discrete Scaled...   \n",
       "13           LightGBM on Combined (A + Scaled Enh. B)   \n",
       "20         MLP on Enhanced Discrete Scaled (Option B)   \n",
       "9        RandomForest on Combined (A + Scaled Enh. B)   \n",
       "5   DecisionTree on Enhanced Discrete Unscaled (Op...   \n",
       "19             MLP on Base Discrete Scaled (Option B)   \n",
       "11      LightGBM on Base Discrete Unscaled (Option B)   \n",
       "1   LogisticRegression on Base Discrete Scaled (Op...   \n",
       "15             SVM on Base Discrete Scaled (Option B)   \n",
       "3               DecisionTree on Embeddings (Option A)   \n",
       "4   DecisionTree on Base Discrete Unscaled (Option B)   \n",
       "\n",
       "                              feature_set         model_class  f1_score_TSR  \\\n",
       "8   Enhanced Discrete Unscaled (Option B)        RandomForest      0.744526   \n",
       "14                  Embeddings (Option A)                 SVM      0.723077   \n",
       "6                   Embeddings (Option A)        RandomForest      0.720588   \n",
       "17           Combined (A + Scaled Enh. B)                 SVM      0.720588   \n",
       "21           Combined (A + Scaled Enh. B)                 MLP      0.716418   \n",
       "10                  Embeddings (Option A)            LightGBM      0.711111   \n",
       "0                   Embeddings (Option A)  LogisticRegression      0.701493   \n",
       "18                  Embeddings (Option A)                 MLP      0.696970   \n",
       "16    Enhanced Discrete Scaled (Option B)                 SVM      0.695652   \n",
       "7       Base Discrete Unscaled (Option B)        RandomForest      0.686131   \n",
       "12  Enhanced Discrete Unscaled (Option B)            LightGBM      0.676056   \n",
       "2     Enhanced Discrete Scaled (Option B)  LogisticRegression      0.671875   \n",
       "13           Combined (A + Scaled Enh. B)            LightGBM      0.661417   \n",
       "20    Enhanced Discrete Scaled (Option B)                 MLP      0.656934   \n",
       "9            Combined (A + Scaled Enh. B)        RandomForest      0.656489   \n",
       "5   Enhanced Discrete Unscaled (Option B)        DecisionTree      0.627737   \n",
       "19        Base Discrete Scaled (Option B)                 MLP      0.609272   \n",
       "11      Base Discrete Unscaled (Option B)            LightGBM      0.592593   \n",
       "1         Base Discrete Scaled (Option B)  LogisticRegression      0.584615   \n",
       "15        Base Discrete Scaled (Option B)                 SVM      0.569106   \n",
       "3                   Embeddings (Option A)        DecisionTree      0.518519   \n",
       "4       Base Discrete Unscaled (Option B)        DecisionTree      0.507937   \n",
       "\n",
       "    f1_score_macro  accuracy  training_time_seconds  prediction_time_seconds  \n",
       "8         0.722690  0.724409               0.252555                 0.048067  \n",
       "14        0.716377  0.716535               0.256576                 0.019514  \n",
       "6         0.699277  0.700787               0.260784                 0.047040  \n",
       "17        0.699277  0.700787               0.228007                 0.020000  \n",
       "21        0.699876  0.700787               0.572530                 0.001998  \n",
       "10        0.691690  0.692913               0.579991                 0.002005  \n",
       "0         0.684080  0.685039               0.017003                 0.000996  \n",
       "18        0.684550  0.685039               0.406313                 0.003998  \n",
       "16        0.666792  0.669291               0.074361                 0.006512  \n",
       "7         0.659305  0.661417               0.250183                 0.042302  \n",
       "12        0.632671  0.637795               0.055520                 0.003000  \n",
       "2         0.669271  0.669291               0.003972                 0.000000  \n",
       "13        0.661417  0.661417               0.430125                 0.003000  \n",
       "20        0.627612  0.629921               0.133904                 0.001002  \n",
       "9         0.645317  0.645669               0.269359                 0.039418  \n",
       "5         0.595920  0.598425               0.009999                 0.001003  \n",
       "19        0.518228  0.535433               0.198962                 0.000000  \n",
       "11        0.565204  0.566929               0.041523                 0.003001  \n",
       "1         0.574566  0.574803               0.002001                 0.000000  \n",
       "15        0.582263  0.582677               0.067008                 0.006505  \n",
       "3         0.486150  0.488189               0.234218                 0.001000  \n",
       "4         0.511781  0.511811               0.007513                 0.002000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model performance summary saved to model_performance_summary.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 4.4. Final Model Performance Summary ---\")\n",
    "if all_model_results_list:\n",
    "    df_all_results = pd.DataFrame(all_model_results_list)\n",
    "    # Select and order columns for better readability\n",
    "    display_cols = [\n",
    "        \"model_name\", \"feature_set\", \"model_class\",\n",
    "        \"f1_score_TSR\", \"f1_score_macro\", \"accuracy\",\n",
    "        \"training_time_seconds\", \"prediction_time_seconds\"\n",
    "    ]\n",
    "    # Ensure all display_cols exist in the dataframe, add if missing with NaN\n",
    "    for col in display_cols:\n",
    "        if col not in df_all_results.columns:\n",
    "            df_all_results[col] = np.nan\n",
    "\n",
    "    df_all_results_sorted = df_all_results.sort_values(by='f1_score_TSR', ascending=False)\n",
    "    print(\"Model Performance Summary (Sorted by F1-score for TSR class):\")\n",
    "    display(df_all_results_sorted[display_cols])\n",
    "\n",
    "    # Save results to CSV\n",
    "    try:\n",
    "        df_all_results_sorted.to_csv(\"model_performance_summary.csv\", index=False)\n",
    "        print(\"\\nModel performance summary saved to model_performance_summary.csv\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model performance summary: {e}\")\n",
    "else:\n",
    "    print(\"No model results available to display or save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69fc6fc",
   "metadata": {},
   "source": [
    "## **🎯 Advanced Model Improvement Strategy**\n",
    "\n",
    "The proposal targets two key areas:\n",
    "\n",
    "1. **Improving Representation Learning:** Moving beyond off-the-shelf sentence embeddings to task-specific fine-tuned transformer embeddings.\n",
    "2. **Improving Model Architecture:** Combining these powerful embeddings with your hand-crafted features and using a more complex classifier like a multi-layer perceptron (MLP).\n",
    "\n",
    "We'll use the Hugging Face `transformers` library for fine-tuning (which is free and open-source) and `PyTorch` or `TensorFlow/Keras` for building and training the models. Google Colab offers free GPU resources, which will be essential for fine-tuning.\n",
    "\n",
    "### **5. Enhanced Representation Learning & Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9116226",
   "metadata": {},
   "source": [
    "### **5.1. Beyond Off-the-Shelf Embeddings: Fine-tuning Transformers**\n",
    "\n",
    "While models like `all-MiniLM-L6-v2` provide good general-purpose sentence embeddings, they might not capture the specific nuances required to differentiate between NR and TSR reading tasks in the ZuCo dataset. Fine-tuning a transformer model on your specific task can lead to embeddings that are much more discriminative.\n",
    "\n",
    "**Approach: Domain-Specific Fine-Tuning of a BERT-like Model**\n",
    "\n",
    "We'll take a pre-trained BERT model (e.g., `bert-base-uncased` as it's a good, manageable starting point) and fine-tune it as a sentence classifier on your NR/TSR labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84483039",
   "metadata": {},
   "source": [
    "#### **5.1.1. Setup and Libraries**\n",
    "\n",
    "First, ensure necessary libraries are installed. `transformers`, `torch` (or `tensorflow`), and `datasets` (from Hugging Face, useful for handling data) will be key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "734c4fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- Add to your library imports section ---\n",
    "# pip install transformers torch datasets scikit-learn\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Device Configuration (Important for Colab) ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf1b497",
   "metadata": {},
   "source": [
    "#### **5.1.2. Custom PyTorch Dataset**\n",
    "\n",
    "We need a custom `Dataset` class to feed our sentences and labels to the BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e2757a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom Dataset Class ---\n",
    "class ZuCoSentenceDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length', # Changed from 'pad_to_max_length' which is deprecated\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# --- Tokenizer and Max Length ---\n",
    "MODEL_NAME = 'bert-base-uncased' # Or another model like 'roberta-base', 'microsoft/deberta-base'\n",
    "TOKENIZER = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "# Determine MAX_LEN: analyze your sentence lengths (e.g., 95th percentile) or start with a common value.\n",
    "# Let's assume your EDA (from combined_df['word_length']) showed most sentences are < 128 words.\n",
    "# BERT tokens can be more, so maybe MAX_LEN = 128 or 256.\n",
    "MAX_LEN = 128 # Adjust based on your data analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ecc29",
   "metadata": {},
   "source": [
    "#### **5.1.3. Fine-tuning Loop with Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db90627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "Train -> Loss: 0.6373, Accuracy: 0.6220, F1-Macro: 0.6201, F1-TSR: 0.6471\n",
      "Train -> Loss: 0.6373, Accuracy: 0.6220, F1-Macro: 0.6201, F1-TSR: 0.6471\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.70      0.67        61\n",
      "           1       0.69      0.62      0.66        66\n",
      "\n",
      "    accuracy                           0.66       127\n",
      "   macro avg       0.66      0.66      0.66       127\n",
      "weighted avg       0.66      0.66      0.66       127\n",
      "\n",
      "Val   -> Loss: 0.5993, Accuracy: 0.6614, F1-Macro: 0.6613, F1-TSR: 0.6560\n",
      "New best F1-TSR on validation: 0.6560\n",
      "Epoch 2/4\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.70      0.67        61\n",
      "           1       0.69      0.62      0.66        66\n",
      "\n",
      "    accuracy                           0.66       127\n",
      "   macro avg       0.66      0.66      0.66       127\n",
      "weighted avg       0.66      0.66      0.66       127\n",
      "\n",
      "Val   -> Loss: 0.5993, Accuracy: 0.6614, F1-Macro: 0.6613, F1-TSR: 0.6560\n",
      "New best F1-TSR on validation: 0.6560\n",
      "Epoch 2/4\n",
      "Train -> Loss: 0.5186, Accuracy: 0.7756, F1-Macro: 0.7752, F1-TSR: 0.7664\n",
      "Train -> Loss: 0.5186, Accuracy: 0.7756, F1-Macro: 0.7752, F1-TSR: 0.7664\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71        61\n",
      "           1       0.73      0.74      0.74        66\n",
      "\n",
      "    accuracy                           0.72       127\n",
      "   macro avg       0.72      0.72      0.72       127\n",
      "weighted avg       0.72      0.72      0.72       127\n",
      "\n",
      "Val   -> Loss: 0.5859, Accuracy: 0.7244, F1-Macro: 0.7238, F1-TSR: 0.7368\n",
      "New best F1-TSR on validation: 0.7368\n",
      "Epoch 3/4\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71        61\n",
      "           1       0.73      0.74      0.74        66\n",
      "\n",
      "    accuracy                           0.72       127\n",
      "   macro avg       0.72      0.72      0.72       127\n",
      "weighted avg       0.72      0.72      0.72       127\n",
      "\n",
      "Val   -> Loss: 0.5859, Accuracy: 0.7244, F1-Macro: 0.7238, F1-TSR: 0.7368\n",
      "New best F1-TSR on validation: 0.7368\n",
      "Epoch 3/4\n",
      "Train -> Loss: 0.4425, Accuracy: 0.8307, F1-Macro: 0.8306, F1-TSR: 0.8346\n",
      "Train -> Loss: 0.4425, Accuracy: 0.8307, F1-Macro: 0.8306, F1-TSR: 0.8346\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        61\n",
      "           1       0.74      0.77      0.76        66\n",
      "\n",
      "    accuracy                           0.74       127\n",
      "   macro avg       0.74      0.74      0.74       127\n",
      "weighted avg       0.74      0.74      0.74       127\n",
      "\n",
      "Val   -> Loss: 0.5907, Accuracy: 0.7402, F1-Macro: 0.7391, F1-TSR: 0.7556\n",
      "New best F1-TSR on validation: 0.7556\n",
      "Epoch 4/4\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        61\n",
      "           1       0.74      0.77      0.76        66\n",
      "\n",
      "    accuracy                           0.74       127\n",
      "   macro avg       0.74      0.74      0.74       127\n",
      "weighted avg       0.74      0.74      0.74       127\n",
      "\n",
      "Val   -> Loss: 0.5907, Accuracy: 0.7402, F1-Macro: 0.7391, F1-TSR: 0.7556\n",
      "New best F1-TSR on validation: 0.7556\n",
      "Epoch 4/4\n",
      "Train -> Loss: 0.3608, Accuracy: 0.8720, F1-Macro: 0.8720, F1-TSR: 0.8752\n",
      "Train -> Loss: 0.3608, Accuracy: 0.8720, F1-Macro: 0.8720, F1-TSR: 0.8752\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.64      0.68        61\n",
      "           1       0.70      0.79      0.74        66\n",
      "\n",
      "    accuracy                           0.72       127\n",
      "   macro avg       0.72      0.71      0.71       127\n",
      "weighted avg       0.72      0.72      0.71       127\n",
      "\n",
      "Val   -> Loss: 0.5967, Accuracy: 0.7165, F1-Macro: 0.7135, F1-TSR: 0.7429\n",
      "Early stopping triggered after 4 epochs for fold 1.\n",
      "--- Fold 2/5 ---\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.64      0.68        61\n",
      "           1       0.70      0.79      0.74        66\n",
      "\n",
      "    accuracy                           0.72       127\n",
      "   macro avg       0.72      0.71      0.71       127\n",
      "weighted avg       0.72      0.72      0.71       127\n",
      "\n",
      "Val   -> Loss: 0.5967, Accuracy: 0.7165, F1-Macro: 0.7135, F1-TSR: 0.7429\n",
      "Early stopping triggered after 4 epochs for fold 1.\n",
      "--- Fold 2/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "Train -> Loss: 0.6374, Accuracy: 0.6181, F1-Macro: 0.6180, F1-TSR: 0.6120\n",
      "Train -> Loss: 0.6374, Accuracy: 0.6181, F1-Macro: 0.6180, F1-TSR: 0.6120\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.87      0.74        61\n",
      "           1       0.82      0.56      0.67        66\n",
      "\n",
      "    accuracy                           0.71       127\n",
      "   macro avg       0.73      0.71      0.70       127\n",
      "weighted avg       0.74      0.71      0.70       127\n",
      "\n",
      "Val   -> Loss: 0.5772, Accuracy: 0.7087, F1-Macro: 0.7040, F1-TSR: 0.6667\n",
      "New best F1-TSR on validation: 0.6667\n",
      "Epoch 2/4\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.87      0.74        61\n",
      "           1       0.82      0.56      0.67        66\n",
      "\n",
      "    accuracy                           0.71       127\n",
      "   macro avg       0.73      0.71      0.70       127\n",
      "weighted avg       0.74      0.71      0.70       127\n",
      "\n",
      "Val   -> Loss: 0.5772, Accuracy: 0.7087, F1-Macro: 0.7040, F1-TSR: 0.6667\n",
      "New best F1-TSR on validation: 0.6667\n",
      "Epoch 2/4\n",
      "Train -> Loss: 0.5274, Accuracy: 0.7520, F1-Macro: 0.7520, F1-TSR: 0.7500\n",
      "Train -> Loss: 0.5274, Accuracy: 0.7520, F1-Macro: 0.7520, F1-TSR: 0.7500\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.89      0.74        61\n",
      "           1       0.84      0.55      0.66        66\n",
      "\n",
      "    accuracy                           0.71       127\n",
      "   macro avg       0.74      0.72      0.70       127\n",
      "weighted avg       0.74      0.71      0.70       127\n",
      "\n",
      "Val   -> Loss: 0.5573, Accuracy: 0.7087, F1-Macro: 0.7027, F1-TSR: 0.6606\n",
      "Early stopping triggered after 2 epochs for fold 2.\n",
      "--- Fold 3/5 ---\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.89      0.74        61\n",
      "           1       0.84      0.55      0.66        66\n",
      "\n",
      "    accuracy                           0.71       127\n",
      "   macro avg       0.74      0.72      0.70       127\n",
      "weighted avg       0.74      0.71      0.70       127\n",
      "\n",
      "Val   -> Loss: 0.5573, Accuracy: 0.7087, F1-Macro: 0.7027, F1-TSR: 0.6606\n",
      "Early stopping triggered after 2 epochs for fold 2.\n",
      "--- Fold 3/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "Train -> Loss: 0.6635, Accuracy: 0.5709, F1-Macro: 0.5694, F1-TSR: 0.5948\n",
      "Train -> Loss: 0.6635, Accuracy: 0.5709, F1-Macro: 0.5694, F1-TSR: 0.5948\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75        61\n",
      "           1       0.79      0.70      0.74        66\n",
      "\n",
      "    accuracy                           0.75       127\n",
      "   macro avg       0.75      0.75      0.75       127\n",
      "weighted avg       0.75      0.75      0.75       127\n",
      "\n",
      "Val   -> Loss: 0.5709, Accuracy: 0.7480, F1-Macro: 0.7479, F1-TSR: 0.7419\n",
      "New best F1-TSR on validation: 0.7419\n",
      "Epoch 2/4\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75        61\n",
      "           1       0.79      0.70      0.74        66\n",
      "\n",
      "    accuracy                           0.75       127\n",
      "   macro avg       0.75      0.75      0.75       127\n",
      "weighted avg       0.75      0.75      0.75       127\n",
      "\n",
      "Val   -> Loss: 0.5709, Accuracy: 0.7480, F1-Macro: 0.7479, F1-TSR: 0.7419\n",
      "New best F1-TSR on validation: 0.7419\n",
      "Epoch 2/4\n",
      "Train -> Loss: 0.5098, Accuracy: 0.7697, F1-Macro: 0.7697, F1-TSR: 0.7674\n",
      "Train -> Loss: 0.5098, Accuracy: 0.7697, F1-Macro: 0.7697, F1-TSR: 0.7674\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76        61\n",
      "           1       0.78      0.77      0.78        66\n",
      "\n",
      "    accuracy                           0.77       127\n",
      "   macro avg       0.77      0.77      0.77       127\n",
      "weighted avg       0.77      0.77      0.77       127\n",
      "\n",
      "Val   -> Loss: 0.5146, Accuracy: 0.7717, F1-Macro: 0.7714, F1-TSR: 0.7786\n",
      "New best F1-TSR on validation: 0.7786\n",
      "Epoch 3/4\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76        61\n",
      "           1       0.78      0.77      0.78        66\n",
      "\n",
      "    accuracy                           0.77       127\n",
      "   macro avg       0.77      0.77      0.77       127\n",
      "weighted avg       0.77      0.77      0.77       127\n",
      "\n",
      "Val   -> Loss: 0.5146, Accuracy: 0.7717, F1-Macro: 0.7714, F1-TSR: 0.7786\n",
      "New best F1-TSR on validation: 0.7786\n",
      "Epoch 3/4\n",
      "Train -> Loss: 0.3933, Accuracy: 0.8465, F1-Macro: 0.8463, F1-TSR: 0.8511\n",
      "Train -> Loss: 0.3933, Accuracy: 0.8465, F1-Macro: 0.8463, F1-TSR: 0.8511\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78        61\n",
      "           1       0.80      0.79      0.79        66\n",
      "\n",
      "    accuracy                           0.79       127\n",
      "   macro avg       0.79      0.79      0.79       127\n",
      "weighted avg       0.79      0.79      0.79       127\n",
      "\n",
      "Val   -> Loss: 0.4948, Accuracy: 0.7874, F1-Macro: 0.7872, F1-TSR: 0.7939\n",
      "New best F1-TSR on validation: 0.7939\n",
      "Epoch 4/4\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78        61\n",
      "           1       0.80      0.79      0.79        66\n",
      "\n",
      "    accuracy                           0.79       127\n",
      "   macro avg       0.79      0.79      0.79       127\n",
      "weighted avg       0.79      0.79      0.79       127\n",
      "\n",
      "Val   -> Loss: 0.4948, Accuracy: 0.7874, F1-Macro: 0.7872, F1-TSR: 0.7939\n",
      "New best F1-TSR on validation: 0.7939\n",
      "Epoch 4/4\n",
      "Train -> Loss: 0.3025, Accuracy: 0.9114, F1-Macro: 0.9113, F1-TSR: 0.9146\n",
      "Train -> Loss: 0.3025, Accuracy: 0.9114, F1-Macro: 0.9113, F1-TSR: 0.9146\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76        61\n",
      "           1       0.78      0.79      0.78        66\n",
      "\n",
      "    accuracy                           0.77       127\n",
      "   macro avg       0.77      0.77      0.77       127\n",
      "weighted avg       0.77      0.77      0.77       127\n",
      "\n",
      "Val   -> Loss: 0.4871, Accuracy: 0.7717, F1-Macro: 0.7711, F1-TSR: 0.7820\n",
      "Early stopping triggered after 4 epochs for fold 3.\n",
      "--- Fold 4/5 ---\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76        61\n",
      "           1       0.78      0.79      0.78        66\n",
      "\n",
      "    accuracy                           0.77       127\n",
      "   macro avg       0.77      0.77      0.77       127\n",
      "weighted avg       0.77      0.77      0.77       127\n",
      "\n",
      "Val   -> Loss: 0.4871, Accuracy: 0.7717, F1-Macro: 0.7711, F1-TSR: 0.7820\n",
      "Early stopping triggered after 4 epochs for fold 3.\n",
      "--- Fold 4/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "Train -> Loss: 0.6426, Accuracy: 0.6476, F1-Macro: 0.6428, F1-TSR: 0.6013\n",
      "Train -> Loss: 0.6426, Accuracy: 0.6476, F1-Macro: 0.6428, F1-TSR: 0.6013\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.77      0.71        61\n",
      "           1       0.75      0.62      0.68        66\n",
      "\n",
      "    accuracy                           0.69       127\n",
      "   macro avg       0.70      0.70      0.69       127\n",
      "weighted avg       0.70      0.69      0.69       127\n",
      "\n",
      "Val   -> Loss: 0.5792, Accuracy: 0.6929, F1-Macro: 0.6922, F1-TSR: 0.6777\n",
      "New best F1-TSR on validation: 0.6777\n",
      "Epoch 2/4\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.77      0.71        61\n",
      "           1       0.75      0.62      0.68        66\n",
      "\n",
      "    accuracy                           0.69       127\n",
      "   macro avg       0.70      0.70      0.69       127\n",
      "weighted avg       0.70      0.69      0.69       127\n",
      "\n",
      "Val   -> Loss: 0.5792, Accuracy: 0.6929, F1-Macro: 0.6922, F1-TSR: 0.6777\n",
      "New best F1-TSR on validation: 0.6777\n",
      "Epoch 2/4\n",
      "Train -> Loss: 0.5217, Accuracy: 0.7638, F1-Macro: 0.7635, F1-TSR: 0.7561\n",
      "Train -> Loss: 0.5217, Accuracy: 0.7638, F1-Macro: 0.7635, F1-TSR: 0.7561\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72        61\n",
      "           1       0.75      0.70      0.72        66\n",
      "\n",
      "    accuracy                           0.72       127\n",
      "   macro avg       0.73      0.73      0.72       127\n",
      "weighted avg       0.73      0.72      0.72       127\n",
      "\n",
      "Val   -> Loss: 0.5334, Accuracy: 0.7244, F1-Macro: 0.7244, F1-TSR: 0.7244\n",
      "New best F1-TSR on validation: 0.7244\n",
      "Epoch 3/4\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72        61\n",
      "           1       0.75      0.70      0.72        66\n",
      "\n",
      "    accuracy                           0.72       127\n",
      "   macro avg       0.73      0.73      0.72       127\n",
      "weighted avg       0.73      0.72      0.72       127\n",
      "\n",
      "Val   -> Loss: 0.5334, Accuracy: 0.7244, F1-Macro: 0.7244, F1-TSR: 0.7244\n",
      "New best F1-TSR on validation: 0.7244\n",
      "Epoch 3/4\n",
      "Train -> Loss: 0.4238, Accuracy: 0.8268, F1-Macro: 0.8267, F1-TSR: 0.8301\n",
      "Train -> Loss: 0.4238, Accuracy: 0.8268, F1-Macro: 0.8267, F1-TSR: 0.8301\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.75        61\n",
      "           1       0.77      0.76      0.76        66\n",
      "\n",
      "    accuracy                           0.76       127\n",
      "   macro avg       0.76      0.76      0.76       127\n",
      "weighted avg       0.76      0.76      0.76       127\n",
      "\n",
      "Val   -> Loss: 0.5056, Accuracy: 0.7559, F1-Macro: 0.7557, F1-TSR: 0.7634\n",
      "New best F1-TSR on validation: 0.7634\n",
      "Epoch 4/4\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.75        61\n",
      "           1       0.77      0.76      0.76        66\n",
      "\n",
      "    accuracy                           0.76       127\n",
      "   macro avg       0.76      0.76      0.76       127\n",
      "weighted avg       0.76      0.76      0.76       127\n",
      "\n",
      "Val   -> Loss: 0.5056, Accuracy: 0.7559, F1-Macro: 0.7557, F1-TSR: 0.7634\n",
      "New best F1-TSR on validation: 0.7634\n",
      "Epoch 4/4\n",
      "Train -> Loss: 0.3549, Accuracy: 0.8701, F1-Macro: 0.8700, F1-TSR: 0.8736\n",
      "Train -> Loss: 0.3549, Accuracy: 0.8701, F1-Macro: 0.8700, F1-TSR: 0.8736\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75        61\n",
      "           1       0.78      0.74      0.76        66\n",
      "\n",
      "    accuracy                           0.76       127\n",
      "   macro avg       0.76      0.76      0.76       127\n",
      "weighted avg       0.76      0.76      0.76       127\n",
      "\n",
      "Val   -> Loss: 0.5045, Accuracy: 0.7559, F1-Macro: 0.7558, F1-TSR: 0.7597\n",
      "Early stopping triggered after 4 epochs for fold 4.\n",
      "--- Fold 5/5 ---\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75        61\n",
      "           1       0.78      0.74      0.76        66\n",
      "\n",
      "    accuracy                           0.76       127\n",
      "   macro avg       0.76      0.76      0.76       127\n",
      "weighted avg       0.76      0.76      0.76       127\n",
      "\n",
      "Val   -> Loss: 0.5045, Accuracy: 0.7559, F1-Macro: 0.7558, F1-TSR: 0.7597\n",
      "Early stopping triggered after 4 epochs for fold 4.\n",
      "--- Fold 5/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "Train -> Loss: 0.6193, Accuracy: 0.6752, F1-Macro: 0.6735, F1-TSR: 0.6497\n",
      "Train -> Loss: 0.6193, Accuracy: 0.6752, F1-Macro: 0.6735, F1-TSR: 0.6497\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.76        60\n",
      "           1       0.82      0.67      0.74        67\n",
      "\n",
      "    accuracy                           0.75       127\n",
      "   macro avg       0.76      0.75      0.75       127\n",
      "weighted avg       0.76      0.75      0.75       127\n",
      "\n",
      "Val   -> Loss: 0.5379, Accuracy: 0.7480, F1-Macro: 0.7476, F1-TSR: 0.7377\n",
      "New best F1-TSR on validation: 0.7377\n",
      "Epoch 2/4\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.76        60\n",
      "           1       0.82      0.67      0.74        67\n",
      "\n",
      "    accuracy                           0.75       127\n",
      "   macro avg       0.76      0.75      0.75       127\n",
      "weighted avg       0.76      0.75      0.75       127\n",
      "\n",
      "Val   -> Loss: 0.5379, Accuracy: 0.7480, F1-Macro: 0.7476, F1-TSR: 0.7377\n",
      "New best F1-TSR on validation: 0.7377\n",
      "Epoch 2/4\n",
      "Train -> Loss: 0.4961, Accuracy: 0.7854, F1-Macro: 0.7854, F1-TSR: 0.7850\n",
      "Train -> Loss: 0.4961, Accuracy: 0.7854, F1-Macro: 0.7854, F1-TSR: 0.7850\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.93      0.78        60\n",
      "           1       0.91      0.60      0.72        67\n",
      "\n",
      "    accuracy                           0.76       127\n",
      "   macro avg       0.79      0.77      0.75       127\n",
      "weighted avg       0.80      0.76      0.75       127\n",
      "\n",
      "Val   -> Loss: 0.5141, Accuracy: 0.7559, F1-Macro: 0.7520, F1-TSR: 0.7207\n",
      "Early stopping triggered after 2 epochs for fold 5.\n",
      "\n",
      "--- Cross-Validation Results ---\n",
      "F1-scores for TSR class across folds: [0.7555555555555555, 0.6666666666666666, 0.7938931297709924, 0.7633587786259542, 0.7377049180327869]\n",
      "Mean F1-TSR: 0.7434 (+/- 0.0425)\n",
      "Mean F1-Macro: 0.7390 (+/- 0.0263)\n",
      "Validation Classification Report (Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.93      0.78        60\n",
      "           1       0.91      0.60      0.72        67\n",
      "\n",
      "    accuracy                           0.76       127\n",
      "   macro avg       0.79      0.77      0.75       127\n",
      "weighted avg       0.80      0.76      0.75       127\n",
      "\n",
      "Val   -> Loss: 0.5141, Accuracy: 0.7559, F1-Macro: 0.7520, F1-TSR: 0.7207\n",
      "Early stopping triggered after 2 epochs for fold 5.\n",
      "\n",
      "--- Cross-Validation Results ---\n",
      "F1-scores for TSR class across folds: [0.7555555555555555, 0.6666666666666666, 0.7938931297709924, 0.7633587786259542, 0.7377049180327869]\n",
      "Mean F1-TSR: 0.7434 (+/- 0.0425)\n",
      "Mean F1-Macro: 0.7390 (+/- 0.0263)\n"
     ]
    }
   ],
   "source": [
    "# --- Load your processed data (df_processed from your earlier steps) ---\n",
    "# Ensure df_processed has 'cleaned_sentence' and 'label' columns\n",
    "df_processed = pd.read_csv(PROCESSED_DATA_FILENAME) # If reloading\n",
    "df_processed['cleaned_sentence'] = df_processed['cleaned_sentence'].fillna('').astype(str)\n",
    "texts = df_processed['cleaned_sentence'].values\n",
    "labels = df_processed['label'].values\n",
    "\n",
    "# --- Cross-Validation Setup ---\n",
    "N_SPLITS = 5 # 5-fold CV is a good start\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# --- Hyperparameters (start with these, then tune) ---\n",
    "EPOCHS = 4 # 3-5 epochs is common for fine-tuning\n",
    "LEARNING_RATE = 2e-5\n",
    "BATCH_SIZE = 16 # 16-32, adjust based on GPU memory in Colab\n",
    "\n",
    "# --- Store CV results ---\n",
    "cv_f1_scores_macro = []\n",
    "cv_f1_scores_tsr = []\n",
    "best_models_per_fold = [] # To store the best model from each fold\n",
    "\n",
    "# --- Training Function for one fold ---\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        labels_tensor = d[\"labels\"].to(device) # Renamed to avoid conflict\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels_tensor # Pass labels for loss calculation\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        correct_predictions += torch.sum(preds == labels_tensor)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels_tensor.cpu().numpy())\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # Gradient clipping\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1_tsr = f1_score(all_labels, all_preds, pos_label=1, zero_division=0) # Assuming TSR is label 1\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses), f1_macro, f1_tsr\n",
    "\n",
    "# --- Evaluation Function for one fold ---\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            labels_tensor = d[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels_tensor\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "            correct_predictions += torch.sum(preds == labels_tensor)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels_tensor.cpu().numpy())\n",
    "\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1_tsr = f1_score(all_labels, all_preds, pos_label=1, zero_division=0)\n",
    "    accuracy = correct_predictions.double() / n_examples\n",
    "    print(f\"Validation Classification Report (Fold):\\n{classification_report(all_labels, all_preds, zero_division=0)}\")\n",
    "    return accuracy, np.mean(losses), f1_macro, f1_tsr\n",
    "\n",
    "# --- Main CV Loop ---\n",
    "if 'texts' in globals() and 'labels' in globals(): # Ensure data is loaded\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(texts, labels)):\n",
    "        print(f\"--- Fold {fold + 1}/{N_SPLITS} ---\")\n",
    "\n",
    "        train_texts, val_texts = texts[train_idx], texts[val_idx]\n",
    "        train_labels, val_labels = labels[train_idx], labels[val_idx]\n",
    "\n",
    "        train_dataset = ZuCoSentenceDataset(train_texts, train_labels, TOKENIZER, MAX_LEN)\n",
    "        val_dataset = ZuCoSentenceDataset(val_texts, val_labels, TOKENIZER, MAX_LEN)\n",
    "\n",
    "        train_data_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_data_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "        model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2) # 2 for NR/TSR\n",
    "        model = model.to(DEVICE)\n",
    "\n",
    "        optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, correct_bias=False)\n",
    "        total_steps = len(train_data_loader) * EPOCHS\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=0, # Or a small percentage like 0.1 * total_steps\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "\n",
    "        loss_fn = torch.nn.CrossEntropyLoss().to(DEVICE) # BERT model calculates it internally if labels are passed\n",
    "\n",
    "        best_val_f1_tsr = -1\n",
    "        current_best_model_state = None\n",
    "        early_stopping_patience = 1 # Number of epochs to wait for improvement\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "            train_acc, train_loss, train_f1_macro, train_f1_tsr = train_epoch(\n",
    "                model, train_data_loader, loss_fn, optimizer, DEVICE, scheduler, len(train_dataset)\n",
    "            )\n",
    "            print(f\"Train -> Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}, F1-Macro: {train_f1_macro:.4f}, F1-TSR: {train_f1_tsr:.4f}\")\n",
    "\n",
    "            val_acc, val_loss, val_f1_macro, val_f1_tsr = eval_model(\n",
    "                model, val_data_loader, loss_fn, DEVICE, len(val_dataset)\n",
    "            )\n",
    "            print(f\"Val   -> Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}, F1-Macro: {val_f1_macro:.4f}, F1-TSR: {val_f1_tsr:.4f}\")\n",
    "\n",
    "            if val_f1_tsr > best_val_f1_tsr:\n",
    "                best_val_f1_tsr = val_f1_tsr\n",
    "                # Save the best model state for this fold\n",
    "                current_best_model_state = model.state_dict()\n",
    "                epochs_no_improve = 0\n",
    "                print(f\"New best F1-TSR on validation: {best_val_f1_tsr:.4f}\")\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "\n",
    "            if epochs_no_improve >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered after {epoch + 1} epochs for fold {fold + 1}.\")\n",
    "                break\n",
    "        \n",
    "        if current_best_model_state:\n",
    "            # If you want to save the model from each fold:\n",
    "            # torch.save(current_best_model_state, f\"bert_finetuned_fold_{fold+1}.bin\")\n",
    "            # print(f\"Best model for fold {fold+1} saved with Val F1-TSR: {best_val_f1_tsr:.4f}\")\n",
    "            best_models_per_fold.append(current_best_model_state) # Store the state dict\n",
    "\n",
    "        cv_f1_scores_tsr.append(best_val_f1_tsr if best_val_f1_tsr != -1 else 0) # Use 0 if no improvement\n",
    "        cv_f1_scores_macro.append(val_f1_macro) # Or track best val_f1_macro\n",
    "\n",
    "    print(\"\\n--- Cross-Validation Results ---\")\n",
    "    print(f\"F1-scores for TSR class across folds: {cv_f1_scores_tsr}\")\n",
    "    print(f\"Mean F1-TSR: {np.mean(cv_f1_scores_tsr):.4f} (+/- {np.std(cv_f1_scores_tsr):.4f})\")\n",
    "    print(f\"Mean F1-Macro: {np.mean(cv_f1_scores_macro):.4f} (+/- {np.std(cv_f1_scores_macro):.4f})\")\n",
    "\n",
    "else:\n",
    "    print(\"Cannot run fine-tuning as 'texts' or 'labels' are not defined. Please load data first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263f0337",
   "metadata": {},
   "source": [
    "- **Principles:** Test Writing (CV is a form of robustness testing), Performance (GPU usage, `DataLoader`, gradient clipping, learning rate scheduler), Reproducibility (`RANDOM_STATE` in `StratifiedKFold`), Team and Project Management (clear logging per fold).\n",
    "- **Best Practices:**\n",
    "    - **StratifiedKFold:** Essential for maintaining class distribution.\n",
    "    - **Learning Rate Scheduler:** `get_linear_schedule_with_warmup` is common for transformers.\n",
    "    - **Gradient Clipping:** Helps prevent exploding gradients.\n",
    "    - **Early Stopping:** Your suggestion is excellent. Monitor validation loss (or F1-score on the target class like F1-TSR) and stop if it doesn't improve for a set number of epochs (patience). I've added a simple version based on `val_f1_tsr`.\n",
    "    - **Saving the Best Model:** Instead of just the last epoch, save the model state that gave the best validation performance during the fold.\n",
    "    - **Clear Logging:** Print metrics for both training and validation sets per epoch.\n",
    "\n",
    "Note on SBERT Fine-Tuning:\n",
    "\n",
    "Fine-tuning SBERT for classification involves adding a classification head on top of the pooled output (mean pooling of token embeddings is common for SBERT) and then training this head along with (or after unfreezing some layers of) the SBERT model. The sentence-transformers library has utilities for this, often using triplet loss or similar for semantic similarity, but for classification, you'd adapt it or use the base transformer directly as shown above. The approach of fine-tuning bert-base-uncased (or RoBERTa/DeBERTa) with a sequence classification head is more direct for this task.\n",
    "\n",
    "After Fine-Tuning:\n",
    "\n",
    "Once you have a fine-tuned model (either the best from one fold or an average/ensemble if you train K models), you can use it to extract embeddings. These embeddings will be more task-specific.\n",
    "\n",
    "- The output of the last hidden state of the `[CLS]` token is often used as a sentence representation.\n",
    "- Alternatively, you can average the last hidden states of all tokens in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49988626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Selecting best model from Cross-Validation ---\n",
      "Best F1-TSR score achieved: 0.7939 in Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the best model from Fold 3 for embedding extraction.\n",
      "Extracting embeddings for 635 sentences...\n",
      "Shape of fine-tuned embeddings: (635, 768)\n",
      "Shape of fine-tuned embeddings: (635, 768)\n"
     ]
    }
   ],
   "source": [
    "# --- Code to come AFTER your entire cross-validation loop has finished ---\n",
    "\n",
    "# --- 1. Determine the best fold ---\n",
    "if 'cv_f1_scores_tsr' in globals() and cv_f1_scores_tsr:\n",
    "    best_fold_index = np.argmax(cv_f1_scores_tsr)\n",
    "    best_f1_tsr_overall = cv_f1_scores_tsr[best_fold_index]\n",
    "    print(f\"\\n--- Selecting best model from Cross-Validation ---\")\n",
    "    print(f\"Best F1-TSR score achieved: {best_f1_tsr_overall:.4f} in Fold {best_fold_index + 1}\")\n",
    "\n",
    "    # --- 2. Load the state dictionary of the best model ---\n",
    "    # Ensure 'best_models_per_fold' contains the state_dict() from the best epoch of each fold\n",
    "    if 'best_models_per_fold' in globals() and len(best_models_per_fold) == N_SPLITS:\n",
    "        best_model_state_dict = best_models_per_fold[best_fold_index]\n",
    "\n",
    "        # --- 3. Initialize a new model instance and load the state_dict ---\n",
    "        model_to_extract_embeddings_from = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "        model_to_extract_embeddings_from.load_state_dict(best_model_state_dict)\n",
    "        model_to_extract_embeddings_from = model_to_extract_embeddings_from.to(DEVICE)\n",
    "        model_to_extract_embeddings_from.eval() # Set to evaluation mode\n",
    "\n",
    "        # Get the base BERT model (without the classification head)\n",
    "        bert_model_base_for_embeddings = model_to_extract_embeddings_from.bert\n",
    "        print(f\"Successfully loaded the best model from Fold {best_fold_index + 1} for embedding extraction.\")\n",
    "\n",
    "        # --- 4. Define the Embedding Extraction Function (if not already defined) ---\n",
    "        def get_fine_tuned_embeddings(texts_list, tokenizer, bert_base_model, device, max_len):\n",
    "            embeddings_list = []\n",
    "            bert_base_model.eval() # Ensure it's in eval mode\n",
    "            \n",
    "            # Create a DataLoader for efficient batching\n",
    "            temp_dataset = [{'text': text} for text in texts_list] # Minimal dataset structure\n",
    "            \n",
    "            def collate_fn_texts(batch):\n",
    "                return [item['text'] for item in batch]\n",
    "\n",
    "            data_loader = DataLoader(temp_dataset, batch_size=BATCH_SIZE*2, collate_fn=collate_fn_texts, shuffle=False) # Use a larger batch size for inference\n",
    "            \n",
    "            print(f\"Extracting embeddings for {len(texts_list)} sentences...\")\n",
    "            with torch.no_grad():\n",
    "                for text_batch in data_loader: # Iterate over batches of texts\n",
    "                    encodings = tokenizer.batch_encode_plus( # Use batch_encode_plus\n",
    "                        text_batch,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=max_len,\n",
    "                        return_token_type_ids=False,\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask=True,\n",
    "                        return_tensors='pt',\n",
    "                    )\n",
    "                    input_ids = encodings['input_ids'].to(device)\n",
    "                    attention_mask = encodings['attention_mask'].to(device)\n",
    "                    \n",
    "                    outputs = bert_base_model(input_ids, attention_mask=attention_mask)\n",
    "                    # Use the [CLS] token's representation from the last hidden state\n",
    "                    cls_embeddings_batch = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "                    embeddings_list.extend(cls_embeddings_batch)\n",
    "            return np.array(embeddings_list)\n",
    "\n",
    "        # --- 5. Extract embeddings for your entire df_processed['cleaned_sentence'] ---\n",
    "        if 'df_processed' in globals() and not df_processed.empty:\n",
    "            all_sentences_texts_for_embedding = df_processed['cleaned_sentence'].tolist()\n",
    "            \n",
    "            fine_tuned_embeddings_array = get_fine_tuned_embeddings(\n",
    "                all_sentences_texts_for_embedding, \n",
    "                TOKENIZER, # Make sure TOKENIZER is defined (BertTokenizerFast.from_pretrained(MODEL_NAME))\n",
    "                bert_model_base_for_embeddings, \n",
    "                DEVICE, \n",
    "                MAX_LEN # Make sure MAX_LEN is defined\n",
    "            )\n",
    "            print(f\"Shape of fine-tuned embeddings: {fine_tuned_embeddings_array.shape}\")\n",
    "            \n",
    "            # Now, fine_tuned_embeddings_array can be used as X in your SVM/MLP.\n",
    "            # You will need to split this new fine_tuned_embeddings_array into train/test sets\n",
    "            # using the same indices from StratifiedKFold if you want to be rigorous,\n",
    "            # or just a new stratified train_test_split for the MLP part.\n",
    "            \n",
    "            # Example of a new split for the MLP part:\n",
    "            # X_ft_emb_train, X_ft_emb_test, y_ft_emb_train, y_ft_emb_test = train_test_split(\n",
    "            #    fine_tuned_embeddings_array, labels_array, # labels_array from your original data\n",
    "            #    test_size=0.2, random_state=RANDOM_STATE, stratify=labels_array\n",
    "            # )\n",
    "\n",
    "        else:\n",
    "            print(\"df_processed is not available. Cannot extract embeddings.\")\n",
    "            fine_tuned_embeddings_array = np.array([])\n",
    "\n",
    "    else:\n",
    "        print(\"Error: 'best_models_per_fold' list is not populated or N_SPLITS mismatch. Cannot load best model.\")\n",
    "        fine_tuned_embeddings_array = np.array([])\n",
    "else:\n",
    "    print(\"Error: 'cv_f1_scores_tsr' not found. Run Cross-Validation first.\")\n",
    "    fine_tuned_embeddings_array = np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da4742e",
   "metadata": {},
   "source": [
    "### **5.2. Advanced MLP or CNN Layers**\n",
    "\n",
    "Your idea to concatenate the transformer's `[CLS]` embedding with your hand-crafted \"Enhanced Discrete\" features and feed this into an MLP is excellent. This creates a multimodal input, leveraging both learned semantic representations and explicit linguistic features.\n",
    "\n",
    "**Steps & Code Snippets (Conceptual - using PyTorch/Keras):**\n",
    "\n",
    "Let's assume `fine_tuned_embeddings_array` (from the fine-tuned BERT) and `df_enhanced_discrete_features` (from your Option B enhancements) are ready and aligned by index with `df_processed`.\n",
    "\n",
    "#### **5.2.1. Prepare Combined Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff751e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined features for MLP: (635, 787)\n"
     ]
    }
   ],
   "source": [
    "# --- Assume fine_tuned_embeddings_array and df_enhanced_discrete_features are available ---\n",
    "# Ensure df_enhanced_discrete_features is scaled if not already for MLP\n",
    "# Ensure labels_array is also available\n",
    "\n",
    "scaler_mlp_discrete = StandardScaler()\n",
    "scaled_enhanced_discrete_features = scaler_mlp_discrete.fit_transform(df_enhanced_discrete_features) # Scale all discrete features\n",
    "\n",
    "if fine_tuned_embeddings_array.size > 0 and scaled_enhanced_discrete_features.shape[0] == fine_tuned_embeddings_array.shape[0]:\n",
    "    combined_features_for_mlp = np.concatenate(\n",
    "        (fine_tuned_embeddings_array, scaled_enhanced_discrete_features), axis=1\n",
    "    )\n",
    "    print(f\"Shape of combined features for MLP: {combined_features_for_mlp.shape}\")\n",
    "\n",
    "    # Split combined_features_for_mlp and labels_array into train/test for the MLP\n",
    "    X_mlp_train, X_mlp_test, y_mlp_train, y_mlp_test = train_test_split(\n",
    "        combined_features_for_mlp, labels_array, test_size=0.2, random_state=RANDOM_STATE, stratify=labels_array     )\n",
    "else:\n",
    "    print(\"Fine-tuned embeddings or enhanced discrete features not ready for MLP combination.\")\n",
    "    # Fallback or error handling\n",
    "    X_mlp_train, X_mlp_test, y_mlp_train, y_mlp_test = [None]*4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eb02a1",
   "metadata": {},
   "source": [
    "#### **5.2.2. Define and Train MLP (using PyTorch)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f9d153c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Advanced MLP on Combined Features ---\n",
      "MLP Epoch 1/20 -> Train Loss: 0.4046, Train F1-TSR: 0.8566 | Val Loss: 0.2032, Val F1-TSR: 0.9197\n",
      "New best MLP Val F1-TSR: 0.9197\n",
      "MLP Epoch 1/20 -> Train Loss: 0.4046, Train F1-TSR: 0.8566 | Val Loss: 0.2032, Val F1-TSR: 0.9197\n",
      "New best MLP Val F1-TSR: 0.9197\n",
      "MLP Epoch 2/20 -> Train Loss: 0.2622, Train F1-TSR: 0.8966 | Val Loss: 0.2142, Val F1-TSR: 0.9323\n",
      "New best MLP Val F1-TSR: 0.9323\n",
      "MLP Epoch 3/20 -> Train Loss: 0.1936, Train F1-TSR: 0.9353 | Val Loss: 0.2449, Val F1-TSR: 0.9077\n",
      "MLP Epoch 2/20 -> Train Loss: 0.2622, Train F1-TSR: 0.8966 | Val Loss: 0.2142, Val F1-TSR: 0.9323\n",
      "New best MLP Val F1-TSR: 0.9323\n",
      "MLP Epoch 3/20 -> Train Loss: 0.1936, Train F1-TSR: 0.9353 | Val Loss: 0.2449, Val F1-TSR: 0.9077\n",
      "MLP Epoch 4/20 -> Train Loss: 0.1541, Train F1-TSR: 0.9468 | Val Loss: 0.2430, Val F1-TSR: 0.9130\n",
      "MLP Epoch 4/20 -> Train Loss: 0.1541, Train F1-TSR: 0.9468 | Val Loss: 0.2430, Val F1-TSR: 0.9130\n",
      "MLP Epoch 5/20 -> Train Loss: 0.1318, Train F1-TSR: 0.9501 | Val Loss: 0.2610, Val F1-TSR: 0.8992\n",
      "MLP Epoch 6/20 -> Train Loss: 0.1425, Train F1-TSR: 0.9529 | Val Loss: 0.3002, Val F1-TSR: 0.8841\n",
      "MLP Epoch 5/20 -> Train Loss: 0.1318, Train F1-TSR: 0.9501 | Val Loss: 0.2610, Val F1-TSR: 0.8992\n",
      "MLP Epoch 6/20 -> Train Loss: 0.1425, Train F1-TSR: 0.9529 | Val Loss: 0.3002, Val F1-TSR: 0.8841\n",
      "MLP Epoch 7/20 -> Train Loss: 0.1386, Train F1-TSR: 0.9565 | Val Loss: 0.3147, Val F1-TSR: 0.9143\n",
      "MLP Epoch 8/20 -> Train Loss: 0.1172, Train F1-TSR: 0.9547 | Val Loss: 0.3752, Val F1-TSR: 0.8889\n",
      "MLP Epoch 7/20 -> Train Loss: 0.1386, Train F1-TSR: 0.9565 | Val Loss: 0.3147, Val F1-TSR: 0.9143\n",
      "MLP Epoch 8/20 -> Train Loss: 0.1172, Train F1-TSR: 0.9547 | Val Loss: 0.3752, Val F1-TSR: 0.8889\n",
      "MLP Epoch 9/20 -> Train Loss: 0.1060, Train F1-TSR: 0.9639 | Val Loss: 0.2976, Val F1-TSR: 0.9265\n",
      "MLP Epoch 10/20 -> Train Loss: 0.0751, Train F1-TSR: 0.9659 | Val Loss: 0.3279, Val F1-TSR: 0.8955\n",
      "MLP Epoch 9/20 -> Train Loss: 0.1060, Train F1-TSR: 0.9639 | Val Loss: 0.2976, Val F1-TSR: 0.9265\n",
      "MLP Epoch 10/20 -> Train Loss: 0.0751, Train F1-TSR: 0.9659 | Val Loss: 0.3279, Val F1-TSR: 0.8955\n",
      "MLP Epoch 11/20 -> Train Loss: 0.0928, Train F1-TSR: 0.9720 | Val Loss: 0.2836, Val F1-TSR: 0.9104\n",
      "MLP Epoch 12/20 -> Train Loss: 0.0812, Train F1-TSR: 0.9679 | Val Loss: 0.2485, Val F1-TSR: 0.9474\n",
      "New best MLP Val F1-TSR: 0.9474\n",
      "MLP Epoch 11/20 -> Train Loss: 0.0928, Train F1-TSR: 0.9720 | Val Loss: 0.2836, Val F1-TSR: 0.9104\n",
      "MLP Epoch 12/20 -> Train Loss: 0.0812, Train F1-TSR: 0.9679 | Val Loss: 0.2485, Val F1-TSR: 0.9474\n",
      "New best MLP Val F1-TSR: 0.9474\n",
      "MLP Epoch 13/20 -> Train Loss: 0.0530, Train F1-TSR: 0.9813 | Val Loss: 0.3249, Val F1-TSR: 0.9185\n",
      "MLP Epoch 14/20 -> Train Loss: 0.0635, Train F1-TSR: 0.9773 | Val Loss: 0.3117, Val F1-TSR: 0.9008\n",
      "MLP Epoch 13/20 -> Train Loss: 0.0530, Train F1-TSR: 0.9813 | Val Loss: 0.3249, Val F1-TSR: 0.9185\n",
      "MLP Epoch 14/20 -> Train Loss: 0.0635, Train F1-TSR: 0.9773 | Val Loss: 0.3117, Val F1-TSR: 0.9008\n",
      "MLP Epoch 15/20 -> Train Loss: 0.0404, Train F1-TSR: 0.9851 | Val Loss: 0.2821, Val F1-TSR: 0.9104\n",
      "MLP Epoch 16/20 -> Train Loss: 0.0752, Train F1-TSR: 0.9829 | Val Loss: 0.2882, Val F1-TSR: 0.9385\n",
      "MLP Epoch 15/20 -> Train Loss: 0.0404, Train F1-TSR: 0.9851 | Val Loss: 0.2821, Val F1-TSR: 0.9104\n",
      "MLP Epoch 16/20 -> Train Loss: 0.0752, Train F1-TSR: 0.9829 | Val Loss: 0.2882, Val F1-TSR: 0.9385\n",
      "MLP Epoch 17/20 -> Train Loss: 0.0858, Train F1-TSR: 0.9697 | Val Loss: 0.2972, Val F1-TSR: 0.9023\n",
      "MLP Epoch 18/20 -> Train Loss: 0.0850, Train F1-TSR: 0.9755 | Val Loss: 0.3059, Val F1-TSR: 0.9023\n",
      "MLP Epoch 17/20 -> Train Loss: 0.0858, Train F1-TSR: 0.9697 | Val Loss: 0.2972, Val F1-TSR: 0.9023\n",
      "MLP Epoch 18/20 -> Train Loss: 0.0850, Train F1-TSR: 0.9755 | Val Loss: 0.3059, Val F1-TSR: 0.9023\n",
      "MLP Epoch 19/20 -> Train Loss: 0.0783, Train F1-TSR: 0.9736 | Val Loss: 0.3493, Val F1-TSR: 0.8939\n",
      "MLP Epoch 20/20 -> Train Loss: 0.0433, Train F1-TSR: 0.9887 | Val Loss: 0.3875, Val F1-TSR: 0.8837\n",
      "MLP Epoch 19/20 -> Train Loss: 0.0783, Train F1-TSR: 0.9736 | Val Loss: 0.3493, Val F1-TSR: 0.8939\n",
      "MLP Epoch 20/20 -> Train Loss: 0.0433, Train F1-TSR: 0.9887 | Val Loss: 0.3875, Val F1-TSR: 0.8837\n"
     ]
    }
   ],
   "source": [
    "# --- PyTorch MLP Model ---\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class AdvancedMLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes=2):\n",
    "        super(AdvancedMLP, self).__init__()\n",
    "        self.layer_1 = nn.Linear(input_dim, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "\n",
    "        self.layer_2 = nn.Linear(512, 128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.output_layer = nn.Linear(128, num_classes)\n",
    "        # Softmax is usually applied implicitly by CrossEntropyLoss\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.layer_2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# --- Custom Dataset for PyTorch MLP ---\n",
    "class CombinedFeaturesDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):return self.features[idx], self.labels[idx]\n",
    "\n",
    "# --- Training Loop for MLP (Simplified - needs CV, early stopping like BERT) ---\n",
    "if X_mlp_train is not None and y_mlp_train is not None:\n",
    "    input_dim_mlp = X_mlp_train.shape[1]\n",
    "    mlp_model = AdvancedMLP(input_dim=input_dim_mlp, num_classes=2).to(DEVICE)\n",
    "    optimizer_mlp = optim.Adam(mlp_model.parameters(), lr=0.001) # Common LR for MLP\n",
    "    loss_fn_mlp = nn.CrossEntropyLoss()\n",
    "\n",
    "    mlp_train_dataset = CombinedFeaturesDataset(X_mlp_train, y_mlp_train)\n",
    "    mlp_train_loader = DataLoader(mlp_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    mlp_val_dataset = CombinedFeaturesDataset(X_mlp_test, y_mlp_test) # Use X_mlp_test for validation here\n",
    "    mlp_val_loader = DataLoader(mlp_val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    print(\"\\n--- Training Advanced MLP on Combined Features ---\")\n",
    "    MLP_EPOCHS = 20 # MLPs might need more epochs, use early stopping\n",
    "    best_mlp_val_f1_tsr = -1\n",
    "\n",
    "    for epoch in range(MLP_EPOCHS):\n",
    "        mlp_model.train()\n",
    "        epoch_train_loss = 0\n",
    "        train_preds_mlp, train_labels_mlp = [], []\n",
    "        for features, labels_batch in mlp_train_loader:\n",
    "            features, labels_batch = features.to(DEVICE), labels_batch.to(DEVICE)\n",
    "            optimizer_mlp.zero_grad()\n",
    "            outputs = mlp_model(features)\n",
    "            loss = loss_fn_mlp(outputs, labels_batch)\n",
    "            loss.backward()\n",
    "            optimizer_mlp.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "            train_preds_mlp.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "            train_labels_mlp.extend(labels_batch.cpu().numpy())\n",
    "\n",
    "        avg_train_loss = epoch_train_loss / len(mlp_train_loader)\n",
    "        train_f1_tsr_mlp = f1_score(train_labels_mlp, train_preds_mlp, pos_label=1, zero_division=0)\n",
    "\n",
    "        # Validation\n",
    "        mlp_model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        val_preds_mlp, val_labels_mlp = [], []\n",
    "        with torch.no_grad():\n",
    "            for features, labels_batch in mlp_val_loader:\n",
    "                features, labels_batch = features.to(DEVICE), labels_batch.to(DEVICE)\n",
    "                outputs = mlp_model(features)\n",
    "                loss = loss_fn_mlp(outputs, labels_batch)\n",
    "                epoch_val_loss += loss.item()\n",
    "                val_preds_mlp.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "                val_labels_mlp.extend(labels_batch.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = epoch_val_loss / len(mlp_val_loader)\n",
    "        val_f1_tsr_mlp = f1_score(val_labels_mlp, val_preds_mlp, pos_label=1, zero_division=0)\n",
    "        val_f1_macro_mlp = f1_score(val_labels_mlp, val_preds_mlp, average='macro', zero_division=0)\n",
    "        val_accuracy_mlp = accuracy_score(val_labels_mlp, val_preds_mlp)\n",
    "\n",
    "        print(f\"MLP Epoch {epoch+1}/{MLP_EPOCHS} -> Train Loss: {avg_train_loss:.4f}, Train F1-TSR: {train_f1_tsr_mlp:.4f} | Val Loss: {avg_val_loss:.4f}, Val F1-TSR: {val_f1_tsr_mlp:.4f}\")\n",
    "\n",
    "        if val_f1_tsr_mlp > best_mlp_val_f1_tsr:\n",
    "            best_mlp_val_f1_tsr = val_f1_tsr_mlp\n",
    "            print(f\"New best MLP Val F1-TSR: {best_mlp_val_f1_tsr:.4f}\")\n",
    "            torch.save(mlp_model.state_dict(), \"best_mlp_combined_features_ZuCo.bin\") # Save the best model\n",
    "            epochs_no_improve = 0 # Reset counter for early stopping\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "    # After training, you would collect results like in the train_and_evaluate_model function\n",
    "    # For brevity, this part is simplified. You'd add it to all_model_results_list.\n",
    "    if best_mlp_val_f1_tsr != -1 :\n",
    "        all_model_results_list.append({\n",
    "            \"model_name\": \"AdvancedMLP on Combined (FineTunedEmb + EnhDiscScaled)\",\n",
    "            \"model_class\": \"AdvancedMLP_PyTorch\",\n",
    "            \"feature_set\": \"FineTunedEmb + EnhDiscScaled\",\n",
    "            \"accuracy\": val_accuracy_mlp, # Using last epoch's val accuracy\n",
    "            \"f1_score_TSR\": best_mlp_val_f1_tsr, # Using best F1 TSR found\n",
    "            \"f1_score_macro\": val_f1_macro_mlp, # Using last epoch's macro F1\n",
    "            # \"classification_report_dict\": ..., \"confusion_matrix\": ...,\n",
    "            \"training_time_seconds\": \"N/A_in_simplified_loop\",\n",
    "            \"prediction_time_seconds\": \"N/A_in_simplified_loop\"\n",
    "        })\n",
    "else:\n",
    "    print(\"MLP training skipped as combined features are not ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86bc6de",
   "metadata": {},
   "source": [
    "- **Principles:** Performance (BatchNorm helps stabilize training, Dropout reduces overfitting), Modularity (separate `Dataset` and `nn.Module` classes).\n",
    "- **Best Practices:**\n",
    "    - **Input Dimension:** The `input_dim` for the MLP will be the sum of the fine-tuned embedding dimension (e.g., 768 for `bert-base-uncased`) and the number of scaled enhanced discrete features.\n",
    "    - **Normalization/Scaling:** Ensure that the concatenated features are appropriately scaled. Embeddings are often somewhat normalized, but your discrete features will vary wildly in scale. Scaling them *before* concatenation is crucial.\n",
    "    - **Activation Functions:** ReLU is a common choice.\n",
    "    - **Optimizer:** Adam or AdamW are good defaults.\n",
    "    - **Loss Function:** `CrossEntropyLoss` for binary/multi-class classification.\n",
    "    - **Cross-Validation for MLP:** The MLP training also needs to be wrapped in a `StratifiedKFold` loop for robust evaluation, similar to the BERT fine-tuning. The simplified loop above is just for one train/val split.\n",
    "\n",
    "Regarding CNNs:\n",
    "\n",
    "While CNNs can be used for text classification (often 1D CNNs over token embeddings), for sentence-level classification with already-rich sentence embeddings (like [CLS] from BERT or SBERT outputs), an MLP is often a more straightforward and effective choice to combine these with other features. If you were working with raw token embeddings for the entire sentence, a 1D CNN could learn local patterns, followed by pooling and then an MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c0ce29",
   "metadata": {},
   "source": [
    "### 5.3 Compile and Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c6a16f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 5.3 Final Model Performance Summary ---\n",
      "Model Performance Summary (Sorted by F1-score for TSR class):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "feature_set",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_class",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "f1_score_TSR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f1_score_macro",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "training_time_seconds",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "prediction_time_seconds",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e3c573bd-fefb-49ab-8772-d1992a1399d6",
       "rows": [
        [
         "23",
         "AdvancedMLP on Combined (FineTunedEmb + EnhDiscScaled)",
         "FineTunedEmb + EnhDiscScaled",
         "AdvancedMLP_PyTorch",
         "0.9473684210526315",
         "0.8818604651162791",
         "0.8818897637795275",
         "N/A_in_simplified_loop",
         "N/A_in_simplified_loop"
        ],
        [
         "22",
         "AdvancedMLP on Combined (FineTunedEmb + EnhDiscScaled)",
         "FineTunedEmb + EnhDiscScaled",
         "AdvancedMLP_PyTorch",
         "0.9343065693430657",
         "0.9050348953140579",
         "0.905511811023622",
         "N/A_in_simplified_loop",
         "N/A_in_simplified_loop"
        ],
        [
         "8",
         "RandomForest on Enhanced Discrete Unscaled (Option B)",
         "Enhanced Discrete Unscaled (Option B)",
         "RandomForest",
         "0.7445255474452555",
         "0.7226901241499781",
         "0.7244094488188977",
         "0.25255537033081055",
         "0.04806661605834961"
        ],
        [
         "14",
         "SVM on Embeddings (Option A)",
         "Embeddings (Option A)",
         "SVM",
         "0.7230769230769231",
         "0.7163771712158808",
         "0.7165354330708661",
         "0.2565762996673584",
         "0.019513607025146484"
        ],
        [
         "17",
         "SVM on Combined (A + Scaled Enh. B)",
         "Combined (A + Scaled Enh. B)",
         "SVM",
         "0.7205882352941176",
         "0.6992771684945165",
         "0.7007874015748031",
         "0.22800707817077637",
         "0.019999980926513672"
        ],
        [
         "6",
         "RandomForest on Embeddings (Option A)",
         "Embeddings (Option A)",
         "RandomForest",
         "0.7205882352941176",
         "0.6992771684945165",
         "0.7007874015748031",
         "0.26078367233276367",
         "0.04703974723815918"
        ],
        [
         "21",
         "MLP on Combined (A + Scaled Enh. B)",
         "Combined (A + Scaled Enh. B)",
         "MLP",
         "0.7164179104477612",
         "0.6998756218905473",
         "0.7007874015748031",
         "0.5725297927856445",
         "0.001998424530029297"
        ],
        [
         "10",
         "LightGBM on Embeddings (Option A)",
         "Embeddings (Option A)",
         "LightGBM",
         "0.7111111111111111",
         "0.6916900093370681",
         "0.6929133858267716",
         "0.5799911022186279",
         "0.0020046234130859375"
        ],
        [
         "0",
         "LogisticRegression on Embeddings (Option A)",
         "Embeddings (Option A)",
         "LogisticRegression",
         "0.7014925373134329",
         "0.6840796019900497",
         "0.6850393700787402",
         "0.017002582550048828",
         "0.0009963512420654297"
        ],
        [
         "18",
         "MLP on Embeddings (Option A)",
         "Embeddings (Option A)",
         "MLP",
         "0.696969696969697",
         "0.6845504222553402",
         "0.6850393700787402",
         "0.4063129425048828",
         "0.0039975643157958984"
        ],
        [
         "16",
         "SVM on Enhanced Discrete Scaled (Option B)",
         "Enhanced Discrete Scaled (Option B)",
         "SVM",
         "0.6956521739130435",
         "0.6667916041979011",
         "0.6692913385826772",
         "0.07436084747314453",
         "0.006511688232421875"
        ],
        [
         "7",
         "RandomForest on Base Discrete Unscaled (Option B)",
         "Base Discrete Unscaled (Option B)",
         "RandomForest",
         "0.6861313868613139",
         "0.6593050096699732",
         "0.6614173228346457",
         "0.25018310546875",
         "0.04230189323425293"
        ],
        [
         "12",
         "LightGBM on Enhanced Discrete Unscaled (Option B)",
         "Enhanced Discrete Unscaled (Option B)",
         "LightGBM",
         "0.676056338028169",
         "0.6326710261569417",
         "0.6377952755905512",
         "0.055519819259643555",
         "0.002999544143676758"
        ],
        [
         "2",
         "LogisticRegression on Enhanced Discrete Scaled (Option B)",
         "Enhanced Discrete Scaled (Option B)",
         "LogisticRegression",
         "0.671875",
         "0.6692708333333333",
         "0.6692913385826772",
         "0.003971576690673828",
         "0.0"
        ],
        [
         "13",
         "LightGBM on Combined (A + Scaled Enh. B)",
         "Combined (A + Scaled Enh. B)",
         "LightGBM",
         "0.6614173228346457",
         "0.6614173228346457",
         "0.6614173228346457",
         "0.43012547492980957",
         "0.0030002593994140625"
        ],
        [
         "20",
         "MLP on Enhanced Discrete Scaled (Option B)",
         "Enhanced Discrete Scaled (Option B)",
         "MLP",
         "0.656934306569343",
         "0.6276124524299707",
         "0.6299212598425197",
         "0.13390398025512695",
         "0.001001596450805664"
        ],
        [
         "9",
         "RandomForest on Combined (A + Scaled Enh. B)",
         "Combined (A + Scaled Enh. B)",
         "RandomForest",
         "0.6564885496183206",
         "0.6453174455408677",
         "0.6456692913385826",
         "0.2693593502044678",
         "0.03941750526428223"
        ],
        [
         "5",
         "DecisionTree on Enhanced Discrete Unscaled (Option B)",
         "Enhanced Discrete Unscaled (Option B)",
         "DecisionTree",
         "0.6277372262773723",
         "0.5959198951899682",
         "0.5984251968503937",
         "0.009999275207519531",
         "0.0010025501251220703"
        ],
        [
         "19",
         "MLP on Base Discrete Scaled (Option B)",
         "Base Discrete Scaled (Option B)",
         "MLP",
         "0.609271523178808",
         "0.5182279945991127",
         "0.5354330708661418",
         "0.19896245002746582",
         "0.0"
        ],
        [
         "11",
         "LightGBM on Base Discrete Unscaled (Option B)",
         "Base Discrete Unscaled (Option B)",
         "LightGBM",
         "0.5925925925925926",
         "0.5652038593215063",
         "0.5669291338582677",
         "0.04152274131774902",
         "0.0030014514923095703"
        ],
        [
         "1",
         "LogisticRegression on Base Discrete Scaled (Option B)",
         "Base Discrete Scaled (Option B)",
         "LogisticRegression",
         "0.5846153846153846",
         "0.5745657568238214",
         "0.5748031496062992",
         "0.0020008087158203125",
         "0.0"
        ],
        [
         "15",
         "SVM on Base Discrete Scaled (Option B)",
         "Base Discrete Scaled (Option B)",
         "SVM",
         "0.5691056910569106",
         "0.5822627691925775",
         "0.5826771653543307",
         "0.06700801849365234",
         "0.00650477409362793"
        ],
        [
         "3",
         "DecisionTree on Embeddings (Option A)",
         "Embeddings (Option A)",
         "DecisionTree",
         "0.5185185185185185",
         "0.4861500155617803",
         "0.4881889763779528",
         "0.23421835899353027",
         "0.0009996891021728516"
        ],
        [
         "4",
         "DecisionTree on Base Discrete Unscaled (Option B)",
         "Base Discrete Unscaled (Option B)",
         "DecisionTree",
         "0.5079365079365079",
         "0.511780753968254",
         "0.5118110236220472",
         "0.0075130462646484375",
         "0.0020003318786621094"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 24
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>model_class</th>\n",
       "      <th>f1_score_TSR</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>training_time_seconds</th>\n",
       "      <th>prediction_time_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AdvancedMLP on Combined (FineTunedEmb + EnhDiscScaled)</td>\n",
       "      <td>FineTunedEmb + EnhDiscScaled</td>\n",
       "      <td>AdvancedMLP_PyTorch</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.881860</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>N/A_in_simplified_loop</td>\n",
       "      <td>N/A_in_simplified_loop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AdvancedMLP on Combined (FineTunedEmb + EnhDiscScaled)</td>\n",
       "      <td>FineTunedEmb + EnhDiscScaled</td>\n",
       "      <td>AdvancedMLP_PyTorch</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.905035</td>\n",
       "      <td>0.905512</td>\n",
       "      <td>N/A_in_simplified_loop</td>\n",
       "      <td>N/A_in_simplified_loop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForest on Enhanced Discrete Unscaled (Option B)</td>\n",
       "      <td>Enhanced Discrete Unscaled (Option B)</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.722690</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.252555</td>\n",
       "      <td>0.048067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVM on Embeddings (Option A)</td>\n",
       "      <td>Embeddings (Option A)</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.716377</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>0.256576</td>\n",
       "      <td>0.019514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM on Combined (A + Scaled Enh. B)</td>\n",
       "      <td>Combined (A + Scaled Enh. B)</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.699277</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>0.228007</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest on Embeddings (Option A)</td>\n",
       "      <td>Embeddings (Option A)</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.699277</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>0.260784</td>\n",
       "      <td>0.04704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MLP on Combined (A + Scaled Enh. B)</td>\n",
       "      <td>Combined (A + Scaled Enh. B)</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.699876</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>0.57253</td>\n",
       "      <td>0.001998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBM on Embeddings (Option A)</td>\n",
       "      <td>Embeddings (Option A)</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.691690</td>\n",
       "      <td>0.692913</td>\n",
       "      <td>0.579991</td>\n",
       "      <td>0.002005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression on Embeddings (Option A)</td>\n",
       "      <td>Embeddings (Option A)</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.684080</td>\n",
       "      <td>0.685039</td>\n",
       "      <td>0.017003</td>\n",
       "      <td>0.000996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MLP on Embeddings (Option A)</td>\n",
       "      <td>Embeddings (Option A)</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.684550</td>\n",
       "      <td>0.685039</td>\n",
       "      <td>0.406313</td>\n",
       "      <td>0.003998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVM on Enhanced Discrete Scaled (Option B)</td>\n",
       "      <td>Enhanced Discrete Scaled (Option B)</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.666792</td>\n",
       "      <td>0.669291</td>\n",
       "      <td>0.074361</td>\n",
       "      <td>0.006512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForest on Base Discrete Unscaled (Option B)</td>\n",
       "      <td>Base Discrete Unscaled (Option B)</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.686131</td>\n",
       "      <td>0.659305</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.250183</td>\n",
       "      <td>0.042302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBM on Enhanced Discrete Unscaled (Option B)</td>\n",
       "      <td>Enhanced Discrete Unscaled (Option B)</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.632671</td>\n",
       "      <td>0.637795</td>\n",
       "      <td>0.05552</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression on Enhanced Discrete Scaled (Option B)</td>\n",
       "      <td>Enhanced Discrete Scaled (Option B)</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.669271</td>\n",
       "      <td>0.669291</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBM on Combined (A + Scaled Enh. B)</td>\n",
       "      <td>Combined (A + Scaled Enh. B)</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.430125</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MLP on Enhanced Discrete Scaled (Option B)</td>\n",
       "      <td>Enhanced Discrete Scaled (Option B)</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.656934</td>\n",
       "      <td>0.627612</td>\n",
       "      <td>0.629921</td>\n",
       "      <td>0.133904</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForest on Combined (A + Scaled Enh. B)</td>\n",
       "      <td>Combined (A + Scaled Enh. B)</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.656489</td>\n",
       "      <td>0.645317</td>\n",
       "      <td>0.645669</td>\n",
       "      <td>0.269359</td>\n",
       "      <td>0.039418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTree on Enhanced Discrete Unscaled (Option B)</td>\n",
       "      <td>Enhanced Discrete Unscaled (Option B)</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.627737</td>\n",
       "      <td>0.595920</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>0.001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MLP on Base Discrete Scaled (Option B)</td>\n",
       "      <td>Base Discrete Scaled (Option B)</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.518228</td>\n",
       "      <td>0.535433</td>\n",
       "      <td>0.198962</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBM on Base Discrete Unscaled (Option B)</td>\n",
       "      <td>Base Discrete Unscaled (Option B)</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.565204</td>\n",
       "      <td>0.566929</td>\n",
       "      <td>0.041523</td>\n",
       "      <td>0.003001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression on Base Discrete Scaled (Option B)</td>\n",
       "      <td>Base Discrete Scaled (Option B)</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.574566</td>\n",
       "      <td>0.574803</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVM on Base Discrete Scaled (Option B)</td>\n",
       "      <td>Base Discrete Scaled (Option B)</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.569106</td>\n",
       "      <td>0.582263</td>\n",
       "      <td>0.582677</td>\n",
       "      <td>0.067008</td>\n",
       "      <td>0.006505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTree on Embeddings (Option A)</td>\n",
       "      <td>Embeddings (Option A)</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.486150</td>\n",
       "      <td>0.488189</td>\n",
       "      <td>0.234218</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree on Base Discrete Unscaled (Option B)</td>\n",
       "      <td>Base Discrete Unscaled (Option B)</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.511781</td>\n",
       "      <td>0.511811</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   model_name  \\\n",
       "23     AdvancedMLP on Combined (FineTunedEmb + EnhDiscScaled)   \n",
       "22     AdvancedMLP on Combined (FineTunedEmb + EnhDiscScaled)   \n",
       "8       RandomForest on Enhanced Discrete Unscaled (Option B)   \n",
       "14                               SVM on Embeddings (Option A)   \n",
       "17                        SVM on Combined (A + Scaled Enh. B)   \n",
       "6                       RandomForest on Embeddings (Option A)   \n",
       "21                        MLP on Combined (A + Scaled Enh. B)   \n",
       "10                          LightGBM on Embeddings (Option A)   \n",
       "0                 LogisticRegression on Embeddings (Option A)   \n",
       "18                               MLP on Embeddings (Option A)   \n",
       "16                 SVM on Enhanced Discrete Scaled (Option B)   \n",
       "7           RandomForest on Base Discrete Unscaled (Option B)   \n",
       "12          LightGBM on Enhanced Discrete Unscaled (Option B)   \n",
       "2   LogisticRegression on Enhanced Discrete Scaled (Option B)   \n",
       "13                   LightGBM on Combined (A + Scaled Enh. B)   \n",
       "20                 MLP on Enhanced Discrete Scaled (Option B)   \n",
       "9                RandomForest on Combined (A + Scaled Enh. B)   \n",
       "5       DecisionTree on Enhanced Discrete Unscaled (Option B)   \n",
       "19                     MLP on Base Discrete Scaled (Option B)   \n",
       "11              LightGBM on Base Discrete Unscaled (Option B)   \n",
       "1       LogisticRegression on Base Discrete Scaled (Option B)   \n",
       "15                     SVM on Base Discrete Scaled (Option B)   \n",
       "3                       DecisionTree on Embeddings (Option A)   \n",
       "4           DecisionTree on Base Discrete Unscaled (Option B)   \n",
       "\n",
       "                              feature_set          model_class  f1_score_TSR  \\\n",
       "23           FineTunedEmb + EnhDiscScaled  AdvancedMLP_PyTorch      0.947368   \n",
       "22           FineTunedEmb + EnhDiscScaled  AdvancedMLP_PyTorch      0.934307   \n",
       "8   Enhanced Discrete Unscaled (Option B)         RandomForest      0.744526   \n",
       "14                  Embeddings (Option A)                  SVM      0.723077   \n",
       "17           Combined (A + Scaled Enh. B)                  SVM      0.720588   \n",
       "6                   Embeddings (Option A)         RandomForest      0.720588   \n",
       "21           Combined (A + Scaled Enh. B)                  MLP      0.716418   \n",
       "10                  Embeddings (Option A)             LightGBM      0.711111   \n",
       "0                   Embeddings (Option A)   LogisticRegression      0.701493   \n",
       "18                  Embeddings (Option A)                  MLP      0.696970   \n",
       "16    Enhanced Discrete Scaled (Option B)                  SVM      0.695652   \n",
       "7       Base Discrete Unscaled (Option B)         RandomForest      0.686131   \n",
       "12  Enhanced Discrete Unscaled (Option B)             LightGBM      0.676056   \n",
       "2     Enhanced Discrete Scaled (Option B)   LogisticRegression      0.671875   \n",
       "13           Combined (A + Scaled Enh. B)             LightGBM      0.661417   \n",
       "20    Enhanced Discrete Scaled (Option B)                  MLP      0.656934   \n",
       "9            Combined (A + Scaled Enh. B)         RandomForest      0.656489   \n",
       "5   Enhanced Discrete Unscaled (Option B)         DecisionTree      0.627737   \n",
       "19        Base Discrete Scaled (Option B)                  MLP      0.609272   \n",
       "11      Base Discrete Unscaled (Option B)             LightGBM      0.592593   \n",
       "1         Base Discrete Scaled (Option B)   LogisticRegression      0.584615   \n",
       "15        Base Discrete Scaled (Option B)                  SVM      0.569106   \n",
       "3                   Embeddings (Option A)         DecisionTree      0.518519   \n",
       "4       Base Discrete Unscaled (Option B)         DecisionTree      0.507937   \n",
       "\n",
       "    f1_score_macro  accuracy   training_time_seconds prediction_time_seconds  \n",
       "23        0.881860  0.881890  N/A_in_simplified_loop  N/A_in_simplified_loop  \n",
       "22        0.905035  0.905512  N/A_in_simplified_loop  N/A_in_simplified_loop  \n",
       "8         0.722690  0.724409                0.252555                0.048067  \n",
       "14        0.716377  0.716535                0.256576                0.019514  \n",
       "17        0.699277  0.700787                0.228007                    0.02  \n",
       "6         0.699277  0.700787                0.260784                 0.04704  \n",
       "21        0.699876  0.700787                 0.57253                0.001998  \n",
       "10        0.691690  0.692913                0.579991                0.002005  \n",
       "0         0.684080  0.685039                0.017003                0.000996  \n",
       "18        0.684550  0.685039                0.406313                0.003998  \n",
       "16        0.666792  0.669291                0.074361                0.006512  \n",
       "7         0.659305  0.661417                0.250183                0.042302  \n",
       "12        0.632671  0.637795                 0.05552                   0.003  \n",
       "2         0.669271  0.669291                0.003972                     0.0  \n",
       "13        0.661417  0.661417                0.430125                   0.003  \n",
       "20        0.627612  0.629921                0.133904                0.001002  \n",
       "9         0.645317  0.645669                0.269359                0.039418  \n",
       "5         0.595920  0.598425                0.009999                0.001003  \n",
       "19        0.518228  0.535433                0.198962                     0.0  \n",
       "11        0.565204  0.566929                0.041523                0.003001  \n",
       "1         0.574566  0.574803                0.002001                     0.0  \n",
       "15        0.582263  0.582677                0.067008                0.006505  \n",
       "3         0.486150  0.488189                0.234218                   0.001  \n",
       "4         0.511781  0.511811                0.007513                   0.002  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final model performance summary saved to final_model_performance_summary.csv\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None) # Show full content of each column\n",
    "\n",
    "print(\"\\n--- 5.3 Final Model Performance Summary ---\")\n",
    "if all_model_results_list:\n",
    "    df_all_results = pd.DataFrame(all_model_results_list)\n",
    "    # Select and order columns for better readability\n",
    "    display_cols = [\n",
    "        \"model_name\", \"feature_set\", \"model_class\",\n",
    "        \"f1_score_TSR\", \"f1_score_macro\", \"accuracy\",\n",
    "        \"training_time_seconds\", \"prediction_time_seconds\"\n",
    "    ]\n",
    "    # Ensure all display_cols exist in the dataframe, add if missing with NaN\n",
    "    for col in display_cols:\n",
    "        if col not in df_all_results.columns:\n",
    "            df_all_results[col] = np.nan\n",
    "\n",
    "    df_all_results_sorted = df_all_results.sort_values(by='f1_score_TSR', ascending=False)\n",
    "    print(\"Model Performance Summary (Sorted by F1-score for TSR class):\")\n",
    "    display(df_all_results_sorted[display_cols])\n",
    "\n",
    "    # Save results to CSV\n",
    "    try:\n",
    "        df_all_results_sorted.to_csv(\"final_model_performance_summary.csv\", index=False)\n",
    "        print(\"\\nFinal model performance summary saved to final_model_performance_summary.csv\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving final model performance summary: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d313f2",
   "metadata": {},
   "source": [
    "## 6. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2418eaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- Ensure necessary libraries are imported ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split # If X_mlp_test needs regeneration\n",
    "from sklearn.preprocessing import StandardScaler     # If scaled_enhanced_discrete_features needs regeneration\n",
    "# from transformers import BertTokenizerFast        # If TOKENIZER needs re-init for embedding regeneration\n",
    "# from sentence_transformers import SentenceTransformer # If fine_tuned_embeddings_array needs regeneration\n",
    "\n",
    "# --- Device Configuration (ensure this is consistent) ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- Constants (ensure these are consistent with previous steps) ---\n",
    "MODEL_NAME_BERT = 'bert-base-uncased' # Used for fine_tuned_embeddings_array dimension\n",
    "MAX_LEN_BERT = 128                  # Used for fine_tuned_embeddings_array\n",
    "RANDOM_STATE = 42\n",
    "BATCH_SIZE_MLP_EVAL = 32 # Can be larger for evaluation\n",
    "\n",
    "# --- (Re)Define the AdvancedMLP class (if not already in scope) ---\n",
    "# class AdvancedMLP(nn.Module):\n",
    "#     def __init__(self, input_dim, num_classes=2):\n",
    "#         super(AdvancedMLP, self).__init__()\n",
    "#         self.layer_1 = nn.Linear(input_dim, 512)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "#         self.dropout1 = nn.Dropout(0.3)\n",
    "#         self.layer_2 = nn.Linear(512, 128)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "#         self.dropout2 = nn.Dropout(0.3)\n",
    "#         self.output_layer = nn.Linear(128, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.layer_1(x)\n",
    "#         x = self.relu1(x)\n",
    "#         x = self.batchnorm1(x)\n",
    "#         x = self.dropout1(x)\n",
    "#         x = self.layer_2(x)\n",
    "#         x = self.relu2(x)\n",
    "#         x = self.batchnorm2(x)\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.output_layer(x)\n",
    "#         return x\n",
    "\n",
    "# # --- (Re)Define CombinedFeaturesDataset for MLP (if not already in scope) ---\n",
    "# class CombinedFeaturesDataset(Dataset):\n",
    "#     def __init__(self, features, labels):\n",
    "#         self.features = torch.tensor(features, dtype=torch.float32)\n",
    "#         self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.features)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.features[idx], self.labels[idx]\n",
    "\n",
    "# --- Step 1: Ensure X_mlp_test and y_mlp_test are available ---\n",
    "# If these variables are not in your current scope, you MUST regenerate them\n",
    "# exactly as they were during the MLP training. This involves:\n",
    "#   1. Loading/generating `fine_tuned_embeddings_array` (from best BERT)\n",
    "#   2. Loading/generating `df_enhanced_discrete_features`\n",
    "#   3. Scaling `df_enhanced_discrete_features` to get `scaled_enhanced_discrete_features`\n",
    "#   4. Concatenating `fine_tuned_embeddings_array` and `scaled_enhanced_discrete_features`\n",
    "#      to get `combined_features_for_mlp`.\n",
    "#   5. Splitting `combined_features_for_mlp` and `labels_array` using the SAME\n",
    "#      `train_test_split` parameters (test_size=0.2, random_state=RANDOM_STATE, stratify=labels_array).\n",
    "\n",
    "# For this script, we'll assume X_mlp_test and y_mlp_test are populated.\n",
    "# Placeholder check:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdbd3636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred MLP input dimension for evaluation: 787\n",
      "Successfully loaded model weights from best_mlp_combined_features_ZuCo.bin\n",
      "\n",
      "--- Evaluating Final MLP Model on the Held-Out Test Set ---\n",
      "\n",
      "Final Model Evaluation - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NR (0)       0.95      0.93      0.94        61\n",
      "     TSR (1)       0.94      0.95      0.95        66\n",
      "\n",
      "    accuracy                           0.94       127\n",
      "   macro avg       0.95      0.94      0.94       127\n",
      "weighted avg       0.94      0.94      0.94       127\n",
      "\n",
      "\n",
      "Final Model Evaluation - Confusion Matrix:\n",
      "[[57  4]\n",
      " [ 3 63]]\n",
      "\n",
      "Final Model Accuracy: 0.9449\n",
      "Final Model F1-score (TSR class): 0.9474\n",
      "Final Model F1-score (Macro): 0.9448\n",
      "Final Model F1-score (Weighted): 0.9449\n",
      "\n",
      "--- Interpretation of Final Model Performance ---\n",
      "The final MLP model achieves an excellent F1-score of 0.9474 for the TSR class on the held-out test set.\n",
      "This indicates strong performance in identifying Task-Specific Reading sentences.\n",
      "Overall accuracy is 0.9449 and macro F1-score is 0.9448.\n",
      "Review the precision and recall for each class in the classification report and the confusion matrix for detailed error patterns.\n",
      "\n",
      "Considerations for this evaluation:\n",
      "- The features used by this MLP include embeddings from a BERT model fine-tuned using Cross-Validation on the *entire* dataset.\n",
      "  Therefore, the BERT component has 'seen' the data that forms this test set during its own training/validation phases in different CV folds.\n",
      "- For the most stringent evaluation, a portion of the data should have been set aside *before* any model (including BERT for embedding generation) was trained or fine-tuned.\n",
      "- However, given the current workflow, this evaluation on X_mlp_test provides the performance of the MLP on data it wasn't directly trained on.\n"
     ]
    }
   ],
   "source": [
    "if 'X_mlp_test' not in globals() or 'y_mlp_test' not in globals() or \\\n",
    "   X_mlp_test is None or y_mlp_test is None:\n",
    "    print(\"ERROR: X_mlp_test or y_mlp_test not found in the current environment.\")\n",
    "    print(\"Please ensure these are loaded or regenerated consistently with the MLP training phase.\")\n",
    "    # As a fallback for the script to run, creating dummy ones.\n",
    "    # THIS IS NOT CORRECT FOR ACTUAL EVALUATION IF THE ORIGINALS ARE LOST.\n",
    "    # You would need to reconstruct them from fine_tuned_embeddings_array and scaled_enhanced_discrete_features\n",
    "    # For example:\n",
    "    # df_processed = pd.read_csv(PROCESSED_DATA_FILENAME)\n",
    "    # labels_array = df_processed['label'].values\n",
    "    # # Assume fine_tuned_embeddings_array & scaled_enhanced_discrete_features are loaded/recreated\n",
    "    # # combined_features_for_mlp = np.concatenate((fine_tuned_embeddings_array, scaled_enhanced_discrete_features), axis=1)\n",
    "    # # _, X_mlp_test, _, y_mlp_test = train_test_split(\n",
    "    # # combined_features_for_mlp, labels_array, test_size=0.2, random_state=RANDOM_STATE, stratify=labels_array\n",
    "    # # )\n",
    "    print(\"Cannot proceed with evaluation without the correct test set.\")\n",
    "    # To prevent error in subsequent lines for demonstration if data is missing:\n",
    "    X_mlp_test = np.array([]) \n",
    "    y_mlp_test = np.array([])\n",
    "\n",
    "if X_mlp_test.size > 0 and y_mlp_test.size > 0:\n",
    "    # --- Step 2: Determine input_dim for the MLP ---\n",
    "    # This must match the input_dim used when the best_mlp_combined_features_ZuCo.bin was saved.\n",
    "    # It's fine_tuned_embedding_dim + number_of_scaled_enhanced_discrete_features.\n",
    "    # Example: BERT-base (768) + num_discrete_features (e.g., 19 from your log) = 787\n",
    "    # You should verify this from your `combined_features_for_mlp.shape[1]` when it was created.\n",
    "    \n",
    "    # Let's try to infer it if possible, or set it manually based on previous steps.\n",
    "    # This is a potential point of failure if not careful.\n",
    "    # Assuming X_mlp_test has the correct number of features:\n",
    "    input_dim_mlp_eval = X_mlp_test.shape[1]\n",
    "    print(f\"Inferred MLP input dimension for evaluation: {input_dim_mlp_eval}\")\n",
    "\n",
    "\n",
    "    # --- Step 3: Instantiate the MLP model ---\n",
    "    final_mlp_model = AdvancedMLP(input_dim=input_dim_mlp_eval, num_classes=2).to(DEVICE)\n",
    "\n",
    "    # --- Step 4: Load the saved state dictionary ---\n",
    "    model_path = \"best_mlp_combined_features_ZuCo.bin\"\n",
    "    try:\n",
    "        final_mlp_model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "        print(f\"Successfully loaded model weights from {model_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Model file '{model_path}' not found. Cannot evaluate.\")\n",
    "        final_mlp_model = None # Ensure it's None so evaluation doesn't run\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model weights: {e}\")\n",
    "        final_mlp_model = None\n",
    "\n",
    "    if final_mlp_model:\n",
    "        # --- Step 5: Set the model to evaluation mode ---\n",
    "        final_mlp_model.eval()\n",
    "\n",
    "        # --- Step 6: Create DataLoader for the test set ---\n",
    "        mlp_test_dataset = CombinedFeaturesDataset(X_mlp_test, y_mlp_test)\n",
    "        mlp_test_loader = DataLoader(mlp_test_dataset, batch_size=BATCH_SIZE_MLP_EVAL) # Can use larger batch for eval\n",
    "\n",
    "        # --- Step 7: Make predictions on X_mlp_test ---\n",
    "        print(\"\\n--- Evaluating Final MLP Model on the Held-Out Test Set ---\")\n",
    "        all_mlp_preds = []\n",
    "        all_mlp_true_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for features_batch, labels_batch in mlp_test_loader:\n",
    "                features_batch = features_batch.to(DEVICE)\n",
    "                # labels_batch are already tensors, no need to move to DEVICE if only used for sklearn metrics\n",
    "\n",
    "                outputs = final_mlp_model(features_batch)\n",
    "                preds_batch = torch.argmax(outputs, dim=1)\n",
    "\n",
    "                all_mlp_preds.extend(preds_batch.cpu().numpy())\n",
    "                all_mlp_true_labels.extend(labels_batch.cpu().numpy()) # labels_batch were already tensors\n",
    "\n",
    "        # --- Step 8: Calculate and print comprehensive metrics ---\n",
    "        print(\"\\nFinal Model Evaluation - Classification Report:\")\n",
    "        report_str_final = classification_report(all_mlp_true_labels, all_mlp_preds, target_names=['NR (0)', 'TSR (1)'], zero_division=0)\n",
    "        report_dict_final = classification_report(all_mlp_true_labels, all_mlp_preds, target_names=['NR (0)', 'TSR (1)'], output_dict=True, zero_division=0)\n",
    "        print(report_str_final)\n",
    "\n",
    "        cm_final = confusion_matrix(all_mlp_true_labels, all_mlp_preds)\n",
    "        print(\"\\nFinal Model Evaluation - Confusion Matrix:\")\n",
    "        print(cm_final)\n",
    "        # Plotting confusion matrix can be helpful too\n",
    "        # sns.heatmap(cm_final, annot=True, fmt='d', cmap='Blues', xticklabels=['NR (0)', 'TSR (1)'], yticklabels=['NR (0)', 'TSR (1)'])\n",
    "        # plt.xlabel('Predicted Label')\n",
    "        # plt.ylabel('True Label')\n",
    "        # plt.title('Final MLP Confusion Matrix')\n",
    "        # plt.show()\n",
    "\n",
    "\n",
    "        accuracy_final = accuracy_score(all_mlp_true_labels, all_mlp_preds)\n",
    "        f1_tsr_final = f1_score(all_mlp_true_labels, all_mlp_preds, pos_label=1, zero_division=0)\n",
    "        f1_macro_final = f1_score(all_mlp_true_labels, all_mlp_preds, average='macro', zero_division=0)\n",
    "        f1_weighted_final = f1_score(all_mlp_true_labels, all_mlp_preds, average='weighted', zero_division=0)\n",
    "\n",
    "        print(f\"\\nFinal Model Accuracy: {accuracy_final:.4f}\")\n",
    "        print(f\"Final Model F1-score (TSR class): {f1_tsr_final:.4f}\")\n",
    "        print(f\"Final Model F1-score (Macro): {f1_macro_final:.4f}\")\n",
    "        print(f\"Final Model F1-score (Weighted): {f1_weighted_final:.4f}\")\n",
    "\n",
    "        # Store these final results if needed\n",
    "        final_results_summary = {\n",
    "            \"model_name\": \"Final AdvancedMLP (Combined Features)\",\n",
    "            \"accuracy\": accuracy_final,\n",
    "            \"f1_score_TSR\": f1_tsr_final,\n",
    "            \"f1_score_macro\": f1_macro_final,\n",
    "            \"f1_score_weighted\": f1_weighted_final,\n",
    "            \"classification_report_dict\": report_dict_final,\n",
    "            \"confusion_matrix\": cm_final.tolist()\n",
    "        }\n",
    "        # You might want to append this to a list or save it\n",
    "        # all_model_results_list.append(final_results_summary) # If all_model_results_list is still relevant\n",
    "\n",
    "        print(\"\\n--- Interpretation of Final Model Performance ---\")\n",
    "        if f1_tsr_final >= 0.90:\n",
    "            print(f\"The final MLP model achieves an excellent F1-score of {f1_tsr_final:.4f} for the TSR class on the held-out test set.\")\n",
    "            print(\"This indicates strong performance in identifying Task-Specific Reading sentences.\")\n",
    "        elif f1_tsr_final >= 0.80:\n",
    "            print(f\"The final MLP model achieves a very good F1-score of {f1_tsr_final:.4f} for the TSR class on the held-out test set.\")\n",
    "        else:\n",
    "            print(f\"The final MLP model achieves an F1-score of {f1_tsr_final:.4f} for the TSR class on the held-out test set.\")\n",
    "\n",
    "        print(f\"Overall accuracy is {accuracy_final:.4f} and macro F1-score is {f1_macro_final:.4f}.\")\n",
    "        print(\"Review the precision and recall for each class in the classification report and the confusion matrix for detailed error patterns.\")\n",
    "\n",
    "        print(\"\\nConsiderations for this evaluation:\")\n",
    "        print(\"- The features used by this MLP include embeddings from a BERT model fine-tuned using Cross-Validation on the *entire* dataset.\")\n",
    "        print(\"  Therefore, the BERT component has 'seen' the data that forms this test set during its own training/validation phases in different CV folds.\")\n",
    "        print(\"- For the most stringent evaluation, a portion of the data should have been set aside *before* any model (including BERT for embedding generation) was trained or fine-tuned.\")\n",
    "        print(\"- However, given the current workflow, this evaluation on X_mlp_test provides the performance of the MLP on data it wasn't directly trained on.\")\n",
    "\n",
    "else:\n",
    "    print(\"Evaluation cannot proceed as X_mlp_test or y_mlp_test is empty.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
